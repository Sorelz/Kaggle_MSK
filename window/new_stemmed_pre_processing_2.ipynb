{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gensim\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim import utils\n",
    "import os\n",
    "import nltk\n",
    "import scipy.sparse as ssp\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"checkpoints_databases/new_working_train.csv\",encoding=\"utf8\")\n",
    "test=pd.read_csv(\"checkpoints_databases/new_working_test.csv\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock as input features for meta model\n",
    "train_cl=train.drop([\"Variation\",\"Class\",\"Gene\",\"Full_Text\",\"Window_Text\"],axis=1)\n",
    "test_cl=test.drop([\"Class\",\"Variation\",\"Gene\",\"Full_Text\",\"Window_Text\"],axis=1)\n",
    "train_cl.to_csv(\"w_meta_features/meta_train_l1l2.csv\",index=False)\n",
    "test_cl.to_csv(\"w_meta_features/meta_test_l1l2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat((train,test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all[\"Window_Text\"][data_all[\"Window_Text\"].isnull()==True]=\"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=['a','about','above','after','again','ain','am', 'an','and','any','are','aren','as','at','be','because','been','before','being',\n",
    " 'below','between','both','but','by','d','down','during','for','from','further','had','hadn','has','hasn','have','haven','having',\n",
    "'he','her','here','hers','herself','him','himself','his','how','i','if','in','into','is','isn','it','its','itself','just','ll','m',\n",
    "'ma','me','more','most','my','myself','needn','no','nor','not','now','o','of','off','on','once','only','or','other','our','ours',\n",
    " 'ourselves','out','over','own','re','s','same','shan','she','so','some','such','t','than','that','the','their','theirs','them',\n",
    " 'themselves','then','there','these','they','this','those','through','to','too','under','until','up','ve','very','was','wasn','we',\n",
    " 'were','weren','what','when','where','which','while','who','whom','why','will','with','y','you','your','yours','yourself','yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set('.,!\"#$%&\\'()*+:;<=>?@[\\\\]^_`{|}0123456789')\n",
    "ps=PorterStemmer()\n",
    "lemma=WordNetLemmatizer()\n",
    "def clean(doc,lemmatiz=False,stemming=False):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free_0 =[re.sub(\",|\\.|/\",\" \",ch) for ch in stop_free]\n",
    "    punc_free_lem=\"\".join(ch for ch in punc_free_0 if ch not in exclude)\n",
    "    if lemmatiz==True:\n",
    "        lem=[]\n",
    "        for word,tag in pos_tag(word_tokenize(punc_free_lem)):\n",
    "            wntag=tag[0].lower()\n",
    "            wntag=wntag if wntag in [\"a\",\"r\",\"n\",\"v\"] else None\n",
    "            if not wntag:\n",
    "                lem.append(word)\n",
    "            else:\n",
    "                lem.append(lemma.lemmatize(word,wntag))\n",
    "        normalized=\" \".join(word for word in lem)\n",
    "        return normalized\n",
    "    if stemming==True:\n",
    "        normalized=\" \".join(ps.stem(word) for word in word_tokenize(punc_free_lem))\n",
    "        return normalized\n",
    "    else:\n",
    "        return (\"Choose a cleaning man\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-8674e7add830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Window_Text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstemming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Window_Text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Full_Text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlemmatiz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Full_Text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-108-8674e7add830>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Window_Text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstemming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Window_Text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Full_Text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlemmatiz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Full_Text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-d4887c865443>\u001b[0m in \u001b[0;36mclean\u001b[1;34m(doc, lemmatiz, stemming)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpunc_free_stem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunc_free_0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude_stem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mpunc_free_stem1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\s\\d+\\s'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunc_free_stem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mnormalized\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunc_free_stem1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     return [token for sent in sentences\n\u001b[0m\u001b[0;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[1;32m--> 132\u001b[1;33m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr' \\1 \\2 '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCONTRACTIONS3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr' \\1 \\2 '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m# We are not using CONTRACTIONS4 since\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_all[\"Window_Text\"] = [clean(doc,stemming=True) for doc in data_all[\"Window_Text\"]]\n",
    "data_all[\"Full_Text\"] = [clean(doc,lemmatiz=True) for doc in data_all[\"Full_Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_all.iloc[:len(train)]\n",
    "test = data_all.iloc[len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we will add features from word2vec retrained then get the mean for the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    \"\"\"MySentences is a generator to produce a list of tokenized sentences \n",
    "    \n",
    "    Takes a list of numpy arrays containing documents.\n",
    "    \n",
    "    Args:\n",
    "        arrays: List of arrays, where each element in the array contains a document.\n",
    "    \"\"\"\n",
    "    def __init__(self, *arrays):\n",
    "        self.arrays = arrays\n",
    " \n",
    "    def __iter__(self):\n",
    "        for array in self.arrays:\n",
    "            for document in array:\n",
    "                for sent in nltk.sent_tokenize(document):\n",
    "                    yield nltk.word_tokenize(sent)\n",
    "\n",
    "def get_word2vec(sentences, location,size):\n",
    "    \"\"\"Returns trained word2vec\n",
    "    \n",
    "    Args:\n",
    "        sentences: iterator for sentences\n",
    "        \n",
    "        location (str): Path to save/load word2vec\n",
    "    \"\"\"\n",
    "    if os.path.exists(location):\n",
    "        print('Found {}'.format(location))\n",
    "        model = gensim.models.Word2Vec.load(location)\n",
    "        return model\n",
    "    \n",
    "    print('{} not found. training model'.format(location))\n",
    "    model = gensim.models.Word2Vec(sentences, size=size, window=5, min_count=5, workers=4)\n",
    "    print('Model done training. Saving to disk')\n",
    "    model.save(location)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#It's important to remove duplicated spaces for word2vec learning !\n",
    "train[\"Full_Text\"]=[\" \".join(doc.split()) for doc in train[\"Full_Text\"].values]\n",
    "test[\"Full_Text\"]=[\" \".join(doc.split()) for doc in test[\"Full_Text\"].values]\n",
    "train[\"Window_Text\"]=[\" \".join(doc.split()) for doc in train[\"Window_Text\"].values]\n",
    "test[\"Window_Text\"]=[\" \".join(doc.split()) for doc in test[\"Window_Text\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_w2v=[300] # we know it's 300 from previous runs, no time to gridsearch again and fit weights for lowers \n",
    "w2v={}\n",
    "for size in number_w2v:\n",
    "    w2v[\"w2v_\"+str(size)] = get_word2vec(\n",
    "        MySentences(\n",
    "            train[\"Window_Text\"].values),\"new_stem_w2v_features\"+str(size),size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for document in X:\n",
    "            tokenized_doc = []\n",
    "            for sent in nltk.sent_tokenize(document):\n",
    "                tokenized_doc += nltk.word_tokenize(sent)\n",
    "            transformed_X.append(np.array(tokenized_doc))\n",
    "        return np.array(transformed_X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.wv.syn0[0])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = MyTokenizer().fit_transform(X)\n",
    "        \n",
    "        return np.array([\n",
    "            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_vectorizer={}\n",
    "mean_embedded_train={}\n",
    "mean_embedded_test={}\n",
    "for name in w2v:\n",
    "    mean_embedding_vectorizer[name] = MeanEmbeddingVectorizer(w2v[name])\n",
    "    mean_embedded_train[name] = mean_embedding_vectorizer[name].fit_transform(train['Window_Text'])\n",
    "    mean_embedded_test[name] = mean_embedding_vectorizer[name].fit_transform(test['Window_Text'])\n",
    "df_embed_tr={}\n",
    "df_embed_te={}\n",
    "for name in w2v:\n",
    "    df_embed_tr[name]=pd.DataFrame(mean_embedded_train[name])\n",
    "    df_embed_te[name]=pd.DataFrame(mean_embedded_test[name])\n",
    "train_w2v={}\n",
    "test_w2v={}\n",
    "for name in w2v:\n",
    "    train_w2v[name]=df_embed_tr[name]\n",
    "    test_w2v[name]=df_embed_te[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in w2v:\n",
    "    train_w2v[name].to_csv(\"checkpoints_databases/new_stem_working_train_\"+name+\".csv\",index=False)\n",
    "    test_w2v[name].to_csv(\"checkpoints_databases/new_stem_working_test_\"+name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now TFIDF +300tsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w = TfidfVectorizer(\n",
    "        min_df=3, max_features=8000, strip_accents=None, lowercase = False,\n",
    "        analyzer='word', token_pattern=r'\\w+', ngram_range=(1,3), use_idf=True,\n",
    "        smooth_idf=True, sublinear_tf=True\n",
    "        ).fit(train[\"Window_Text\"])\n",
    "tfidf_f = TfidfVectorizer(\n",
    "        min_df=10, max_features=10000, strip_accents=None, lowercase = False,\n",
    "        analyzer='word', token_pattern=r'\\w+', ngram_range=(1,3), use_idf=True,\n",
    "        smooth_idf=True, sublinear_tf=True\n",
    "        ).fit(train[\"Full_Text\"])\n",
    "\n",
    "X_train_text_w = tfidf_w.transform(train[\"Window_Text\"])\n",
    "X_test_text_w = tfidf_w.transform(test[\"Window_Text\"])\n",
    "X_train_text_f = tfidf_f.transform(train[\"Full_Text\"])\n",
    "X_test_text_f = tfidf_f.transform(test[\"Full_Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_names =tfidf.get_feature_names()\n",
    "#tfidf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a a',\n",
       " 'a assum',\n",
       " 'a assum pathogen',\n",
       " 'a b',\n",
       " 'a c',\n",
       " 'a cell',\n",
       " 'a consist',\n",
       " 'a d',\n",
       " 'a dg',\n",
       " 'a dg ivs',\n",
       " 'a g',\n",
       " 'a g il',\n",
       " 'a g ivs',\n",
       " 'a g rc',\n",
       " 'a gd',\n",
       " 'a gd if',\n",
       " 'a gvgd',\n",
       " 'a ivs',\n",
       " 'a ivs g',\n",
       " 'a ivsg',\n",
       " 'a ivsg a',\n",
       " 'a loop',\n",
       " 'a lp',\n",
       " 'a lp vdel',\n",
       " 'a mr',\n",
       " 'a mutat',\n",
       " 'a p',\n",
       " 'a placeholdermut',\n",
       " 'a pr',\n",
       " 'a pr rh',\n",
       " 'a rc',\n",
       " 'a rc ta',\n",
       " 'a rm',\n",
       " 'a rm g',\n",
       " 'a rq',\n",
       " 'a rq gv',\n",
       " 'a subset',\n",
       " 'a subset class',\n",
       " 'a supplementari',\n",
       " 'a t',\n",
       " 'a t eq',\n",
       " 'a tabl',\n",
       " 'a tabl optionst',\n",
       " 'a ti',\n",
       " 'a ti i',\n",
       " 'a tr',\n",
       " 'a tr ivs',\n",
       " 'a wc',\n",
       " 'a wc ivsa',\n",
       " 'aa',\n",
       " 'aacrjourn',\n",
       " 'aacrjourn org',\n",
       " 'aacrjourn org may',\n",
       " 'aag',\n",
       " 'abbrevi',\n",
       " 'abd',\n",
       " 'aberr',\n",
       " 'abil',\n",
       " 'abil bind',\n",
       " 'abil each',\n",
       " 'abil induc',\n",
       " 'abil induc apoptosi',\n",
       " 'abil placeholdergen',\n",
       " 'abl',\n",
       " 'abl kd',\n",
       " 'abl kd mutat',\n",
       " 'abl transform',\n",
       " 'abnorm',\n",
       " 'abolish',\n",
       " 'abolish transcript',\n",
       " 'abolish transcript activ',\n",
       " 'abov',\n",
       " 'abrog',\n",
       " 'absenc',\n",
       " 'absenc il',\n",
       " 'absenc ligand',\n",
       " 'absenc presenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'abstract',\n",
       " 'abstract introduction',\n",
       " 'abstract introduction results',\n",
       " 'abund',\n",
       " 'ac',\n",
       " 'ac p',\n",
       " 'ac vu',\n",
       " 'ac vu neutral',\n",
       " 'acc',\n",
       " 'accel',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'access codes',\n",
       " 'access codes references',\n",
       " 'access imag',\n",
       " 'access imag plea',\n",
       " 'accommod',\n",
       " 'accompani',\n",
       " 'accord',\n",
       " 'accord manufactur',\n",
       " 'accord manufactur instruct',\n",
       " 'accordingli',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'acet',\n",
       " 'acetyl',\n",
       " 'achiev',\n",
       " 'acid',\n",
       " 'acid chang',\n",
       " 'acid placeholdermut',\n",
       " 'acid posit',\n",
       " 'acid residu',\n",
       " 'acid residu placeholdermut',\n",
       " 'acid sequenc',\n",
       " 'acid substitut',\n",
       " 'acid substitut placeholdermut',\n",
       " 'acknowledgments',\n",
       " 'acknowledgments author',\n",
       " 'acknowledgments author information',\n",
       " 'acquir',\n",
       " 'acquir resist',\n",
       " 'acquisit',\n",
       " 'acral',\n",
       " 'across',\n",
       " 'act',\n",
       " 'act transcript',\n",
       " 'act transcript activ',\n",
       " 'actin',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activ activ',\n",
       " 'activ activ placeholdergen',\n",
       " 'activ against',\n",
       " 'activ akt',\n",
       " 'activ assay',\n",
       " 'activ associ',\n",
       " 'activ brca',\n",
       " 'activ c',\n",
       " 'activ cell',\n",
       " 'activ compar',\n",
       " 'activ conform',\n",
       " 'activ data',\n",
       " 'activ domain',\n",
       " 'activ downstream',\n",
       " 'activ either',\n",
       " 'activ erbb',\n",
       " 'activ erk',\n",
       " 'activ fgfr',\n",
       " 'activ fig',\n",
       " 'activ figur',\n",
       " 'activ flt',\n",
       " 'activ form',\n",
       " 'activ function',\n",
       " 'activ function placeholdergen',\n",
       " 'activ jak',\n",
       " 'activ kina',\n",
       " 'activ level',\n",
       " 'activ loop',\n",
       " 'activ loop mutat',\n",
       " 'activ mapk',\n",
       " 'activ may',\n",
       " 'activ mek',\n",
       " 'activ mtor',\n",
       " 'activ mtorc',\n",
       " 'activ mutant',\n",
       " 'activ mutat',\n",
       " 'activ notch',\n",
       " 'activ observ',\n",
       " 'activ oncogen',\n",
       " 'activ one',\n",
       " 'activ p',\n",
       " 'activ pik',\n",
       " 'activ placeholdergen',\n",
       " 'activ placeholdergen brct',\n",
       " 'activ placeholdergen mutat',\n",
       " 'activ placeholdermut',\n",
       " 'activ placeholdermut mutant',\n",
       " 'activ protein',\n",
       " 'activ pten',\n",
       " 'activ ra',\n",
       " 'activ receptor',\n",
       " 'activ rel',\n",
       " 'activ report',\n",
       " 'activ result',\n",
       " 'activ segment',\n",
       " 'activ signal',\n",
       " 'activ similar',\n",
       " 'activ site',\n",
       " 'activ stat',\n",
       " 'activ state',\n",
       " 'activ structur',\n",
       " 'activ suggest',\n",
       " 'activ thirty',\n",
       " 'activ transcript',\n",
       " 'activ tumor',\n",
       " 'activ two',\n",
       " 'activ variant',\n",
       " 'activ vitro',\n",
       " 'activ vivo',\n",
       " 'activ wherea',\n",
       " 'activ wild',\n",
       " 'activ wild typ',\n",
       " 'activ wt',\n",
       " 'activ yeast',\n",
       " 'actual',\n",
       " 'acut',\n",
       " 'acut lymphoblast',\n",
       " 'acut myeloid',\n",
       " 'acut myeloid leukemia',\n",
       " 'ad',\n",
       " 'ad placeholdermut',\n",
       " 'adapt',\n",
       " 'adc',\n",
       " 'addit',\n",
       " 'addit data',\n",
       " 'addit data obtain',\n",
       " 'addit inform',\n",
       " 'addit mutat',\n",
       " 'addit placeholdermut',\n",
       " 'address',\n",
       " 'adenocarcinoma',\n",
       " 'adenoma',\n",
       " 'adh',\n",
       " 'adjac',\n",
       " 'adjust',\n",
       " 'administr',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adver',\n",
       " 'aee',\n",
       " 'af',\n",
       " 'afatinib',\n",
       " 'affect',\n",
       " 'affect individu',\n",
       " 'affect placeholdermut',\n",
       " 'affect protein',\n",
       " 'affect residu',\n",
       " 'affect splice',\n",
       " 'affect transcript',\n",
       " 'affect transcript activ',\n",
       " 'affect tsc',\n",
       " 'affin',\n",
       " 'ag',\n",
       " 'ag ag',\n",
       " 'ag c',\n",
       " 'ag c g',\n",
       " 'ag ivs',\n",
       " 'ag ivs a',\n",
       " 'ag p',\n",
       " 'ag p eg',\n",
       " 'ag vu',\n",
       " 'ag vu deleteri',\n",
       " 'ag vu neutral',\n",
       " 'against',\n",
       " 'against causal',\n",
       " 'against causal thu',\n",
       " 'against placeholdermut',\n",
       " 'agar',\n",
       " 'agaro',\n",
       " 'age',\n",
       " 'age diagnosi',\n",
       " 'age onset',\n",
       " 'age year',\n",
       " 'agent',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'agil',\n",
       " 'agonist',\n",
       " 'agr',\n",
       " 'agreement',\n",
       " 'agreement differ',\n",
       " 'agreement differ assay',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'ain align',\n",
       " 'ain align vertebr',\n",
       " 'akt',\n",
       " 'akt activ',\n",
       " 'akt akt',\n",
       " 'akt mutant',\n",
       " 'akt phosphoryl',\n",
       " 'akt placeholdermut',\n",
       " 'akt signal',\n",
       " 'al',\n",
       " 'al a',\n",
       " 'al b',\n",
       " 'al c',\n",
       " 'al figur',\n",
       " 'al fm',\n",
       " 'al howev',\n",
       " 'al i',\n",
       " 'al mutat',\n",
       " 'al placeholdermut',\n",
       " 'al use',\n",
       " 'al variant',\n",
       " 'ala',\n",
       " 'alaarg',\n",
       " 'alaarg leudup',\n",
       " 'alanin',\n",
       " 'alav',\n",
       " 'alav alaarg',\n",
       " 'alav alaarg leudup',\n",
       " 'albeit',\n",
       " 'alectinib',\n",
       " 'algorithm',\n",
       " 'align',\n",
       " 'align gvgd',\n",
       " 'align gvgd web',\n",
       " 'align vertebr',\n",
       " 'align vertebr brca',\n",
       " 'alk',\n",
       " 'alk inhibitor',\n",
       " 'alk kina',\n",
       " 'alk mutant',\n",
       " 'alk mutat',\n",
       " 'alk placeholdermut',\n",
       " 'alk placeholdermut mutant',\n",
       " 'alk placeholdermut mutat',\n",
       " 'alk tkd',\n",
       " 'alkat',\n",
       " 'all',\n",
       " 'all assay',\n",
       " 'all avail',\n",
       " 'all brca',\n",
       " 'all brca brca',\n",
       " 'all case',\n",
       " 'all cell',\n",
       " 'all cell line',\n",
       " 'all class',\n",
       " 'all document',\n",
       " 'all document uniqu',\n",
       " 'all four',\n",
       " 'all inform',\n",
       " 'all inform pertain',\n",
       " 'all mutant',\n",
       " 'all mutat',\n",
       " 'all patient',\n",
       " 'all placeholdergen',\n",
       " 'all placeholdermut',\n",
       " 'all remain',\n",
       " 'all remain uniqu',\n",
       " 'all three',\n",
       " 'all tumor',\n",
       " 'all variant',\n",
       " 'all variant odd',\n",
       " 'allel',\n",
       " 'allel frequenc',\n",
       " 'allel loss',\n",
       " 'allele',\n",
       " 'allele specif',\n",
       " 'allele specif loh',\n",
       " 'allost',\n",
       " 'allow',\n",
       " 'allow us',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alpha',\n",
       " 'alreadi',\n",
       " 'also',\n",
       " 'also affect',\n",
       " 'also describ',\n",
       " 'also evalu',\n",
       " 'also found',\n",
       " 'also identifi',\n",
       " 'also includ',\n",
       " 'also observ',\n",
       " 'also possibl',\n",
       " 'also report',\n",
       " 'also show',\n",
       " 'also suggest',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'altern splice',\n",
       " 'although',\n",
       " 'although can',\n",
       " 'although placeholdermut',\n",
       " 'although variant',\n",
       " 'alway',\n",
       " 'american',\n",
       " 'american associ',\n",
       " 'american associ cancer',\n",
       " 'amid',\n",
       " 'amino',\n",
       " 'amino acid',\n",
       " 'amino acid chang',\n",
       " 'amino acid placeholdermut',\n",
       " 'amino acid posit',\n",
       " 'amino acid residu',\n",
       " 'amino acid sequenc',\n",
       " 'amino acid substitut',\n",
       " 'aml',\n",
       " 'aml cell',\n",
       " 'aml patient',\n",
       " 'aml placeholdermut',\n",
       " 'aml sampl',\n",
       " 'among',\n",
       " 'among all',\n",
       " 'among mutat',\n",
       " 'among patient',\n",
       " 'among three',\n",
       " 'amount',\n",
       " 'amplif',\n",
       " 'amplifi',\n",
       " 'amsterdam',\n",
       " 'anali',\n",
       " 'analog',\n",
       " 'analysi',\n",
       " 'analysi base',\n",
       " 'analysi brca',\n",
       " 'analysi brca sequenc',\n",
       " 'analysi class',\n",
       " 'analysi confirm',\n",
       " 'analysi effect',\n",
       " 'analysi identifi',\n",
       " 'analysi mutat',\n",
       " 'analysi perform',\n",
       " 'analysi placeholdergen',\n",
       " 'analysi placeholdermut',\n",
       " 'analysi reveal',\n",
       " 'analysi show',\n",
       " 'analysi use',\n",
       " 'analysi vuss',\n",
       " 'analysi vuss select',\n",
       " 'analyz',\n",
       " 'anaplast',\n",
       " 'anchorage',\n",
       " 'anchorage independ',\n",
       " 'anchorage independ growth',\n",
       " 'and',\n",
       " 'and appendix',\n",
       " 'and appendix tabl',\n",
       " 'androgen',\n",
       " 'anemia',\n",
       " 'anim',\n",
       " 'annot',\n",
       " 'anoth',\n",
       " 'antagonist',\n",
       " 'anti',\n",
       " 'antibodi',\n",
       " 'anticip',\n",
       " 'antigen',\n",
       " 'antisen',\n",
       " 'ap',\n",
       " 'ap cr',\n",
       " 'ap cr gr',\n",
       " 'ap gv',\n",
       " 'ap ta',\n",
       " 'ap ta rw',\n",
       " 'apc',\n",
       " 'apo',\n",
       " 'apoptosi',\n",
       " 'apoptot',\n",
       " 'appar',\n",
       " 'appar discord',\n",
       " 'appear',\n",
       " 'appendix',\n",
       " 'appendix tabl',\n",
       " 'appendix tabl a',\n",
       " 'appli',\n",
       " 'appli retrospect',\n",
       " 'applic',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'approxim',\n",
       " 'ar',\n",
       " 'araf',\n",
       " 'area',\n",
       " 'arg',\n",
       " 'arg placeholdermut',\n",
       " 'argci',\n",
       " 'arggln',\n",
       " 'arginin',\n",
       " 'arginin residu',\n",
       " 'argpro',\n",
       " 'argtrp',\n",
       " 'argu',\n",
       " 'ari',\n",
       " 'arm',\n",
       " 'around',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrow',\n",
       " 'articl',\n",
       " 'artifi',\n",
       " 'artifi cial',\n",
       " 'artifi cial neutral',\n",
       " 'artifici',\n",
       " 'asd',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'ask whether',\n",
       " 'asn',\n",
       " 'asnli',\n",
       " 'asp',\n",
       " 'asparagin',\n",
       " 'aspart',\n",
       " 'aspart acid',\n",
       " 'aspasn',\n",
       " 'aspgli',\n",
       " 'asptyr',\n",
       " 'asptyr thrpro',\n",
       " 'assay',\n",
       " 'assay also',\n",
       " 'assay assess',\n",
       " 'assay assess abil',\n",
       " 'assay assess structur',\n",
       " 'assay base',\n",
       " 'assay data',\n",
       " 'assay fig',\n",
       " 'assay figur',\n",
       " 'assay give',\n",
       " 'assay howev',\n",
       " 'assay howev show',\n",
       " 'assay indic',\n",
       " 'assay perform',\n",
       " 'assay placeholdergen',\n",
       " 'assay placeholdermut',\n",
       " 'assay result',\n",
       " 'assay show',\n",
       " 'assay supplementari',\n",
       " 'assay supplementari tabl',\n",
       " 'assay use',\n",
       " 'assay variant',\n",
       " 'assay wild',\n",
       " 'assembl',\n",
       " 'assess',\n",
       " 'assess abil',\n",
       " 'assess abil each',\n",
       " 'assess cancer',\n",
       " 'assess cancer risk',\n",
       " 'assess clinic',\n",
       " 'assess effect',\n",
       " 'assess structur',\n",
       " 'assess structur function',\n",
       " 'assess whether',\n",
       " 'assign',\n",
       " 'assign class',\n",
       " 'assign class b',\n",
       " 'assign class owe',\n",
       " 'assign each',\n",
       " 'assign risk',\n",
       " 'assign variant',\n",
       " 'assist',\n",
       " 'assist access',\n",
       " 'assist access imag',\n",
       " 'associ',\n",
       " 'associ cancer',\n",
       " 'associ cancer research',\n",
       " 'associ disea',\n",
       " 'associ gene',\n",
       " 'associ hnpcc',\n",
       " 'associ hnpcc cancer',\n",
       " 'associ iarc',\n",
       " 'associ iarc class',\n",
       " 'associ increa',\n",
       " 'associ increa cancer',\n",
       " 'associ loss',\n",
       " 'associ mutant',\n",
       " 'associ mutat',\n",
       " 'associ p',\n",
       " 'associ placeholdergen',\n",
       " 'associ placeholdermut',\n",
       " 'associ spop',\n",
       " 'associ variant',\n",
       " 'assum',\n",
       " 'assum pathogen',\n",
       " 'assum pathogen variant',\n",
       " 'at',\n",
       " 'at placeholdermut',\n",
       " 'at vu',\n",
       " 'at vu neutral',\n",
       " 'ata',\n",
       " 'atg',\n",
       " 'atla',\n",
       " 'atm',\n",
       " 'atom',\n",
       " 'atp',\n",
       " 'atp bind',\n",
       " 'atp bind pocket',\n",
       " 'atp competit',\n",
       " 'atpa',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attenu',\n",
       " 'attribut',\n",
       " 'augment',\n",
       " 'author',\n",
       " 'author information',\n",
       " 'author information supplementari',\n",
       " 'author manuscript',\n",
       " 'author manuscript author',\n",
       " 'author manuscript nih',\n",
       " 'autism',\n",
       " 'auto',\n",
       " 'auto phosphoryl',\n",
       " 'autoinhibit',\n",
       " 'autoinhibitori',\n",
       " 'autophosphoryl',\n",
       " 'av',\n",
       " 'av ga',\n",
       " 'av placeholdermut',\n",
       " 'av vd',\n",
       " 'av vd ivsg',\n",
       " 'avail',\n",
       " 'avail align',\n",
       " 'avail align gvgd',\n",
       " 'avail clinic',\n",
       " 'avail mutat',\n",
       " 'averag',\n",
       " 'away',\n",
       " 'awd',\n",
       " 'azd',\n",
       " 'aα',\n",
       " 'b',\n",
       " 'b all',\n",
       " 'b b',\n",
       " 'b c',\n",
       " 'b cell',\n",
       " 'b contrast',\n",
       " 'b d',\n",
       " 'b figur',\n",
       " 'b mt',\n",
       " 'b mutat',\n",
       " 'b placeholdermut',\n",
       " 'b raf',\n",
       " 'b supplementari',\n",
       " 'b variant',\n",
       " 'ba',\n",
       " 'ba approach',\n",
       " 'ba assay',\n",
       " 'ba data',\n",
       " 'ba f',\n",
       " 'ba f cell',\n",
       " 'ba f kit',\n",
       " 'bach',\n",
       " 'backbon',\n",
       " 'background',\n",
       " 'bacteri',\n",
       " 'baf',\n",
       " 'baf cell',\n",
       " 'baf cell express',\n",
       " 'bamhi',\n",
       " 'bamhi hindiii',\n",
       " 'bamhi hindiii site',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'bap',\n",
       " 'bar',\n",
       " 'bard',\n",
       " 'bard e',\n",
       " 'basal',\n",
       " 'basal activ',\n",
       " 'base',\n",
       " 'base cisplatin',\n",
       " 'base cisplatin respon',\n",
       " 'base pair',\n",
       " 'baselin',\n",
       " 'basi',\n",
       " 'basi dna',\n",
       " 'basi dna sequenc',\n",
       " 'basi mutat',\n",
       " 'basi mutat type',\n",
       " 'basi observ',\n",
       " 'basi observ variant',\n",
       " 'basic',\n",
       " 'bax',\n",
       " 'bay',\n",
       " 'bc',\n",
       " 'bc oc',\n",
       " 'bcc',\n",
       " 'bcl',\n",
       " 'bcl xl',\n",
       " 'bcr',\n",
       " 'bcr abl',\n",
       " 'bcr abl kd',\n",
       " 'bead',\n",
       " 'bear',\n",
       " 'becom',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'believ',\n",
       " 'belong',\n",
       " 'benefit',\n",
       " 'benign',\n",
       " 'benign c',\n",
       " 'benign c toler',\n",
       " 'benign intol',\n",
       " 'benign intol deleteri',\n",
       " 'benign polymorph',\n",
       " 'benign toler',\n",
       " 'benign toler nondeleteri',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'bia',\n",
       " 'biallel',\n",
       " 'bic',\n",
       " 'bilat',\n",
       " 'bind',\n",
       " 'bind activ',\n",
       " 'bind activ wild',\n",
       " 'bind affin',\n",
       " 'bind assay',\n",
       " 'bind cdk',\n",
       " 'bind dna',\n",
       " 'bind domain',\n",
       " 'bind domain dbd',\n",
       " 'bind e',\n",
       " 'bind p',\n",
       " 'bind placeholdermut',\n",
       " 'bind pocket',\n",
       " 'bind protein',\n",
       " 'bind region',\n",
       " 'bind site',\n",
       " 'bind specif',\n",
       " 'bind surfac',\n",
       " 'bind transcript',\n",
       " 'bind transcript activ',\n",
       " 'bind wild',\n",
       " 'biochem',\n",
       " 'biochem properti',\n",
       " 'bioinformat',\n",
       " 'bioinformat analysi',\n",
       " 'biolog',\n",
       " 'biopsi',\n",
       " 'biotinyl',\n",
       " 'birth',\n",
       " 'black',\n",
       " 'bladder',\n",
       " 'bladder cancer',\n",
       " 'blast',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blosum',\n",
       " 'blot',\n",
       " 'blot analysi',\n",
       " 'blue',\n",
       " 'bm',\n",
       " 'bm cell',\n",
       " 'bmp',\n",
       " 'bodi',\n",
       " 'bond',\n",
       " 'bond network',\n",
       " 'bond s',\n",
       " 'bond salt',\n",
       " 'bond salt bridg',\n",
       " 'bone',\n",
       " 'bone dysplasia',\n",
       " 'bone marrow',\n",
       " 'bone marrow cell',\n",
       " 'bottom',\n",
       " 'bound',\n",
       " 'bovin',\n",
       " 'box',\n",
       " 'bp',\n",
       " 'bpw',\n",
       " 'br',\n",
       " 'braf',\n",
       " 'braf inhibitor',\n",
       " 'braf mut',\n",
       " 'braf mutant',\n",
       " 'braf mutat',\n",
       " 'braf nra',\n",
       " 'braf placeholdermut',\n",
       " 'braf placeholdermut mutat',\n",
       " 'braf ve',\n",
       " 'braf wild',\n",
       " 'braf wild typ',\n",
       " 'brafv',\n",
       " 'brain',\n",
       " 'brake',\n",
       " 'brca',\n",
       " 'brca brca',\n",
       " 'brca brca estim',\n",
       " 'brca brca mv',\n",
       " 'brca brca sequenc',\n",
       " 'brca brca variant',\n",
       " 'brca brct',\n",
       " 'brca brct domain',\n",
       " 'brca c',\n",
       " 'brca estim',\n",
       " 'brca estim proport',\n",
       " 'brca figur',\n",
       " 'brca ivs',\n",
       " 'brca kn',\n",
       " 'brca kn rh',\n",
       " 'brca missen',\n",
       " 'brca mutat',\n",
       " 'brca mv',\n",
       " 'brca mv ifdi',\n",
       " 'brca placeholdergen',\n",
       " 'brca placeholdermut',\n",
       " 'brca protein',\n",
       " 'brca rk',\n",
       " 'brca rk g',\n",
       " 'brca sequenc',\n",
       " 'brca sequenc avail',\n",
       " 'brca sequenc variant',\n",
       " 'brca sequenc vuss',\n",
       " 'brca variant',\n",
       " 'brca vu',\n",
       " 'brca vu base',\n",
       " 'brca vu pathogen',\n",
       " 'brcae',\n",
       " 'brcae interact',\n",
       " 'brct',\n",
       " 'brct c',\n",
       " 'brct dbd',\n",
       " 'brct dbd mv',\n",
       " 'brct domain',\n",
       " 'brct domain brca',\n",
       " 'brct domain placeholdergen',\n",
       " 'brct fold',\n",
       " 'brct locat',\n",
       " 'brct locat outsid',\n",
       " 'brct missen',\n",
       " 'brct missen variant',\n",
       " 'brct mutant',\n",
       " 'brct n',\n",
       " 'brct repeat',\n",
       " 'brct repeat region',\n",
       " 'brct variant',\n",
       " 'brct variant set',\n",
       " 'break',\n",
       " 'breast',\n",
       " 'breast cancer',\n",
       " 'breast cancer cell',\n",
       " 'breast cancer inform',\n",
       " 'breast cancer patient',\n",
       " 'breast ovarian',\n",
       " 'breast ovarian cancer',\n",
       " 'breast tumor',\n",
       " 'bridg',\n",
       " 'briefli',\n",
       " 'broad',\n",
       " 'buffer',\n",
       " 'bulki',\n",
       " 'bundl',\n",
       " 'buri',\n",
       " 'buri hydrophob',\n",
       " 'buri hydrophob group',\n",
       " 'buri posit',\n",
       " 'buri residu',\n",
       " 'buri residu like',\n",
       " 'c',\n",
       " 'c a',\n",
       " 'c a pr',\n",
       " 'c ac',\n",
       " 'c ac p',\n",
       " 'c ac vu',\n",
       " 'c ag',\n",
       " 'c ag c',\n",
       " 'c ag p',\n",
       " 'c ag vu',\n",
       " 'c all',\n",
       " 'c at',\n",
       " 'c at vu',\n",
       " 'c brca',\n",
       " 'c brca rk',\n",
       " 'c c',\n",
       " 'c c c',\n",
       " 'c ca',\n",
       " 'c ca p',\n",
       " 'c ca vu',\n",
       " 'c cbl',\n",
       " 'c cell',\n",
       " 'c cg',\n",
       " 'c cg p',\n",
       " 'c cg vu',\n",
       " 'c class',\n",
       " 'c ct',\n",
       " 'c ct p',\n",
       " 'c ct vu',\n",
       " 'c d',\n",
       " 'c del',\n",
       " 'c del p',\n",
       " 'c delag',\n",
       " 'c deleteri',\n",
       " 'c deleteri deleteri',\n",
       " 'c deleteri toler',\n",
       " 'c domain',\n",
       " 'c e',\n",
       " 'c fig',\n",
       " 'c figur',\n",
       " 'c g',\n",
       " 'c g ci',\n",
       " 'c g di',\n",
       " 'c g ivs',\n",
       " 'c g ivsg',\n",
       " 'c ga',\n",
       " 'c ga p',\n",
       " 'c ga vu',\n",
       " 'c gc',\n",
       " 'c gc c',\n",
       " 'c gc p',\n",
       " 'c gc vu',\n",
       " 'c gt',\n",
       " 'c gt p',\n",
       " 'c gt vu',\n",
       " 'c iv',\n",
       " 'c iv qh',\n",
       " 'c kit',\n",
       " 'c lane',\n",
       " 'c mr',\n",
       " 'c mr sr',\n",
       " 'c myc',\n",
       " 'c p',\n",
       " 'c placeholdermut',\n",
       " 'c qe',\n",
       " 'c qe pl',\n",
       " 'c r',\n",
       " 'c raf',\n",
       " 'c rh',\n",
       " 'c rh g',\n",
       " 'c t',\n",
       " 'c t ag',\n",
       " 'c t gr',\n",
       " 'c t nk',\n",
       " 'c ta',\n",
       " 'c ta p',\n",
       " 'c ta vu',\n",
       " 'c tc',\n",
       " 'c tc p',\n",
       " 'c tc vu',\n",
       " 'c termin',\n",
       " 'c termin region',\n",
       " 'c terminu',\n",
       " 'c tg',\n",
       " 'c tg artifi',\n",
       " 'c tg p',\n",
       " 'c tg vu',\n",
       " 'c toler',\n",
       " 'c toler toler',\n",
       " 'c variant',\n",
       " 'c vi',\n",
       " 'c vi ivs',\n",
       " 'ca',\n",
       " 'ca p',\n",
       " 'ca usa',\n",
       " 'ca vu',\n",
       " 'ca vu neutral',\n",
       " 'cag',\n",
       " 'calcium',\n",
       " 'calcul',\n",
       " 'calcul odd',\n",
       " 'calibr',\n",
       " 'call',\n",
       " 'calorimetri',\n",
       " 'can',\n",
       " 'can also',\n",
       " 'can rule',\n",
       " 'can rule possibl',\n",
       " 'can use',\n",
       " 'cancer',\n",
       " 'cancer associ',\n",
       " 'cancer associ iarc',\n",
       " 'cancer associ mutant',\n",
       " 'cancer associ mutat',\n",
       " 'cancer case',\n",
       " 'cancer cell',\n",
       " 'cancer cell line',\n",
       " 'cancer discoveri',\n",
       " 'cancer discoveri function',\n",
       " 'cancer famili',\n",
       " 'cancer gene',\n",
       " 'cancer genom',\n",
       " 'cancer genom atla',\n",
       " 'cancer includ',\n",
       " 'cancer inform',\n",
       " 'cancer inform core',\n",
       " 'cancer mutant',\n",
       " 'cancer mutat',\n",
       " 'cancer patient',\n",
       " 'cancer predisposit',\n",
       " 'cancer research',\n",
       " 'cancer risk',\n",
       " 'cancer risk assess',\n",
       " 'cancer risk class',\n",
       " 'cancer sequenc',\n",
       " 'cancer suscept',\n",
       " 'cancer suscept gene',\n",
       " 'cancer tabl',\n",
       " 'cancer type',\n",
       " 'cancer use',\n",
       " 'cancerdiscoveri',\n",
       " 'cancerdiscoveri aacrjourn',\n",
       " 'cancerdiscoveri aacrjourn org',\n",
       " 'candid',\n",
       " 'canon',\n",
       " 'canon splice',\n",
       " 'canon splice sit',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_w.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#same did thousands of time gridsearchs, perfect is 100 for our cases\n",
    "dic_svd=TruncatedSVD(n_components=100,n_iter=25,random_state=26)\n",
    "\n",
    "tsvd_train_w=dic_svd.fit_transform(X_train_text_w)\n",
    "tsvd_test_w=dic_svd.transform(X_test_text_w)\n",
    "tsvd_train_f=dic_svd.fit_transform(X_train_text_f)\n",
    "tsvd_test_f=dic_svd.transform(X_test_text_f)\n",
    "X_train_w=pd.DataFrame()\n",
    "X_test_w=pd.DataFrame()\n",
    "X_train_f=pd.DataFrame()\n",
    "X_test_f=pd.DataFrame()\n",
    "for i in range(int(100)):\n",
    "    X_train_w['window_' +\"tfidf_\"+str(i)] = tsvd_train_w[:, i]\n",
    "    X_test_w['window_' +\"tfidf_\"+str(i)] = tsvd_test_w[:, i]\n",
    "    X_train_f['full_' +\"tfidf_\"+str(i)] = tsvd_train_f[:, i]\n",
    "    X_test_f['full_' +\"tfidf_\"+str(i)] = tsvd_test_f[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wind=X_train_w\n",
    "X_train_full=X_train_f\n",
    "X_test_wind=X_test_w\n",
    "X_test_full=X_test_f\n",
    "dic_train={}\n",
    "dic_test={}\n",
    "dic_train[\"wind_tfidf_100\"]=X_train_wind\n",
    "dic_test[\"wind_tfidf_100\"]=X_test_wind\n",
    "dic_train[\"full_tfidf_100\"]=X_train_full\n",
    "dic_test[\"full_tfidf_100\"]=X_test_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in dic_train:\n",
    "    dic_train[name].to_csv(\"checkpoints_databases/new_stem_working_train_\"+name+\".csv\",index=False)\n",
    "    dic_test[name].to_csv(\"checkpoints_databases/new_stem_working_test_\"+name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add w2v bio for lemma on FULL text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_bio = KeyedVectors.load_word2vec_format(\"../bases/PMC-w2v.bin\",binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_vec={}\n",
    "me_train={}\n",
    "me_test={}\n",
    "me_vec = MeanEmbeddingVectorizer(w2v_bio)\n",
    "me_train = me_vec.fit_transform(train['Full_Text'])\n",
    "me_test = me_vec.fit_transform(test['Full_Text'])\n",
    "df_bio_tr=pd.DataFrame(me_train)\n",
    "df_bio_te=pd.DataFrame(me_test)\n",
    "\n",
    "train_w2v_bio=df_bio_tr\n",
    "test_w2v_bio=df_bio_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v_bio.to_csv(\"checkpoints_databases/new_working_train_bio.csv\",index=False)\n",
    "test_w2v_bio.to_csv(\"checkpoints_databases/new_working_test_bio.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
