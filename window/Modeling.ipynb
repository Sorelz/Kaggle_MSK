{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work_train = {} \n",
    "work_test = {}\n",
    "pre_process=[\"w2v.npz\",\"d2v.npz\",\"tfidf.npz\"]\n",
    "path=\"bases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"bases/training_variants\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('bases/training_variants')\n",
    "test = pd.read_csv('bases/test_variants')\n",
    "ID_train=train.ID\n",
    "ID_test=test.ID\n",
    "del train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_gen(X,X_test,y,classifier,file,five_fold_predict=True):\n",
    "    #if not os.path.exists(\"scores/\"+file):\n",
    "    #   os.makedirs(\"scores/\"+file)\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)\n",
    "    if five_fold_predict:\n",
    "        fold = 0\n",
    "        y_test=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "            fold += 1\n",
    "\n",
    "            X_train, X_valid    = X[train_index],   X[test_index]\n",
    "            y_train, y_valid    = y[train_index],   y[test_index]\n",
    "\n",
    "            print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "\n",
    "            clf=classifier\n",
    "            clf.fit(X_train,y_train)\n",
    "            p_test = clf.predict_proba(X_test)\n",
    "            y_test += p_test/5\n",
    "    else:\n",
    "        print(\"One Fold predict\")\n",
    "        clf=classifier\n",
    "        clf.fit(X,y)\n",
    "        y_test=clf.predict_proba(X_test)\n",
    "        print(\"One Fold done\")\n",
    "    classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "    subm = pd.DataFrame(y_test, columns=classes)\n",
    "    subm['ID'] = ID_test\n",
    "    \n",
    "    subm.to_csv(\"scores/stack_test/{}.csv\".format(file),index=False)\n",
    "    \n",
    "    print(\"cross_val sur train \") #peut etre que to array est exclusivement pour les xgb\n",
    "    \n",
    "    if os.path.isfile(\"scores/stack_train/{}.csv\".format(file)):\n",
    "        print(\"not necessary, already done\")\n",
    "    else:\n",
    "        y_pred=cross_val_predict(estimator=clf,X=X,y=y,cv=kf,method=\"predict_proba\") \n",
    "        print(cross_val_score(clf,X,y,scoring=\"neg_log_loss\",cv=kf).mean)\n",
    "        subm1 = pd.DataFrame(y_pred, columns=classes)\n",
    "        subm1['ID'] = ID_train\n",
    "        subm1.to_csv(\"scores/stack_train/{}.csv\".format(file),index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Models of XGBOOST for each pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_xgb={\"XGB_M\":XGBClassifier(max_depth=5, objective=\"multi:softprob\",subsample=0.7,seed=26),\n",
    "    \"XGB_S\":XGBClassifier(max_depth=2,objective=\"multi:softprob\",subsample=0.5,seed=26),\n",
    "                   \"XGB_T\":XGBClassifier(max_depth=7,subsample=0.9,objective=\"multi:softprob\",seed=26)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for name in work_train:\n",
    "#   for clf in clf_xgb:\n",
    "#       model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_xgb[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 Models of LGBM for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_lgbm={\"LGBM_S\" : LGBMClassifier(num_leaves=25,bagging_fraction=0.6,\n",
    "feature_fraction=0.6,application=\"multiclass\",num_class=9),\n",
    "\"LGBM_M\" : LGBMClassifier(num_leaves=40,bagging_fraction=0.8,feature_fraction=0.8,\n",
    "        application=\"multiclass\",num_class=9),\n",
    "\"LGBM_T\" : LGBMClassifier(num_leaves=70,num_iterations=150,\n",
    "        application=\"multiclass\",num_class=9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for name in work_train:\n",
    "#    for clf in clf_lgbm:\n",
    "#        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_lgbm[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clf_ada={\"adaboost\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_ada:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_ada[clf],file=clf+\"_\"+name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 logistic reg p√©n L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_logit={\"logit\":LogisticRegression(penalty=\"l2\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_logit:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_logit[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1-Nearest Neighbors (because class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_knn={\"knn\":KNeighborsClassifier(n_neighbors=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_knn:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_knn[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
