{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train = {} \n",
    "work_test = {}\n",
    "pre_process=[\"w2v.npz\",\"d2v.npz\",\"tfidf.npz\"]\n",
    "path=\"bases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"bases/training_variants\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3321x365 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1175251 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_train[\"d2v\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Models of XGBOOST for each pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_xgb={\"XGB_M\":XGBClassifier(max_depth=5, objective=\"multi:softprob\",subsample=0.7,seed=26),\n",
    "    \"XGB_S\":XGBClassifier(max_depth=2,objective=\"multi:softprob\",subsample=0.5,seed=26),\n",
    "                   \"XGB_T\":XGBClassifier(max_depth=7,subsample=0.9,objective=\"multi:softprob\",seed=26)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('bases/training_variants')\n",
    "test = pd.read_csv('bases/test_variants')\n",
    "ID_train=train.ID\n",
    "ID_test=test.ID\n",
    "del train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_gen(X,X_test,y,classifier,file,five_fold_predict=True):\n",
    "    #if not os.path.exists(\"scores/\"+file):\n",
    "    #   os.makedirs(\"scores/\"+file)\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)\n",
    "    if five_fold_predict:\n",
    "        fold = 0\n",
    "        y_test=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "            fold += 1\n",
    "\n",
    "            X_train, X_valid    = X[train_index],   X[test_index]\n",
    "            y_train, y_valid    = y[train_index],   y[test_index]\n",
    "\n",
    "            print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "\n",
    "            clf=classifier\n",
    "            clf.fit(X_train,y_train)\n",
    "            p_test = clf.predict_proba(X_test)\n",
    "            y_test += p_test/5\n",
    "    else:\n",
    "        print(\"One Fold predict\")\n",
    "        clf=classifier\n",
    "        clf.fit(X,y)\n",
    "        y_test=clf.predict_proba(X_test)\n",
    "        print(\"One Fold done\")\n",
    "    classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "    subm = pd.DataFrame(y_test, columns=classes)\n",
    "    subm['ID'] = ID_test\n",
    "    \n",
    "    subm.to_csv(\"scores/stack_test/{}.csv\".format(file),index=False)\n",
    "    \n",
    "    print(\"cross_val sur train \") #peut etre que to array est exclusivement pour les xgb\n",
    "    \n",
    "    if os.path.isfile(\"scores/stack_train/{}.csv\".format(file)):\n",
    "        print(\"not necessary, already done\")\n",
    "    else:\n",
    "        y_pred=cross_val_predict(estimator=clf,X=X,y=y,cv=kf,method=\"predict_proba\") \n",
    "        subm1 = pd.DataFrame(y_pred, columns=classes)\n",
    "        subm1['ID'] = ID_train\n",
    "        subm1.to_csv(\"scores/stack_train/{}.csv\".format(file),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_xgb:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_xgb[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 Models of LGBM for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_lgbm={\"LGBM_S\" : LGBMClassifier(num_leaves=25,bagging_fraction=0.6,\n",
    "feature_fraction=0.6,application=\"multiclass\",num_class=9),\n",
    "\"LGBM_M\" : LGBMClassifier(num_leaves=40,bagging_fraction=0.8,feature_fraction=0.8,\n",
    "        application=\"multiclass\",num_class=9),\n",
    "\"LGBM_T\" : LGBMClassifier(num_leaves=70,num_iterations=150,\n",
    "        application=\"multiclass\",num_class=9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LGBM_S'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0f2ecd63903b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwork_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_lgbm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwork_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwork_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf_xgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'LGBM_S'"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_lgbm:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_lgbm[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d2v': <3321x365 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1175251 stored elements in Compressed Sparse Column format>,\n",
       " 'tfidf': <3321x10015 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2578067 stored elements in Compressed Sparse Column format>,\n",
       " 'w2v': <3321x115 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 345001 stored elements in Compressed Sparse Column format>}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 SVM for each, because it's expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_svm={\"svm_lin\":svm.SVC(kernel=\"linear\",probability=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Fold predict\n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_svm:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_svm[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 logistic reg p√©n L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_logit={\"logit\":LogisticRegression(penalty=\"l2\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Fold predict\n",
      "One Fold done\n",
      "cross_val sur train \n",
      "One Fold predict\n",
      "One Fold done\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_logit:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_logit[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1-Nearest Neighbors (because class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_knn={\"1\":KNeighborsClassifier(n_neighbors=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_knn:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_knn[clf],file=clf+\"_\"+name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
