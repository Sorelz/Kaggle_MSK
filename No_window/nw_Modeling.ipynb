{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LF/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work_train = {} \n",
    "work_test = {}\n",
    "pre_process=[\"w2v.npz\",\"d2v.npz\",\"tfidf.npz\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"nw_working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"..//bases/training_variants\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('..//bases/training_variants')\n",
    "test = pd.read_csv('..//bases/test_variants')\n",
    "ID_train=train.ID  \n",
    "ID_test=test.ID   \n",
    "del train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_gen(X,X_test,y,classifier,file,five_fold_predict=True):\n",
    "    #if not os.path.exists(\"scores/\"+file):\n",
    "    #   os.makedirs(\"scores/\"+file)\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)\n",
    "    if five_fold_predict:\n",
    "        fold = 0\n",
    "        y_test=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "            fold += 1\n",
    "\n",
    "            X_train, X_valid    = X[train_index],   X[test_index]\n",
    "            y_train, y_valid    = y[train_index],   y[test_index]\n",
    "\n",
    "            print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "\n",
    "            clf=classifier\n",
    "            clf.fit(X_train,y_train)\n",
    "            p_test = clf.predict_proba(X_test)\n",
    "            y_test += p_test/5\n",
    "    else:\n",
    "        print(\"One Fold predict\")\n",
    "        clf=classifier\n",
    "        clf.fit(X,y)\n",
    "        y_test=clf.predict_proba(X_test)\n",
    "        print(\"One Fold done\")\n",
    "    classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "    subm = pd.DataFrame(y_test, columns=classes)\n",
    "    subm['ID'] = ID_test\n",
    "    \n",
    "    subm.to_csv(\"nw_scores/nw_stack_test/nw_{}.csv\".format(file),index=False)\n",
    "    \n",
    "    print(\"cross_val sur train \") #peut etre que to array est exclusivement pour les xgb\n",
    "    \n",
    "    if os.path.isfile(\"nw_scores/nw_stack_train/nw_{}.csv\".format(file)):\n",
    "        print(\"not necessary, already done\")\n",
    "    else:\n",
    "        y_pred=cross_val_predict(estimator=clf,X=X,y=y,cv=kf,method=\"predict_proba\") \n",
    "        print(cross_val_score(clf,X,y,scoring=\"neg_log_loss\",cv=kf).mean)\n",
    "        subm1 = pd.DataFrame(y_pred, columns=classes)\n",
    "        subm1['ID'] = ID_train\n",
    "        subm1.to_csv(\"nw_scores/nw_stack_train/nw_{}.csv\".format(file),index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Models of XGBOOST for each pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_xgb={\"XGB_M\":XGBClassifier(max_depth=5, objective=\"multi:softprob\",subsample=0.7,seed=26),\n",
    "    \"XGB_S\":XGBClassifier(max_depth=2,objective=\"multi:softprob\",subsample=0.5,seed=26),\n",
    "                   \"XGB_T\":XGBClassifier(max_depth=7,subsample=0.9,objective=\"multi:softprob\",seed=26)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for name in work_train:\n",
    "#   for clf in clf_xgb:\n",
    "#       model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_xgb[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 Models of LGBM for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_lgbm={\"LGBM_S\" : LGBMClassifier(num_leaves=25,bagging_fraction=0.6,\n",
    "feature_fraction=0.6,application=\"multiclass\",num_class=9),\n",
    "\"LGBM_M\" : LGBMClassifier(num_leaves=40,bagging_fraction=0.8,feature_fraction=0.8,\n",
    "        application=\"multiclass\",num_class=9),\n",
    "\"LGBM_T\" : LGBMClassifier(num_leaves=70,num_iterations=150,\n",
    "        application=\"multiclass\",num_class=9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for name in work_train:\n",
    "#    for clf in clf_lgbm:\n",
    "#        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_lgbm[clf],file=clf+\"_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_ada={\"adaboost\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=None)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_ada:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_ada[clf],file=clf+\"_\"+name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 logistic reg p√©n L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_logit={\"logit\":LogisticRegression(penalty=\"l2\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 115) (668, 115)\n",
      "Fold 2 (2654, 115) (667, 115)\n",
      "Fold 3 (2657, 115) (664, 115)\n",
      "Fold 4 (2659, 115) (662, 115)\n",
      "Fold 5 (2661, 115) (660, 115)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 365) (668, 365)\n",
      "Fold 2 (2654, 365) (667, 365)\n",
      "Fold 3 (2657, 365) (664, 365)\n",
      "Fold 4 (2659, 365) (662, 365)\n",
      "Fold 5 (2661, 365) (660, 365)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10015) (668, 10015)\n",
      "Fold 2 (2654, 10015) (667, 10015)\n",
      "Fold 3 (2657, 10015) (664, 10015)\n",
      "Fold 4 (2659, 10015) (662, 10015)\n",
      "Fold 5 (2661, 10015) (660, 10015)\n",
      "cross_val sur train \n"
     ]
    }
   ],
   "source": [
    "for name in work_train:\n",
    "    for clf in clf_logit:\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=clf_logit[clf],file=clf+\"_\"+name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
