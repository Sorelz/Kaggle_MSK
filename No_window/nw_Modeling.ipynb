{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import os \n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train = {} \n",
    "work_test = {}\n",
    "pre_process=[\"d2v.npz\",\"tfidf.npz\",\"w2v.npz\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"nw_working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.npz\",\"\",f)] = ssp.load_npz(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2v\n",
      "tfidf\n",
      "w2v\n"
     ]
    }
   ],
   "source": [
    "for a in work_train:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"..//bases/training_variants\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('..//bases/training_variants')\n",
    "test = pd.read_csv('..//bases/test_variants')\n",
    "ID_train=train.ID\n",
    "ID_test=test.ID\n",
    "del train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH PHASE ALL ALGOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb=XGBClassifier(max_depth=3, objective=\"multi:softprob\",seed=26)\n",
    "param_test= {\n",
    "    \"max_depth\" : [3,5,7],\n",
    "    \"min_child_weight\" : [1,3],\n",
    "    \"n_estimators\" : [100,200],\n",
    "    \"subsample\":[0.8,1],\n",
    "    \"colsample_bytree\":[0.8,1]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_xgb, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=3,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgbm=LGBMClassifier(seed=26)\n",
    "param_test= {\n",
    "    'n_estimators': [8,24,48],\n",
    "    'num_leaves': [6,12,16,22],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'colsample_bytree' : [0.7 0.8],\n",
    "    'subsample' : [0.7,0.8]\n",
    "    }\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_lgbm, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=3,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log=LogisticRegression()\n",
    "param_test= {\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    \"penalty\" : [\"l1\",\"l2\"]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_log, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=3,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ada=AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26)\n",
    "param_test={\n",
    "    \"n_estimators\":[50,100],\n",
    "    \"learning_rate\":[0.3,0.5,0.9,1]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_ada, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=3,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt=RandomForestClassifier()\n",
    "param_test={\n",
    "    \"max_depth\":[5,7,10,15],\n",
    "    \"n_estimators\":[100,200,300]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_dt, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=3,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING PHASE ALL ALGOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gen(X,X_test,y,classifier,file,five_fold_predict=True):\n",
    "    #if not os.path.exists(\"scores/\"+file):\n",
    "    #   os.makedirs(\"scores/\"+file)\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)\n",
    "    if five_fold_predict:\n",
    "        fold = 0\n",
    "        y_test=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "            fold += 1\n",
    "\n",
    "            X_train, X_valid    = X[train_index],   X[test_index]\n",
    "            y_train, y_valid    = y[train_index],   y[test_index]\n",
    "\n",
    "            print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "\n",
    "            clf=classifier\n",
    "            clf.fit(X_train,y_train)\n",
    "            p_test = clf.predict_proba(X_test)\n",
    "            y_test += p_test/5\n",
    "\n",
    "    classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "    subm = pd.DataFrame(y_test, columns=classes)\n",
    "    subm['ID'] = ID_test\n",
    "    \n",
    "    subm.to_csv(\"nw_scores/nw_stack_test/nw_{}.csv\".format(file),index=False)\n",
    "    \n",
    "    print(\"cross_val sur train \") #peut etre que to array est exclusivement pour les xgb\n",
    "    \n",
    "    if os.path.isfile(\"nw_scores/nw_stack_train/nw_{}.csv\".format(file)):\n",
    "        print(\"not necessary, already done\")\n",
    "    else:\n",
    "        y_pred=cross_val_predict(estimator=clf,X=X,y=y,cv=kf,method=\"predict_proba\")\n",
    "        subm1 = pd.DataFrame(y_pred, columns=classes)\n",
    "        subm1['ID'] = ID_train\n",
    "        subm1.to_csv(\"nw_scores/nw_stack_train/nw_{}.csv\".format(file),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost here\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)"
     ]
    }
   ],
   "source": [
    "print(\"xgboost here\")\n",
    "for clf,name in zip(dic_xgb.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_xgb[clf],file=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n",
      "Fold 4 (2659, 379) (662, 379)\n",
      "Fold 5 (2661, 379) (660, 379)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 629) (668, 629)\n",
      "Fold 2 (2654, 629) (667, 629)\n",
      "Fold 3 (2657, 629) (664, 629)\n",
      "Fold 4 (2659, 629) (662, 629)\n",
      "Fold 5 (2661, 629) (660, 629)\n",
      "cross_val sur train \n",
      "Fold 1 (2653, 10279) (668, 10279)\n",
      "Fold 2 (2654, 10279) (667, 10279)\n",
      "Fold 3 (2657, 10279) (664, 10279)\n",
      "Fold 4 (2659, 10279) (662, 10279)\n",
      "Fold 5 (2661, 10279) (660, 10279)\n",
      "cross_val sur train \n",
      "not necessary, already done\n",
      "Fold 1 (2653, 379) (668, 379)\n",
      "Fold 2 (2654, 379) (667, 379)\n",
      "Fold 3 (2657, 379) (664, 379)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-13ba193b5173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdic_rf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwork_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mmodel_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwork_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwork_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdic_rf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-20f4c2de8655>\u001b[0m in \u001b[0;36mmodel_gen\u001b[1;34m(X, X_test, y, classifier, file, five_fold_predict)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mp_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0my_test\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mp_test\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 326\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dic_xgb={\"xgb_d2v\":XGBClassifier(max_depth=3,objective=\"multi:softprob\",seed=26),\n",
    "        \"xgb_tfidf\":XGBClassifier(max_depth=3,objective=\"multi:softprob\",seed=26),\n",
    "        \"xgb_w2v\":XGBClassifier(max_depth=3,objective=\"multi:softprob\",seed=26)}\n",
    "dic_lgbm={\"lgbm_d2v\":LGBMClassifier(seed=26),\n",
    "        \"lgbm_tfidf\":LGBMClassifier(seed=26),\n",
    "        \"lgbm_w2v\":LGBMClassifier(seed=26)}\n",
    "dic_lr={\"lr_d2v\":LogisticRegression(),\n",
    "        \"lr_tfidf\":LogisticRegression(),\n",
    "        \"lr_w2v\":LogisticRegression()}\n",
    "dic_ada={\"ada_d2v\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26),\n",
    "        \"ada_tfidf\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26),\n",
    "        \"ada_w2v\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26)}\n",
    "dic_rf={\"rf_d2v\":RandomForestClassifier(n_estimators=200,max_depth=10,random_state=26),\n",
    "        \"rf_tfidf\":RandomForestClassifier(n_estimators=200,max_depth=10,random_state=26),\n",
    "        \"rf_w2v\":RandomForestClassifier(n_estimators=200,max_depth=10,random_state=26)}\n",
    "\n",
    "print(\"xgboost here\")\n",
    "for clf,name in zip(dic_xgb.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_xgb[clf],file=clf)\n",
    "print(\"lgbm here\")\n",
    "for clf,name in zip(dic_lgbm.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_lgbm[clf],file=clf)\n",
    "print(\"logreg here\")\n",
    "for clf,name in zip(dic_lr.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_lr[clf],file=clf)\n",
    "print(\"adaboost here\")\n",
    "for clf,name in zip(dic_ada.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_ada[clf],file=clf)\n",
    "print(\"random forest here\")\n",
    "for clf,name in zip(dic_rf.keys(),work_train.keys()):\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_rf[clf],file=clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
