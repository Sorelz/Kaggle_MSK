{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import os \n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will use cross_val_score on XGBoost to select 100,200 or 300 for each preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train_w2v = {} \n",
    "work_test_w2v = {}\n",
    "pre_process=[\"w2v_100.csv\",\"w2v_200.csv\",\"w2v_300.csv\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train_w2v[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_train_\"+f)\n",
    "    work_test_w2v[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train_d2v = {} \n",
    "work_test_d2v = {}\n",
    "pre_process=[\"d2v_100.csv\",\"d2v_200.csv\",\"d2v_300.csv\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train_d2v[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_train_\"+f)\n",
    "    work_test_d2v[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train_tfidf = {} \n",
    "work_test_tfidf = {}\n",
    "pre_process=[\"tfidf_tsvd_100.csv\",\"tfidf_tsvd_200.csv\",\"tfidf_tsvd_300.csv\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train_tfidf[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_train_\"+f)\n",
    "    work_test_tfidf[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_v=pd.read_csv(\"../bases/new_training_variants.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(new_train_v.iloc[:,0])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../bases/new_training_variants.csv').reset_index()\n",
    "train.columns=[[\"Tempo_ID\",\"Class\"]]\n",
    "test = pd.read_csv('../bases/new_test_variants.csv')\n",
    "ID_train=train.Tempo_ID\n",
    "ID_test=test.ID\n",
    "del train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanw2v_100 -0.895570431786 std:w2v_100 0.0548596096564\n",
      "meanw2v_200 -0.90597903088 std:w2v_200 0.0509971236521\n",
      "meanw2v_300 -0.913247864735 std:w2v_300 0.040367728267\n"
     ]
    }
   ],
   "source": [
    "clf_xgb=XGBClassifier(max_depth=5, objective=\"multi:softprob\",seed=26)\n",
    "for name in work_train_w2v:\n",
    "    h=cross_val_score(clf_xgb,np.array(work_train_w2v[name].drop(\"ID\",axis=1)),y,cv=kf,n_jobs=-1,scoring=\"neg_log_loss\")\n",
    "    print(\"mean\"+name+\" \"+str(h.mean()),\n",
    "         \"std:\"+name+\" \"+str(h.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meand2v_100 -1.02297684649 std:d2v_100 0.0567970281113\n",
      "meand2v_200 -1.02919691932 std:d2v_200 0.050459167505\n",
      "meand2v_300 -1.03101971684 std:d2v_300 0.0491266926944\n"
     ]
    }
   ],
   "source": [
    "for name in work_train_d2v:\n",
    "    h=cross_val_score(clf_xgb,np.array(work_train_d2v[name].drop(\"ID\",axis=1)),y,cv=kf,n_jobs=-1,scoring=\"neg_log_loss\")\n",
    "    print(\"mean\"+name+\" \"+str(h.mean()),\n",
    "         \"std:\"+name+\" \"+str(h.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meantfidf_tsvd_100 -0.889870181278 std:tfidf_tsvd_100 0.0535310479521\n",
      "meantfidf_tsvd_200 -0.903077065542 std:tfidf_tsvd_200 0.045128434583\n",
      "meantfidf_tsvd_300 -0.905181327301 std:tfidf_tsvd_300 0.0512618176122\n"
     ]
    }
   ],
   "source": [
    "for name in work_train_tfidf:\n",
    "    h=cross_val_score(clf_xgb,np.array(work_train_tfidf[name].drop(\"ID\",axis=1)),y,cv=kf,n_jobs=-1,scoring=\"neg_log_loss\")\n",
    "    print(\"mean\"+name+\" \"+str(h.mean()),\n",
    "         \"std:\"+name+\" \"+str(h.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH PHASE ALL ALGOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train= {} \n",
    "work_test = {}\n",
    "pre_process=[\"d2v_100.csv\",\"tfidf_tsvd_100.csv\",\"w2v_100.csv\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 48.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 67.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2v_100\n",
      "[mean: -1.10183, std: 0.04434, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.11608, std: 0.03952, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.03937, std: 0.05671, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.06731, std: 0.05026, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -1.10267, std: 0.04157, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.11616, std: 0.03778, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -1.04035, std: 0.05765, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.06385, std: 0.04691, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -1.01124, std: 0.06010, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.02515, std: 0.05799, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.00477, std: 0.07964, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.01056, std: 0.07415, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -1.01882, std: 0.05451, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.03160, std: 0.04726, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.99883, std: 0.07398, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.00864, std: 0.06668, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.99059, std: 0.06817, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.99940, std: 0.06953, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.05722, std: 0.09074, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.02819, std: 0.08708, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.98799, std: 0.06035, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.99927, std: 0.06163, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -1.01819, std: 0.08175, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.01683, std: 0.07830, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -1.09443, std: 0.04345, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.11642, std: 0.03855, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.03659, std: 0.06029, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.06728, std: 0.04848, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -1.09895, std: 0.04032, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.11983, std: 0.03718, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -1.03765, std: 0.05590, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.06607, std: 0.04853, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -1.00796, std: 0.06270, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.02711, std: 0.05615, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.00691, std: 0.08267, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.01188, std: 0.07502, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -1.01173, std: 0.05402, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.03254, std: 0.05427, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.99996, std: 0.07450, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.01476, std: 0.07668, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.99579, std: 0.07367, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.00193, std: 0.06885, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.06911, std: 0.09549, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.03693, std: 0.08953, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.98985, std: 0.06490, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -1.01186, std: 0.06765, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -1.02979, std: 0.08652, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.02639, std: 0.08793, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}]\n",
      "{'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "-0.98799150285\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 67.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 94.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_tsvd_100\n",
      "[mean: -0.91554, std: 0.04153, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92413, std: 0.04066, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.88847, std: 0.05802, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.88659, std: 0.05416, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.91610, std: 0.04252, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92441, std: 0.03528, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.88585, std: 0.05543, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.88395, std: 0.05074, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.89044, std: 0.05955, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.88160, std: 0.05815, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.95667, std: 0.07430, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.93311, std: 0.07024, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.88664, std: 0.05694, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.87274, std: 0.05181, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.93369, std: 0.06888, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.91751, std: 0.06505, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.92980, std: 0.05762, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.91204, std: 0.06112, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.03594, std: 0.06742, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.01363, std: 0.07201, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.90925, std: 0.06001, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.90258, std: 0.05873, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.98317, std: 0.06987, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.98173, std: 0.07001, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.91606, std: 0.04439, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92785, std: 0.03948, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.89280, std: 0.05725, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.88982, std: 0.05375, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.91480, std: 0.04319, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92697, std: 0.03796, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.88708, std: 0.05665, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.88487, std: 0.05092, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.89263, std: 0.05421, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.88812, std: 0.05432, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.96541, std: 0.07203, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.94167, std: 0.06842, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.88725, std: 0.05275, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.88247, std: 0.05681, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.94094, std: 0.06844, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.92920, std: 0.07135, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.93229, std: 0.05640, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92617, std: 0.05876, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.04139, std: 0.06910, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.03283, std: 0.07101, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.90583, std: 0.05494, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.91345, std: 0.05653, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.98477, std: 0.06433, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.99532, std: 0.06827, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}]\n",
      "{'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}\n",
      "-0.87273601942\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 90.6min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 125.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_100\n",
      "[mean: -0.93032, std: 0.03761, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.94576, std: 0.03704, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.89707, std: 0.04870, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.90587, std: 0.04871, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.93094, std: 0.03437, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.94363, std: 0.03466, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.89250, std: 0.04405, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.89994, std: 0.04322, params: {'colsample_bytree': 0.8, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.89708, std: 0.04755, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.89127, std: 0.05070, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.96616, std: 0.06068, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.94205, std: 0.06367, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.88839, std: 0.04591, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.88599, std: 0.04980, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.93715, std: 0.05805, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.92563, std: 0.06260, params: {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.93712, std: 0.06024, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92067, std: 0.05903, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.04438, std: 0.06818, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.01836, std: 0.07304, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.90871, std: 0.05477, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.90166, std: 0.05386, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.98839, std: 0.06442, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.97320, std: 0.06557, params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.93425, std: 0.03885, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.94238, std: 0.03433, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.90717, std: 0.05147, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.90630, std: 0.04512, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.93264, std: 0.03677, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.94063, std: 0.03439, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.89789, std: 0.04993, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.90061, std: 0.04397, params: {'colsample_bytree': 1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.90102, std: 0.05185, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.89497, std: 0.05498, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -0.97424, std: 0.06263, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.94709, std: 0.07176, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.89196, std: 0.05116, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.88566, std: 0.04898, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.94580, std: 0.06587, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.92880, std: 0.06370, params: {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}, mean: -0.94369, std: 0.05694, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.92677, std: 0.06189, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1}, mean: -1.05130, std: 0.06746, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}, mean: -1.03046, std: 0.07684, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}, mean: -0.91398, std: 0.05503, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}, mean: -0.90267, std: 0.05546, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}, mean: -0.99602, std: 0.06629, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}, mean: -0.97601, std: 0.06824, params: {'colsample_bytree': 1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1}]\n",
      "{'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}\n",
      "-0.885656806362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_xgboost=XGBClassifier(max_depth=3, objective=\"multi:softprob\",seed=26)\n",
    "param_test= {\n",
    "    \"max_depth\" : [3,5,7],\n",
    "    \"min_child_weight\" : [1,3],\n",
    "    \"n_estimators\" : [100,200],\n",
    "    \"subsample\":[0.8,1],\n",
    "    \"colsample_bytree\":[0.8,1]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_xgboost, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=kf,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)\n",
    "#d2v : {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "#tfidf : {'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}\n",
    "#w2v : {'colsample_bytree': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2v_100\n",
      "[mean: -1.71471, std: 0.00934, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.71198, std: 0.00720, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.65478, std: 0.02224, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.65026, std: 0.01736, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.63703, std: 0.01133, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.63596, std: 0.02267, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.62014, std: 0.01198, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.61963, std: 0.02007, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.40123, std: 0.02087, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.40411, std: 0.02018, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.32583, std: 0.02570, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.32519, std: 0.02470, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.30712, std: 0.02190, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.30981, std: 0.02733, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.29615, std: 0.02897, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.29135, std: 0.02776, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.26930, std: 0.02649, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.27241, std: 0.02925, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.21383, std: 0.03676, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.21352, std: 0.04300, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.19508, std: 0.03326, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.20114, std: 0.04501, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.18226, std: 0.04133, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.17783, std: 0.04681, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.70753, std: 0.00980, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.70615, std: 0.01023, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.64858, std: 0.01022, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.64097, std: 0.01233, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.62638, std: 0.00972, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.62377, std: 0.01010, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.61271, std: 0.00929, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.61088, std: 0.01873, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.39452, std: 0.01900, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.39687, std: 0.01762, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.32444, std: 0.02110, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.31843, std: 0.01972, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.29985, std: 0.02321, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.29344, std: 0.02681, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.28347, std: 0.02294, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.27893, std: 0.02790, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.27224, std: 0.02598, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.26941, std: 0.02896, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.21501, std: 0.03306, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.21042, std: 0.04014, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.18758, std: 0.03266, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.19110, std: 0.04547, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.17187, std: 0.03659, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.16844, std: 0.04515, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}]\n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}\n",
      "-1.16844338777\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_tsvd_100\n",
      "[mean: -1.59855, std: 0.01637, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.59189, std: 0.01554, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.53482, std: 0.01789, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.52955, std: 0.01667, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.51620, std: 0.01840, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.50908, std: 0.01384, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.49688, std: 0.01829, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.48604, std: 0.01470, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.22447, std: 0.02130, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.22176, std: 0.02416, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.13658, std: 0.02114, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.13600, std: 0.02406, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.11283, std: 0.02366, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.11236, std: 0.01930, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.08738, std: 0.02261, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.07987, std: 0.02242, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.04445, std: 0.02697, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.04293, std: 0.03023, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.8}, mean: -0.96458, std: 0.03078, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.7}, mean: -0.96350, std: 0.03400, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.8}, mean: -0.94805, std: 0.03119, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.7}, mean: -0.94547, std: 0.03351, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.8}, mean: -0.92979, std: 0.03410, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.7}, mean: -0.92298, std: 0.03888, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.59209, std: 0.01376, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.58368, std: 0.01465, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.52896, std: 0.01631, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.52444, std: 0.01013, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.50601, std: 0.01674, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.49747, std: 0.01234, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.48948, std: 0.02115, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.48164, std: 0.01317, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.22195, std: 0.02297, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.21750, std: 0.02203, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.13366, std: 0.02041, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.12991, std: 0.01841, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.10331, std: 0.02228, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.09950, std: 0.02090, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.08580, std: 0.02496, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.07888, std: 0.02002, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.04189, std: 0.02728, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.03874, std: 0.02775, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.8}, mean: -0.96332, std: 0.02802, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.7}, mean: -0.95832, std: 0.03068, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.8}, mean: -0.93899, std: 0.03168, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.7}, mean: -0.93365, std: 0.03138, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.8}, mean: -0.92825, std: 0.03650, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.7}, mean: -0.92395, std: 0.03686, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}]\n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}\n",
      "-0.922979447054\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_100\n",
      "[mean: -1.61438, std: 0.01175, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.61260, std: 0.00565, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.55027, std: 0.01063, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.54867, std: 0.00930, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.52788, std: 0.01277, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.52228, std: 0.01232, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.50684, std: 0.01323, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.50245, std: 0.01157, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.24414, std: 0.02279, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.24503, std: 0.01693, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.15575, std: 0.01824, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.15301, std: 0.02030, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.12829, std: 0.02228, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.12514, std: 0.02135, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.10256, std: 0.01990, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.10012, std: 0.01506, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.06675, std: 0.02948, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.06831, std: 0.02488, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.8}, mean: -0.98571, std: 0.02479, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.7}, mean: -0.97802, std: 0.02891, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.8}, mean: -0.96199, std: 0.02994, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.7}, mean: -0.96234, std: 0.03328, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.8}, mean: -0.94585, std: 0.03149, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.7}, mean: -0.94393, std: 0.03289, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.60875, std: 0.01287, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.60784, std: 0.00964, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.54048, std: 0.01229, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.53635, std: 0.00672, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.52099, std: 0.01124, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.51206, std: 0.00620, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.50120, std: 0.01406, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.48673, std: 0.00536, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 8, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.24235, std: 0.02170, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.24344, std: 0.01770, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 6, 'subsample': 0.8}, mean: -1.14489, std: 0.01893, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.7}, mean: -1.14808, std: 0.01440, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 12, 'subsample': 0.8}, mean: -1.12317, std: 0.02086, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.7}, mean: -1.11574, std: 0.01726, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 16, 'subsample': 0.8}, mean: -1.09914, std: 0.02020, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.7}, mean: -1.08621, std: 0.01432, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 24, 'num_leaves': 22, 'subsample': 0.8}, mean: -1.06709, std: 0.02627, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.7}, mean: -1.06908, std: 0.02798, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 6, 'subsample': 0.8}, mean: -0.97864, std: 0.02923, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.7}, mean: -0.97943, std: 0.03076, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 12, 'subsample': 0.8}, mean: -0.95999, std: 0.03461, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.7}, mean: -0.95186, std: 0.03177, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 16, 'subsample': 0.8}, mean: -0.94524, std: 0.03637, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.7}, mean: -0.93148, std: 0.02966, params: {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}]\n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}\n",
      "-0.931482969854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_lgbm=LGBMClassifier(seed=26)\n",
    "param_test= {\n",
    "    'n_estimators': [8,24,48],\n",
    "    'num_leaves': [6,12,16,22],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'colsample_bytree' : [0.7,0.8],\n",
    "    'subsample' : [0.7,0.8]\n",
    "    }\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_lgbm, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=kf,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)\n",
    "#d2v : {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}\n",
    "#tfidf : {'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}\n",
    "#w2v : {'boosting_type': 'gbdt', 'colsample_bytree': 0.8, 'n_estimators': 48, 'num_leaves': 22, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   43.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2v_100\n",
      "[mean: -1.86803, std: 0.03398, params: {'C': 0.001, 'penalty': 'l1'}, mean: -1.85301, std: 0.03435, params: {'C': 0.001, 'penalty': 'l2'}, mean: -1.85695, std: 0.03592, params: {'C': 0.01, 'penalty': 'l1'}, mean: -1.76132, std: 0.02708, params: {'C': 0.01, 'penalty': 'l2'}, mean: -1.48878, std: 0.03079, params: {'C': 0.1, 'penalty': 'l1'}, mean: -1.70851, std: 0.02299, params: {'C': 0.1, 'penalty': 'l2'}, mean: -1.28133, std: 0.02638, params: {'C': 1, 'penalty': 'l1'}, mean: -1.62934, std: 0.04810, params: {'C': 1, 'penalty': 'l2'}, mean: -1.26483, std: 0.03273, params: {'C': 10, 'penalty': 'l1'}, mean: -1.62548, std: 0.04035, params: {'C': 10, 'penalty': 'l2'}, mean: -1.31990, std: 0.04065, params: {'C': 100, 'penalty': 'l1'}, mean: -1.64046, std: 0.03516, params: {'C': 100, 'penalty': 'l2'}, mean: -1.41898, std: 0.06563, params: {'C': 1000, 'penalty': 'l1'}, mean: -1.63924, std: 0.03499, params: {'C': 1000, 'penalty': 'l2'}]\n",
      "{'C': 10, 'penalty': 'l1'}\n",
      "-1.2648347351\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_tsvd_100\n",
      "[mean: -1.86803, std: 0.03398, params: {'C': 0.001, 'penalty': 'l1'}, mean: -1.84770, std: 0.03393, params: {'C': 0.001, 'penalty': 'l2'}, mean: -1.85690, std: 0.03590, params: {'C': 0.01, 'penalty': 'l1'}, mean: -1.72502, std: 0.03332, params: {'C': 0.01, 'penalty': 'l2'}, mean: -1.37320, std: 0.03032, params: {'C': 0.1, 'penalty': 'l1'}, mean: -1.54961, std: 0.03515, params: {'C': 0.1, 'penalty': 'l2'}, mean: -1.04443, std: 0.03156, params: {'C': 1, 'penalty': 'l1'}, mean: -1.50064, std: 0.04759, params: {'C': 1, 'penalty': 'l2'}, mean: -0.97721, std: 0.03534, params: {'C': 10, 'penalty': 'l1'}, mean: -1.46547, std: 0.04555, params: {'C': 10, 'penalty': 'l2'}, mean: -1.11089, std: 0.06555, params: {'C': 100, 'penalty': 'l1'}, mean: -1.47910, std: 0.05720, params: {'C': 100, 'penalty': 'l2'}, mean: -1.25983, std: 0.09510, params: {'C': 1000, 'penalty': 'l1'}, mean: -1.47220, std: 0.03731, params: {'C': 1000, 'penalty': 'l2'}]\n",
      "{'C': 10, 'penalty': 'l1'}\n",
      "-0.977210584672\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_100\n",
      "[mean: -1.86803, std: 0.03397, params: {'C': 0.001, 'penalty': 'l1'}, mean: -1.73130, std: 0.02830, params: {'C': 0.001, 'penalty': 'l2'}, mean: -1.79844, std: 0.03595, params: {'C': 0.01, 'penalty': 'l1'}, mean: -1.49137, std: 0.02284, params: {'C': 0.01, 'penalty': 'l2'}, mean: -1.32659, std: 0.03685, params: {'C': 0.1, 'penalty': 'l1'}, mean: -1.34454, std: 0.01237, params: {'C': 0.1, 'penalty': 'l2'}, mean: -1.07196, std: 0.04045, params: {'C': 1, 'penalty': 'l1'}, mean: -1.28040, std: 0.04270, params: {'C': 1, 'penalty': 'l2'}, mean: -1.06280, std: 0.05567, params: {'C': 10, 'penalty': 'l1'}, mean: -1.28403, std: 0.04111, params: {'C': 10, 'penalty': 'l2'}, mean: -1.16657, std: 0.09201, params: {'C': 100, 'penalty': 'l1'}, mean: -1.29447, std: 0.02789, params: {'C': 100, 'penalty': 'l2'}, mean: -1.23551, std: 0.11745, params: {'C': 1000, 'penalty': 'l1'}, mean: -1.27845, std: 0.04311, params: {'C': 1000, 'penalty': 'l2'}]\n",
      "{'C': 10, 'penalty': 'l1'}\n",
      "-1.06279894516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_log=LogisticRegression()\n",
    "param_test= {\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    \"penalty\" : [\"l1\",\"l2\"]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_log, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=kf,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)\n",
    "#d2v : {'C': 10, 'penalty': 'l1'}\n",
    "#tfidf : {'C': 10, 'penalty': 'l1'}\n",
    "#w2v : {'C': 10, 'penalty': 'l1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   46.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2v_100\n",
      "[mean: -1.94169, std: 0.00465, params: {'learning_rate': 0.3, 'n_estimators': 50}, mean: -1.99920, std: 0.01060, params: {'learning_rate': 0.3, 'n_estimators': 100}, mean: -1.96065, std: 0.01302, params: {'learning_rate': 0.5, 'n_estimators': 50}, mean: -2.01419, std: 0.01107, params: {'learning_rate': 0.5, 'n_estimators': 100}, mean: -2.00529, std: 0.02161, params: {'learning_rate': 0.9, 'n_estimators': 50}, mean: -2.04604, std: 0.01959, params: {'learning_rate': 0.9, 'n_estimators': 100}, mean: -2.00737, std: 0.01516, params: {'learning_rate': 1, 'n_estimators': 50}, mean: -2.05062, std: 0.01401, params: {'learning_rate': 1, 'n_estimators': 100}]\n",
      "{'learning_rate': 0.3, 'n_estimators': 50}\n",
      "-1.94168942506\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_tsvd_100\n",
      "[mean: -1.91750, std: 0.01409, params: {'learning_rate': 0.3, 'n_estimators': 50}, mean: -1.94188, std: 0.01189, params: {'learning_rate': 0.3, 'n_estimators': 100}, mean: -1.95182, std: 0.01644, params: {'learning_rate': 0.5, 'n_estimators': 50}, mean: -1.97111, std: 0.01814, params: {'learning_rate': 0.5, 'n_estimators': 100}, mean: -2.00289, std: 0.02692, params: {'learning_rate': 0.9, 'n_estimators': 50}, mean: -2.06171, std: 0.07002, params: {'learning_rate': 0.9, 'n_estimators': 100}, mean: -2.03082, std: 0.03772, params: {'learning_rate': 1, 'n_estimators': 50}, mean: -2.07098, std: 0.04586, params: {'learning_rate': 1, 'n_estimators': 100}]\n",
      "{'learning_rate': 0.3, 'n_estimators': 50}\n",
      "-1.91749502231\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_100\n",
      "[mean: -1.91682, std: 0.00978, params: {'learning_rate': 0.3, 'n_estimators': 50}, mean: -1.94374, std: 0.00987, params: {'learning_rate': 0.3, 'n_estimators': 100}, mean: -1.95939, std: 0.03143, params: {'learning_rate': 0.5, 'n_estimators': 50}, mean: -1.99379, std: 0.04053, params: {'learning_rate': 0.5, 'n_estimators': 100}, mean: -2.02985, std: 0.02044, params: {'learning_rate': 0.9, 'n_estimators': 50}, mean: -2.03370, std: 0.01915, params: {'learning_rate': 0.9, 'n_estimators': 100}, mean: -2.04482, std: 0.02814, params: {'learning_rate': 1, 'n_estimators': 50}, mean: -2.09304, std: 0.04078, params: {'learning_rate': 1, 'n_estimators': 100}]\n",
      "{'learning_rate': 0.3, 'n_estimators': 50}\n",
      "-1.91681966898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_ada=AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26)\n",
    "param_test={\n",
    "    \"n_estimators\":[50,100],\n",
    "    \"learning_rate\":[0.3,0.5,0.9,1]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_ada, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=kf,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)\n",
    "#d2v : {'learning_rate': 0.3, 'n_estimators': 50}\n",
    "#tfidf : {'learning_rate': 0.3, 'n_estimators': 50}\n",
    "#w2v : {'learning_rate': 0.3, 'n_estimators': 50}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2v_100\n",
      "[mean: -1.55450, std: 0.01645, params: {'max_depth': 5, 'n_estimators': 100}, mean: -1.55385, std: 0.01623, params: {'max_depth': 5, 'n_estimators': 200}, mean: -1.55669, std: 0.01442, params: {'max_depth': 5, 'n_estimators': 300}, mean: -1.46899, std: 0.02145, params: {'max_depth': 7, 'n_estimators': 100}, mean: -1.46709, std: 0.01621, params: {'max_depth': 7, 'n_estimators': 200}, mean: -1.46734, std: 0.02178, params: {'max_depth': 7, 'n_estimators': 300}, mean: -1.36696, std: 0.02447, params: {'max_depth': 10, 'n_estimators': 100}, mean: -1.35802, std: 0.02643, params: {'max_depth': 10, 'n_estimators': 200}, mean: -1.35845, std: 0.02639, params: {'max_depth': 10, 'n_estimators': 300}, mean: -1.23195, std: 0.03798, params: {'max_depth': 15, 'n_estimators': 100}, mean: -1.22704, std: 0.03746, params: {'max_depth': 15, 'n_estimators': 200}, mean: -1.22608, std: 0.04033, params: {'max_depth': 15, 'n_estimators': 300}]\n",
      "{'max_depth': 15, 'n_estimators': 300}\n",
      "-1.22607533435\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_tsvd_100\n",
      "[mean: -1.35762, std: 0.02528, params: {'max_depth': 5, 'n_estimators': 100}, mean: -1.36400, std: 0.01501, params: {'max_depth': 5, 'n_estimators': 200}, mean: -1.36234, std: 0.01855, params: {'max_depth': 5, 'n_estimators': 300}, mean: -1.21549, std: 0.01840, params: {'max_depth': 7, 'n_estimators': 100}, mean: -1.22147, std: 0.02262, params: {'max_depth': 7, 'n_estimators': 200}, mean: -1.22395, std: 0.02135, params: {'max_depth': 7, 'n_estimators': 300}, mean: -1.06192, std: 0.03022, params: {'max_depth': 10, 'n_estimators': 100}, mean: -1.05693, std: 0.02365, params: {'max_depth': 10, 'n_estimators': 200}, mean: -1.05594, std: 0.02709, params: {'max_depth': 10, 'n_estimators': 300}, mean: -0.95162, std: 0.03561, params: {'max_depth': 15, 'n_estimators': 100}, mean: -0.94587, std: 0.03060, params: {'max_depth': 15, 'n_estimators': 200}, mean: -0.94415, std: 0.02992, params: {'max_depth': 15, 'n_estimators': 300}]\n",
      "{'max_depth': 15, 'n_estimators': 300}\n",
      "-0.944145729649\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_100\n",
      "[mean: -1.30178, std: 0.02275, params: {'max_depth': 5, 'n_estimators': 100}, mean: -1.29955, std: 0.02268, params: {'max_depth': 5, 'n_estimators': 200}, mean: -1.29942, std: 0.02190, params: {'max_depth': 5, 'n_estimators': 300}, mean: -1.15762, std: 0.02378, params: {'max_depth': 7, 'n_estimators': 100}, mean: -1.15918, std: 0.02682, params: {'max_depth': 7, 'n_estimators': 200}, mean: -1.15403, std: 0.02480, params: {'max_depth': 7, 'n_estimators': 300}, mean: -1.02141, std: 0.03265, params: {'max_depth': 10, 'n_estimators': 100}, mean: -1.01316, std: 0.03040, params: {'max_depth': 10, 'n_estimators': 200}, mean: -1.01753, std: 0.02973, params: {'max_depth': 10, 'n_estimators': 300}, mean: -1.02948, std: 0.07607, params: {'max_depth': 15, 'n_estimators': 100}, mean: -1.01016, std: 0.04225, params: {'max_depth': 15, 'n_estimators': 200}, mean: -1.01192, std: 0.04159, params: {'max_depth': 15, 'n_estimators': 300}]\n",
      "{'max_depth': 15, 'n_estimators': 200}\n",
      "-1.01015899003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_dt=RandomForestClassifier()\n",
    "param_test={\n",
    "    \"max_depth\":[5,7,10,15],\n",
    "    \"n_estimators\":[100,200,300]\n",
    "}\n",
    "for name in work_train:\n",
    "    gsearch=GridSearchCV(estimator=clf_dt, param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=-1,iid=False, cv=kf,verbose=True)\n",
    "    gsearch.fit(work_train[name],y)\n",
    "    print(name)\n",
    "    print(gsearch.grid_scores_)\n",
    "    print(gsearch.best_params_)\n",
    "    print(gsearch.best_score_)\n",
    "#d2v : {'max_depth': 15, 'n_estimators': 300}\n",
    "#tfidf : {'max_depth': 15, 'n_estimators': 300}\n",
    "#w2v : {'max_depth': 15, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING PHASE ALL ALGOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gen(X,X_test,y,classifier,file,five_fold_predict=True):\n",
    "    #if not os.path.exists(\"scores/\"+file):\n",
    "    #   os.makedirs(\"scores/\"+file)\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)\n",
    "    if five_fold_predict:\n",
    "        fold = 0\n",
    "        y_test=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "            fold += 1\n",
    "\n",
    "            X_train, X_valid    = X[train_index],   X[test_index]\n",
    "            y_train, y_valid    = y[train_index],   y[test_index]\n",
    "\n",
    "            print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "\n",
    "            clf=classifier\n",
    "            clf.fit(X_train,y_train)\n",
    "            p_test = clf.predict_proba(X_test)\n",
    "            y_test += p_test/5\n",
    "\n",
    "    classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "    subm = pd.DataFrame(y_test, columns=classes)\n",
    "    subm['ID'] = ID_test\n",
    "    \n",
    "    subm.to_csv(\"nw_scores/nw_stack_test/nw_{}.csv\".format(file),index=False)\n",
    "    \n",
    "    print(\"cross_val sur train \") #peut etre que to array est exclusivement pour les xgb\n",
    "    \n",
    "    if os.path.isfile(\"nw_scores/nw_stack_train/nw_{}.csv\".format(file)):\n",
    "        print(\"not necessary, already done\")\n",
    "    else:\n",
    "        y_pred=cross_val_predict(estimator=clf,X=X,y=y,cv=kf,method=\"predict_proba\")\n",
    "        subm1 = pd.DataFrame(y_pred, columns=classes)\n",
    "        subm1['ID'] = ID_train\n",
    "        subm1.to_csv(\"nw_scores/nw_stack_train/nw_{}.csv\".format(file),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost here\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'d2v_100'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-9c6374d9acbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xgboost here\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwork_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmodel_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwork_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwork_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdic_xgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lgbm here\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwork_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd2v_100'"
     ]
    }
   ],
   "source": [
    "dic_xgb={\"xgb_d2v\":XGBClassifier(max_depth=3,objective=\"multi:softprob\",seed=26),\n",
    "        \"xgb_tfidf\":XGBClassifier(max_depth=3,objective=\"multi:softprob\",seed=26),\n",
    "        \"xgb_w2v\":XGBClassifier(max_depth=3,objective=\"multi:softprob\",seed=26)}\n",
    "dic_lgbm={\"lgbm_d2v\":LGBMClassifier(seed=26),\n",
    "        \"lgbm_tfidf\":LGBMClassifier(seed=26),\n",
    "        \"lgbm_w2v\":LGBMClassifier(seed=26)}\n",
    "dic_lr={\"lr_d2v\":LogisticRegression(),\n",
    "        \"lr_tfidf\":LogisticRegression(),\n",
    "        \"lr_w2v\":LogisticRegression()}\n",
    "dic_ada={\"ada_d2v\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26),\n",
    "        \"ada_tfidf\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26),\n",
    "        \"ada_w2v\":AdaBoostClassifier(n_estimators=100, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=26)}\n",
    "dic_rf={\"rf_d2v\":RandomForestClassifier(n_estimators=200,max_depth=10,random_state=26),\n",
    "        \"rf_tfidf\":RandomForestClassifier(n_estimators=200,max_depth=10,random_state=26),\n",
    "        \"rf_w2v\":RandomForestClassifier(n_estimators=200,max_depth=10,random_state=26)}\n",
    "\n",
    "print(\"xgboost here\")\n",
    "for clf,name in zip(dic_xgb.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_xgb[clf],file=clf)\n",
    "print(\"lgbm here\")\n",
    "for clf,name in zip(dic_lgbm.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_lgbm[clf],file=clf)\n",
    "print(\"logreg here\")\n",
    "for clf,name in zip(dic_lr.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_lr[clf],file=clf)\n",
    "print(\"adaboost here\")\n",
    "for clf,name in zip(dic_ada.keys(),work_train.keys()):\n",
    "    model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_ada[clf],file=clf)\n",
    "print(\"random forest here\")\n",
    "for clf,name in zip(dic_rf.keys(),work_train.keys()):\n",
    "        model_gen(X=work_train[name],X_test=work_test[name],y=y,classifier=dic_rf[clf],file=clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d2v_100.csv':       ID  Substitutions_var  Stop_codon_var  Fusion_var  gene_fusion_var  \\\n",
       " 0      1                  1               0           0              0.0   \n",
       " 1      2                  0               0           0              0.0   \n",
       " 2      3                  1               0           0              0.0   \n",
       " 3      4                  1               0           0              0.0   \n",
       " 4      5                  0               0           0              0.0   \n",
       " 5      6                  1               0           0              0.0   \n",
       " 6      7                  1               0           0              0.0   \n",
       " 7      8                  1               0           0              0.0   \n",
       " 8      9                  1               0           0              0.0   \n",
       " 9     10                  1               0           0              0.0   \n",
       " 10    11                  1               0           0              0.0   \n",
       " 11    12                  1               0           0              0.0   \n",
       " 12    13                  1               0           0              0.0   \n",
       " 13    14                  1               0           0              0.0   \n",
       " 14    15                  1               0           0              0.0   \n",
       " 15    16                  1               0           0              0.0   \n",
       " 16    17                  1               0           0              0.0   \n",
       " 17    18                  1               0           0              0.0   \n",
       " 18    19                  1               0           0              0.0   \n",
       " 19    20                  1               0           0              0.0   \n",
       " 20    21                  1               0           0              0.0   \n",
       " 21    22                  1               0           0              0.0   \n",
       " 22    23                  1               0           0              0.0   \n",
       " 23    24                  0               0           0              1.0   \n",
       " 24    25                  1               0           0              0.0   \n",
       " 25    26                  1               0           0              0.0   \n",
       " 26    27                  1               0           0              0.0   \n",
       " 27    28                  1               0           0              0.0   \n",
       " 28    29                  1               0           0              0.0   \n",
       " 29    30                  1               0           0              0.0   \n",
       " ..   ...                ...             ...         ...              ...   \n",
       " 956  957                  1               0           0              0.0   \n",
       " 957  958                  1               0           0              0.0   \n",
       " 958  959                  1               0           0              0.0   \n",
       " 959  960                  1               0           0              0.0   \n",
       " 960  961                  1               0           0              0.0   \n",
       " 961  962                  0               0           0              0.0   \n",
       " 962  963                  0               0           0              0.0   \n",
       " 963  964                  1               0           0              0.0   \n",
       " 964  965                  1               0           0              0.0   \n",
       " 965  966                  1               0           0              0.0   \n",
       " 966  967                  1               0           0              0.0   \n",
       " 967  968                  1               0           0              0.0   \n",
       " 968  969                  1               0           0              0.0   \n",
       " 969  970                  1               0           0              0.0   \n",
       " 970  971                  1               0           0              0.0   \n",
       " 971  972                  1               0           0              0.0   \n",
       " 972  973                  1               0           0              0.0   \n",
       " 973  974                  1               0           0              0.0   \n",
       " 974  975                  1               0           0              0.0   \n",
       " 975  976                  1               0           0              0.0   \n",
       " 976  977                  1               0           0              0.0   \n",
       " 977  978                  1               0           0              0.0   \n",
       " 978  979                  1               0           0              0.0   \n",
       " 979  980                  1               0           0              0.0   \n",
       " 980  981                  1               0           0              0.0   \n",
       " 981  982                  1               0           0              0.0   \n",
       " 982  983                  1               0           0              0.0   \n",
       " 983  984                  1               0           0              0.0   \n",
       " 984  985                  1               0           0              0.0   \n",
       " 985  986                  1               0           0              0.0   \n",
       " \n",
       "      Deletion_var  del_or_ins_var  Amplification_var  Truncation_var  \\\n",
       " 0             0.0             0.0                  0               0   \n",
       " 1             0.0             0.0                  0               1   \n",
       " 2             0.0             0.0                  0               0   \n",
       " 3             0.0             0.0                  0               0   \n",
       " 4             0.0             1.0                  0               0   \n",
       " 5             0.0             0.0                  0               0   \n",
       " 6             0.0             0.0                  0               0   \n",
       " 7             0.0             0.0                  0               0   \n",
       " 8             0.0             0.0                  0               0   \n",
       " 9             0.0             0.0                  0               0   \n",
       " 10            0.0             0.0                  0               0   \n",
       " 11            0.0             0.0                  0               0   \n",
       " 12            0.0             0.0                  0               0   \n",
       " 13            0.0             0.0                  0               0   \n",
       " 14            0.0             0.0                  0               0   \n",
       " 15            0.0             0.0                  0               0   \n",
       " 16            0.0             0.0                  0               0   \n",
       " 17            0.0             0.0                  0               0   \n",
       " 18            0.0             0.0                  0               0   \n",
       " 19            0.0             0.0                  0               0   \n",
       " 20            0.0             0.0                  0               0   \n",
       " 21            0.0             0.0                  0               0   \n",
       " 22            0.0             0.0                  0               0   \n",
       " 23            0.0             0.0                  0               0   \n",
       " 24            0.0             0.0                  0               0   \n",
       " 25            0.0             0.0                  0               0   \n",
       " 26            0.0             0.0                  0               0   \n",
       " 27            0.0             0.0                  0               0   \n",
       " 28            0.0             0.0                  0               0   \n",
       " 29            0.0             0.0                  0               0   \n",
       " ..            ...             ...                ...             ...   \n",
       " 956           0.0             0.0                  0               0   \n",
       " 957           0.0             0.0                  0               0   \n",
       " 958           0.0             0.0                  0               0   \n",
       " 959           0.0             0.0                  0               0   \n",
       " 960           0.0             0.0                  0               0   \n",
       " 961           0.0             1.0                  0               0   \n",
       " 962           1.0             0.0                  0               0   \n",
       " 963           0.0             0.0                  0               0   \n",
       " 964           0.0             0.0                  0               0   \n",
       " 965           0.0             0.0                  0               0   \n",
       " 966           0.0             0.0                  0               0   \n",
       " 967           0.0             0.0                  0               0   \n",
       " 968           0.0             0.0                  0               0   \n",
       " 969           0.0             0.0                  0               0   \n",
       " 970           0.0             0.0                  0               0   \n",
       " 971           0.0             0.0                  0               0   \n",
       " 972           0.0             0.0                  0               0   \n",
       " 973           0.0             0.0                  0               0   \n",
       " 974           0.0             0.0                  0               0   \n",
       " 975           0.0             0.0                  0               0   \n",
       " 976           0.0             0.0                  0               0   \n",
       " 977           0.0             0.0                  0               0   \n",
       " 978           0.0             0.0                  0               0   \n",
       " 979           0.0             0.0                  0               0   \n",
       " 980           0.0             0.0                  0               0   \n",
       " 981           0.0             0.0                  0               0   \n",
       " 982           0.0             0.0                  0               0   \n",
       " 983           0.0             0.0                  0               0   \n",
       " 984           0.0             0.0                  0               0   \n",
       " 985           0.0             0.0                  0               0   \n",
       " \n",
       "      exon_var    ...           90        91        92        93        94  \\\n",
       " 0           0    ...    -0.000567 -0.000472 -0.003945 -0.002916 -0.002691   \n",
       " 1           0    ...    -0.004402  0.002091  0.003097  0.002735  0.001612   \n",
       " 2           0    ...     0.004575 -0.002449 -0.003408 -0.000256 -0.000323   \n",
       " 3           0    ...     0.003030 -0.001530 -0.000967  0.001588  0.004774   \n",
       " 4           0    ...     0.000814  0.002896 -0.004456 -0.004406 -0.003081   \n",
       " 5           0    ...    -0.002210 -0.001635 -0.000373  0.002449  0.004940   \n",
       " 6           0    ...     0.003536 -0.001242  0.003132 -0.002762  0.002099   \n",
       " 7           0    ...     0.002916  0.002873 -0.003672 -0.003126 -0.001726   \n",
       " 8           0    ...    -0.002328  0.002158 -0.000890  0.003338  0.002722   \n",
       " 9           0    ...    -0.002286 -0.004778 -0.000225 -0.004362 -0.001671   \n",
       " 10          0    ...    -0.001587 -0.003626  0.000821  0.000502  0.000503   \n",
       " 11          0    ...    -0.004937 -0.004335 -0.000647 -0.001236 -0.001508   \n",
       " 12          0    ...    -0.001882 -0.004456  0.002015  0.000367 -0.003267   \n",
       " 13          0    ...     0.004144 -0.002280  0.001071  0.003201  0.000308   \n",
       " 14          0    ...    -0.004594  0.002610  0.003093 -0.000454 -0.001054   \n",
       " 15          0    ...     0.004944  0.003097  0.003228  0.001219  0.005000   \n",
       " 16          0    ...     0.000933  0.002991 -0.004885 -0.003179 -0.002854   \n",
       " 17          0    ...     0.002887  0.003722  0.001820 -0.003893  0.001233   \n",
       " 18          0    ...     0.000390 -0.003225 -0.002315  0.004393  0.000074   \n",
       " 19          0    ...     0.001606  0.003573 -0.002371  0.002832  0.004653   \n",
       " 20          0    ...     0.000992 -0.000312 -0.001037 -0.001210 -0.003594   \n",
       " 21          0    ...    -0.000057  0.004864  0.003243 -0.003397 -0.001719   \n",
       " 22          0    ...    -0.004961  0.004854 -0.000774  0.002772 -0.001043   \n",
       " 23          0    ...    -0.002713 -0.002152 -0.002965 -0.004875  0.003666   \n",
       " 24          0    ...    -0.001432 -0.001779  0.001867 -0.001567 -0.003839   \n",
       " 25          0    ...     0.000644 -0.001570  0.004150  0.001433 -0.002073   \n",
       " 26          0    ...    -0.000962  0.001245  0.004863  0.004610 -0.000846   \n",
       " 27          0    ...     0.001937 -0.002495  0.002129 -0.002124  0.003838   \n",
       " 28          0    ...    -0.000979  0.004508 -0.002279  0.002131  0.000779   \n",
       " 29          0    ...    -0.003745  0.003954  0.002233 -0.003929 -0.004320   \n",
       " ..        ...    ...          ...       ...       ...       ...       ...   \n",
       " 956         0    ...     0.001975 -0.004531  0.003665 -0.001675 -0.003341   \n",
       " 957         0    ...    -0.004117  0.002657  0.000033  0.000136  0.004388   \n",
       " 958         0    ...     0.002735 -0.002478  0.001335  0.000412  0.001895   \n",
       " 959         0    ...    -0.002067 -0.003044 -0.001815  0.000781  0.001721   \n",
       " 960         0    ...     0.002130  0.003910  0.000210  0.004321 -0.002869   \n",
       " 961         0    ...     0.003178  0.000663  0.000219  0.000230  0.003561   \n",
       " 962         0    ...     0.003172  0.000757  0.001002 -0.004109  0.003014   \n",
       " 963         0    ...    -0.000500  0.001155 -0.001236  0.001099  0.002298   \n",
       " 964         0    ...    -0.003597 -0.001904 -0.001529  0.001603 -0.002539   \n",
       " 965         0    ...     0.002439 -0.001074 -0.000757 -0.001110 -0.004750   \n",
       " 966         0    ...    -0.000178 -0.003238  0.002962 -0.000447 -0.003856   \n",
       " 967         0    ...    -0.003058  0.002008 -0.003362 -0.001387 -0.001261   \n",
       " 968         0    ...    -0.001936  0.004369 -0.002325 -0.001256  0.003251   \n",
       " 969         0    ...     0.004612 -0.004901  0.000004  0.003490  0.000462   \n",
       " 970         0    ...    -0.000943 -0.004783  0.002806  0.000878  0.003625   \n",
       " 971         0    ...    -0.003251  0.003953 -0.002537 -0.000091 -0.004163   \n",
       " 972         0    ...    -0.004015 -0.000859  0.001110  0.004499  0.001922   \n",
       " 973         0    ...    -0.001441 -0.004745  0.000488 -0.001263 -0.002881   \n",
       " 974         0    ...     0.004749 -0.002193  0.003478 -0.003505 -0.002308   \n",
       " 975         0    ...    -0.001714 -0.000472  0.003661 -0.001008  0.004800   \n",
       " 976         0    ...    -0.001287 -0.002333  0.004490  0.003237 -0.002412   \n",
       " 977         0    ...     0.003091  0.004212 -0.002067  0.002841 -0.004031   \n",
       " 978         0    ...     0.002290 -0.004179  0.000335  0.001752  0.001152   \n",
       " 979         0    ...    -0.004451 -0.000148  0.000948 -0.004745 -0.001485   \n",
       " 980         0    ...     0.002247 -0.002978  0.001187 -0.001046  0.003467   \n",
       " 981         0    ...     0.001769 -0.000533 -0.002087 -0.000448  0.001663   \n",
       " 982         0    ...    -0.001163 -0.000993  0.002754  0.004167 -0.001860   \n",
       " 983         0    ...    -0.004726 -0.003906  0.001438 -0.002746 -0.003251   \n",
       " 984         0    ...    -0.000020 -0.000904  0.000628 -0.000416  0.004487   \n",
       " 985         0    ...    -0.002999  0.001324 -0.002635 -0.004835 -0.002842   \n",
       " \n",
       "            95        96        97        98        99  \n",
       " 0   -0.003599 -0.004686 -0.002303 -0.000048  0.001877  \n",
       " 1    0.004638 -0.002299 -0.004381  0.003704  0.002368  \n",
       " 2    0.001065 -0.002390  0.002566  0.003766  0.000915  \n",
       " 3   -0.004611  0.001505  0.000746  0.000199 -0.003421  \n",
       " 4   -0.004070  0.003265 -0.004917 -0.002415  0.001928  \n",
       " 5   -0.003969 -0.004301  0.004961 -0.003279 -0.000226  \n",
       " 6   -0.000084  0.003161  0.000913 -0.001778  0.004341  \n",
       " 7    0.004672 -0.004173  0.002754  0.003327 -0.002140  \n",
       " 8   -0.004035 -0.001322  0.002322 -0.004527  0.000628  \n",
       " 9   -0.003614  0.004457  0.002079  0.001770  0.002023  \n",
       " 10   0.003862  0.004788 -0.004925 -0.000869 -0.002294  \n",
       " 11  -0.003916  0.003653  0.004395 -0.000649  0.000046  \n",
       " 12  -0.001664 -0.004785 -0.004312 -0.000512  0.000953  \n",
       " 13  -0.002564  0.002128  0.002418  0.001638  0.002752  \n",
       " 14   0.001733  0.004220  0.000597  0.004483  0.002343  \n",
       " 15  -0.002832  0.003652  0.003731 -0.001604  0.001973  \n",
       " 16   0.002131  0.000650  0.004618  0.003557  0.003537  \n",
       " 17  -0.003162  0.004522 -0.000498 -0.000014 -0.004830  \n",
       " 18   0.000149 -0.000675 -0.004131  0.000009  0.000491  \n",
       " 19   0.001442  0.000477 -0.004007 -0.003179  0.004325  \n",
       " 20  -0.004029 -0.002445  0.001072 -0.000435  0.004911  \n",
       " 21  -0.004536  0.004076 -0.003184  0.004822  0.000784  \n",
       " 22  -0.003803 -0.002166  0.004797 -0.001500  0.004510  \n",
       " 23  -0.003985 -0.000793  0.000367  0.002405 -0.002694  \n",
       " 24   0.003318  0.001319 -0.000872 -0.002783 -0.001186  \n",
       " 25  -0.001252 -0.002179  0.001551 -0.004326 -0.001356  \n",
       " 26   0.001651  0.001718  0.004869 -0.003276 -0.004667  \n",
       " 27   0.001800  0.004626 -0.003774  0.002683  0.000773  \n",
       " 28   0.002055 -0.002678 -0.001788 -0.004637 -0.000971  \n",
       " 29  -0.002074 -0.000606 -0.000830 -0.001881 -0.000906  \n",
       " ..        ...       ...       ...       ...       ...  \n",
       " 956  0.004222  0.003586 -0.000450 -0.004473  0.000844  \n",
       " 957 -0.003866 -0.001686  0.000532  0.003768  0.002087  \n",
       " 958 -0.001702 -0.002283  0.004894  0.001420 -0.004567  \n",
       " 959  0.003929 -0.000212 -0.002203 -0.003792  0.003467  \n",
       " 960 -0.002863  0.001250  0.001334  0.003624  0.002539  \n",
       " 961 -0.001587 -0.000406 -0.000004  0.004574 -0.004504  \n",
       " 962  0.000763  0.003126  0.003299 -0.000531 -0.001011  \n",
       " 963  0.002984 -0.004667  0.001455  0.003559  0.002830  \n",
       " 964  0.002110  0.001471 -0.000179  0.002121  0.004275  \n",
       " 965 -0.004445  0.003375 -0.001653 -0.001506 -0.002075  \n",
       " 966 -0.004947  0.003047  0.004530  0.002815  0.003029  \n",
       " 967 -0.003477  0.004560  0.004174  0.003756  0.002019  \n",
       " 968  0.003773  0.001699 -0.002846 -0.002536  0.002311  \n",
       " 969  0.004000  0.001716 -0.000303 -0.004337 -0.003259  \n",
       " 970  0.004309 -0.001175  0.003704  0.003630 -0.000160  \n",
       " 971 -0.003078  0.002902  0.002013 -0.004874 -0.004855  \n",
       " 972  0.000107  0.000817 -0.004584  0.002463  0.004490  \n",
       " 973  0.002270  0.001746 -0.001132 -0.000193  0.002198  \n",
       " 974  0.000849  0.003202  0.002969 -0.004057 -0.001083  \n",
       " 975 -0.000956  0.004632  0.001230 -0.004413  0.002247  \n",
       " 976  0.004270 -0.001908 -0.002235 -0.002316  0.004201  \n",
       " 977 -0.000803  0.003622 -0.003798  0.001240  0.000720  \n",
       " 978 -0.002285  0.003734  0.001220  0.003574 -0.001391  \n",
       " 979  0.004350  0.004490  0.000939  0.003965 -0.002101  \n",
       " 980  0.004966 -0.000217  0.004448 -0.000103 -0.003716  \n",
       " 981 -0.000509 -0.003213  0.003110 -0.004764 -0.002871  \n",
       " 982 -0.001405  0.003946  0.003546 -0.001438  0.001026  \n",
       " 983  0.003349  0.000262  0.002005 -0.003206  0.000724  \n",
       " 984 -0.003588 -0.003562 -0.003704  0.000357  0.002414  \n",
       " 985 -0.001443 -0.001941  0.000555  0.001872  0.000397  \n",
       " \n",
       " [986 rows x 138 columns],\n",
       " 'tfidf_tsvd_100.csv':       ID  Substitutions_var  Stop_codon_var  Fusion_var  gene_fusion_var  \\\n",
       " 0      1                  1               0           0              0.0   \n",
       " 1      2                  0               0           0              0.0   \n",
       " 2      3                  1               0           0              0.0   \n",
       " 3      4                  1               0           0              0.0   \n",
       " 4      5                  0               0           0              0.0   \n",
       " 5      6                  1               0           0              0.0   \n",
       " 6      7                  1               0           0              0.0   \n",
       " 7      8                  1               0           0              0.0   \n",
       " 8      9                  1               0           0              0.0   \n",
       " 9     10                  1               0           0              0.0   \n",
       " 10    11                  1               0           0              0.0   \n",
       " 11    12                  1               0           0              0.0   \n",
       " 12    13                  1               0           0              0.0   \n",
       " 13    14                  1               0           0              0.0   \n",
       " 14    15                  1               0           0              0.0   \n",
       " 15    16                  1               0           0              0.0   \n",
       " 16    17                  1               0           0              0.0   \n",
       " 17    18                  1               0           0              0.0   \n",
       " 18    19                  1               0           0              0.0   \n",
       " 19    20                  1               0           0              0.0   \n",
       " 20    21                  1               0           0              0.0   \n",
       " 21    22                  1               0           0              0.0   \n",
       " 22    23                  1               0           0              0.0   \n",
       " 23    24                  0               0           0              1.0   \n",
       " 24    25                  1               0           0              0.0   \n",
       " 25    26                  1               0           0              0.0   \n",
       " 26    27                  1               0           0              0.0   \n",
       " 27    28                  1               0           0              0.0   \n",
       " 28    29                  1               0           0              0.0   \n",
       " 29    30                  1               0           0              0.0   \n",
       " ..   ...                ...             ...         ...              ...   \n",
       " 956  957                  1               0           0              0.0   \n",
       " 957  958                  1               0           0              0.0   \n",
       " 958  959                  1               0           0              0.0   \n",
       " 959  960                  1               0           0              0.0   \n",
       " 960  961                  1               0           0              0.0   \n",
       " 961  962                  0               0           0              0.0   \n",
       " 962  963                  0               0           0              0.0   \n",
       " 963  964                  1               0           0              0.0   \n",
       " 964  965                  1               0           0              0.0   \n",
       " 965  966                  1               0           0              0.0   \n",
       " 966  967                  1               0           0              0.0   \n",
       " 967  968                  1               0           0              0.0   \n",
       " 968  969                  1               0           0              0.0   \n",
       " 969  970                  1               0           0              0.0   \n",
       " 970  971                  1               0           0              0.0   \n",
       " 971  972                  1               0           0              0.0   \n",
       " 972  973                  1               0           0              0.0   \n",
       " 973  974                  1               0           0              0.0   \n",
       " 974  975                  1               0           0              0.0   \n",
       " 975  976                  1               0           0              0.0   \n",
       " 976  977                  1               0           0              0.0   \n",
       " 977  978                  1               0           0              0.0   \n",
       " 978  979                  1               0           0              0.0   \n",
       " 979  980                  1               0           0              0.0   \n",
       " 980  981                  1               0           0              0.0   \n",
       " 981  982                  1               0           0              0.0   \n",
       " 982  983                  1               0           0              0.0   \n",
       " 983  984                  1               0           0              0.0   \n",
       " 984  985                  1               0           0              0.0   \n",
       " 985  986                  1               0           0              0.0   \n",
       " \n",
       "      Deletion_var  del_or_ins_var  Amplification_var  Truncation_var  \\\n",
       " 0             0.0             0.0                  0               0   \n",
       " 1             0.0             0.0                  0               1   \n",
       " 2             0.0             0.0                  0               0   \n",
       " 3             0.0             0.0                  0               0   \n",
       " 4             0.0             1.0                  0               0   \n",
       " 5             0.0             0.0                  0               0   \n",
       " 6             0.0             0.0                  0               0   \n",
       " 7             0.0             0.0                  0               0   \n",
       " 8             0.0             0.0                  0               0   \n",
       " 9             0.0             0.0                  0               0   \n",
       " 10            0.0             0.0                  0               0   \n",
       " 11            0.0             0.0                  0               0   \n",
       " 12            0.0             0.0                  0               0   \n",
       " 13            0.0             0.0                  0               0   \n",
       " 14            0.0             0.0                  0               0   \n",
       " 15            0.0             0.0                  0               0   \n",
       " 16            0.0             0.0                  0               0   \n",
       " 17            0.0             0.0                  0               0   \n",
       " 18            0.0             0.0                  0               0   \n",
       " 19            0.0             0.0                  0               0   \n",
       " 20            0.0             0.0                  0               0   \n",
       " 21            0.0             0.0                  0               0   \n",
       " 22            0.0             0.0                  0               0   \n",
       " 23            0.0             0.0                  0               0   \n",
       " 24            0.0             0.0                  0               0   \n",
       " 25            0.0             0.0                  0               0   \n",
       " 26            0.0             0.0                  0               0   \n",
       " 27            0.0             0.0                  0               0   \n",
       " 28            0.0             0.0                  0               0   \n",
       " 29            0.0             0.0                  0               0   \n",
       " ..            ...             ...                ...             ...   \n",
       " 956           0.0             0.0                  0               0   \n",
       " 957           0.0             0.0                  0               0   \n",
       " 958           0.0             0.0                  0               0   \n",
       " 959           0.0             0.0                  0               0   \n",
       " 960           0.0             0.0                  0               0   \n",
       " 961           0.0             1.0                  0               0   \n",
       " 962           1.0             0.0                  0               0   \n",
       " 963           0.0             0.0                  0               0   \n",
       " 964           0.0             0.0                  0               0   \n",
       " 965           0.0             0.0                  0               0   \n",
       " 966           0.0             0.0                  0               0   \n",
       " 967           0.0             0.0                  0               0   \n",
       " 968           0.0             0.0                  0               0   \n",
       " 969           0.0             0.0                  0               0   \n",
       " 970           0.0             0.0                  0               0   \n",
       " 971           0.0             0.0                  0               0   \n",
       " 972           0.0             0.0                  0               0   \n",
       " 973           0.0             0.0                  0               0   \n",
       " 974           0.0             0.0                  0               0   \n",
       " 975           0.0             0.0                  0               0   \n",
       " 976           0.0             0.0                  0               0   \n",
       " 977           0.0             0.0                  0               0   \n",
       " 978           0.0             0.0                  0               0   \n",
       " 979           0.0             0.0                  0               0   \n",
       " 980           0.0             0.0                  0               0   \n",
       " 981           0.0             0.0                  0               0   \n",
       " 982           0.0             0.0                  0               0   \n",
       " 983           0.0             0.0                  0               0   \n",
       " 984           0.0             0.0                  0               0   \n",
       " 985           0.0             0.0                  0               0   \n",
       " \n",
       "      exon_var     ...       tsvd_100_90  tsvd_100_91  tsvd_100_92  \\\n",
       " 0           0     ...          0.051136    -0.064537     0.013280   \n",
       " 1           0     ...         -0.009623    -0.046242    -0.024687   \n",
       " 2           0     ...         -0.015950    -0.011164    -0.017143   \n",
       " 3           0     ...         -0.028990    -0.017455    -0.015833   \n",
       " 4           0     ...         -0.028298    -0.021922     0.033257   \n",
       " 5           0     ...          0.003633     0.017127    -0.010975   \n",
       " 6           0     ...         -0.024859    -0.023065     0.010567   \n",
       " 7           0     ...         -0.020009     0.029894    -0.044784   \n",
       " 8           0     ...         -0.020198    -0.006154     0.036330   \n",
       " 9           0     ...          0.010341    -0.012949     0.026076   \n",
       " 10          0     ...         -0.014051    -0.005544    -0.003668   \n",
       " 11          0     ...         -0.034008    -0.008175    -0.030609   \n",
       " 12          0     ...          0.030524    -0.057539     0.035946   \n",
       " 13          0     ...          0.018035    -0.002750     0.001941   \n",
       " 14          0     ...          0.009624     0.010758    -0.007104   \n",
       " 15          0     ...         -0.022531     0.007846     0.015159   \n",
       " 16          0     ...         -0.020397    -0.001123    -0.007373   \n",
       " 17          0     ...         -0.029122    -0.008562     0.010967   \n",
       " 18          0     ...         -0.017137     0.008297     0.007081   \n",
       " 19          0     ...          0.011378     0.024027    -0.002159   \n",
       " 20          0     ...         -0.024888    -0.029220    -0.017481   \n",
       " 21          0     ...          0.010959     0.026147    -0.000762   \n",
       " 22          0     ...         -0.033148    -0.012930    -0.013770   \n",
       " 23          0     ...          0.004811    -0.020472    -0.030329   \n",
       " 24          0     ...          0.001537     0.006068    -0.026544   \n",
       " 25          0     ...         -0.039869    -0.006410     0.043426   \n",
       " 26          0     ...         -0.011529     0.030505    -0.005657   \n",
       " 27          0     ...          0.014243    -0.039619    -0.012452   \n",
       " 28          0     ...         -0.018088    -0.036646    -0.012280   \n",
       " 29          0     ...          0.047761    -0.060715    -0.007001   \n",
       " ..        ...     ...               ...          ...          ...   \n",
       " 956         0     ...         -0.000013    -0.005420     0.007683   \n",
       " 957         0     ...         -0.038488    -0.063254    -0.005914   \n",
       " 958         0     ...         -0.051600     0.030485    -0.010512   \n",
       " 959         0     ...         -0.031629    -0.008132    -0.024797   \n",
       " 960         0     ...          0.004150     0.056880    -0.004535   \n",
       " 961         0     ...         -0.017904    -0.014393     0.025920   \n",
       " 962         0     ...          0.020342    -0.006161    -0.025204   \n",
       " 963         0     ...          0.001520    -0.016413    -0.002413   \n",
       " 964         0     ...          0.024264     0.002476     0.014648   \n",
       " 965         0     ...          0.007944     0.012745     0.035874   \n",
       " 966         0     ...          0.009174     0.097810    -0.079139   \n",
       " 967         0     ...         -0.049937    -0.005890    -0.020829   \n",
       " 968         0     ...         -0.006430     0.018362    -0.009630   \n",
       " 969         0     ...         -0.030979     0.002331    -0.008560   \n",
       " 970         0     ...          0.003935    -0.015223     0.004218   \n",
       " 971         0     ...          0.023165    -0.016989     0.002991   \n",
       " 972         0     ...         -0.003913    -0.006735     0.007143   \n",
       " 973         0     ...         -0.011129     0.032191    -0.012299   \n",
       " 974         0     ...         -0.000164     0.027180    -0.003207   \n",
       " 975         0     ...          0.004157     0.012737    -0.010052   \n",
       " 976         0     ...         -0.025212     0.002856    -0.015792   \n",
       " 977         0     ...          0.019619     0.007786    -0.005868   \n",
       " 978         0     ...          0.003541     0.017750     0.018489   \n",
       " 979         0     ...         -0.002532    -0.016710     0.019228   \n",
       " 980         0     ...          0.021679     0.032041     0.039816   \n",
       " 981         0     ...          0.021618    -0.022476     0.021843   \n",
       " 982         0     ...          0.009557     0.035745    -0.005842   \n",
       " 983         0     ...          0.029711     0.070466     0.056033   \n",
       " 984         0     ...         -0.003017    -0.033111    -0.026511   \n",
       " 985         0     ...         -0.024481    -0.028785    -0.004831   \n",
       " \n",
       "      tsvd_100_93  tsvd_100_94  tsvd_100_95  tsvd_100_96  tsvd_100_97  \\\n",
       " 0      -0.051711    -0.008686     0.063702    -0.033369     0.047507   \n",
       " 1       0.002689     0.001146    -0.004227     0.013684    -0.019795   \n",
       " 2       0.013692     0.025594    -0.012595     0.012041     0.009233   \n",
       " 3       0.007888     0.013270    -0.043635     0.029360     0.002756   \n",
       " 4      -0.012296     0.008621    -0.002116    -0.014589    -0.009098   \n",
       " 5       0.000863    -0.018487    -0.034054    -0.025474     0.018020   \n",
       " 6       0.014682     0.035405     0.000287    -0.002926    -0.015661   \n",
       " 7      -0.002686     0.002535     0.013052     0.041337     0.006878   \n",
       " 8      -0.057816     0.043661    -0.056993    -0.018344     0.029321   \n",
       " 9       0.015974     0.019916    -0.008094    -0.030111    -0.035647   \n",
       " 10      0.016076    -0.038488    -0.006138     0.005727    -0.011831   \n",
       " 11      0.004124     0.041401     0.044187     0.006327    -0.012347   \n",
       " 12     -0.009523     0.059923    -0.057699     0.057335    -0.015719   \n",
       " 13      0.002201     0.012474     0.001954     0.053938     0.009063   \n",
       " 14     -0.001898     0.015428    -0.007819     0.015587     0.017695   \n",
       " 15      0.023245    -0.007217    -0.011820     0.003556     0.013171   \n",
       " 16     -0.009267     0.007430     0.010738     0.023042    -0.003768   \n",
       " 17      0.025018     0.017443     0.015389     0.027642    -0.063516   \n",
       " 18     -0.030830     0.098508     0.020280    -0.002138     0.016567   \n",
       " 19      0.011973     0.010937    -0.001382     0.025168     0.015134   \n",
       " 20     -0.006440    -0.002205     0.007648     0.017762    -0.032245   \n",
       " 21      0.051707    -0.007708    -0.011751    -0.004379    -0.000501   \n",
       " 22      0.048266    -0.003942    -0.006718     0.002932    -0.008119   \n",
       " 23     -0.005698     0.042732     0.018296    -0.019918     0.016466   \n",
       " 24      0.013855     0.010058    -0.011230     0.002488     0.032603   \n",
       " 25     -0.032859    -0.067035    -0.036653    -0.001485    -0.022597   \n",
       " 26     -0.032345     0.003874     0.027838    -0.054474     0.021200   \n",
       " 27     -0.045782     0.017577     0.009155    -0.018471    -0.009306   \n",
       " 28      0.027191     0.042585     0.009550    -0.019602    -0.019053   \n",
       " 29     -0.041101    -0.024852     0.004319    -0.007110     0.011242   \n",
       " ..           ...          ...          ...          ...          ...   \n",
       " 956    -0.007658     0.012154    -0.018029    -0.011289    -0.008423   \n",
       " 957     0.056374    -0.022311    -0.027941     0.019331    -0.007126   \n",
       " 958    -0.081855     0.017823     0.036209     0.063302    -0.037599   \n",
       " 959    -0.012760     0.040386    -0.010829    -0.021343    -0.013362   \n",
       " 960    -0.007152     0.000986     0.024921    -0.000999    -0.006827   \n",
       " 961     0.010755    -0.102925    -0.089625     0.034681    -0.022845   \n",
       " 962     0.000475    -0.004567    -0.020932     0.004415    -0.003056   \n",
       " 963     0.000641     0.006603     0.034714     0.001343     0.034937   \n",
       " 964     0.007525    -0.010687     0.013754     0.000242    -0.060032   \n",
       " 965     0.000767     0.002555     0.014930     0.034458    -0.000821   \n",
       " 966    -0.010697     0.010222     0.028738    -0.012810     0.101421   \n",
       " 967     0.054385     0.025034    -0.012460    -0.006200     0.018094   \n",
       " 968    -0.025726     0.031948    -0.008503    -0.024613     0.015400   \n",
       " 969     0.036986     0.005763     0.012373    -0.022348    -0.011978   \n",
       " 970     0.000647     0.001878    -0.001927     0.004111     0.005555   \n",
       " 971     0.004300     0.023908     0.023082     0.010657     0.018187   \n",
       " 972    -0.013777    -0.027479     0.008085    -0.013028    -0.021680   \n",
       " 973     0.051360    -0.010182     0.006550     0.002169     0.020846   \n",
       " 974    -0.024585    -0.007336    -0.017340    -0.002462     0.002455   \n",
       " 975    -0.016493    -0.015317     0.013800     0.009617    -0.023624   \n",
       " 976     0.038130    -0.011176     0.042560     0.035254    -0.023301   \n",
       " 977    -0.007188    -0.024172     0.015933     0.009245    -0.039699   \n",
       " 978     0.003212    -0.004919     0.026681     0.015545     0.015496   \n",
       " 979     0.011997    -0.040241    -0.007928     0.010460     0.016918   \n",
       " 980     0.014840    -0.009871     0.028949     0.010911    -0.001771   \n",
       " 981     0.023852     0.005158    -0.012084     0.010867     0.036288   \n",
       " 982     0.013066     0.001824    -0.023706     0.011661    -0.065897   \n",
       " 983    -0.037786     0.036171     0.023641     0.032657     0.073908   \n",
       " 984    -0.007198     0.020134    -0.009751    -0.023082     0.003664   \n",
       " 985    -0.042057    -0.059556     0.026780     0.011944     0.021789   \n",
       " \n",
       "      tsvd_100_98  tsvd_100_99  \n",
       " 0      -0.011223    -0.025000  \n",
       " 1      -0.023560     0.012469  \n",
       " 2       0.001668    -0.041702  \n",
       " 3      -0.036137    -0.002726  \n",
       " 4       0.006339     0.012608  \n",
       " 5       0.011501    -0.002968  \n",
       " 6      -0.015077    -0.038714  \n",
       " 7      -0.007241     0.024137  \n",
       " 8      -0.027651     0.022929  \n",
       " 9       0.016012    -0.024145  \n",
       " 10     -0.071792    -0.045738  \n",
       " 11     -0.035557    -0.030858  \n",
       " 12      0.063174     0.009297  \n",
       " 13     -0.013379    -0.027928  \n",
       " 14     -0.031232     0.008454  \n",
       " 15     -0.013801     0.003631  \n",
       " 16      0.025693    -0.031111  \n",
       " 17     -0.010742    -0.021103  \n",
       " 18      0.058039    -0.051571  \n",
       " 19     -0.021840     0.011064  \n",
       " 20     -0.024125     0.027851  \n",
       " 21     -0.022172    -0.001265  \n",
       " 22      0.029783     0.030334  \n",
       " 23      0.020951     0.010637  \n",
       " 24     -0.012556    -0.001941  \n",
       " 25      0.014971    -0.012888  \n",
       " 26      0.062335    -0.017426  \n",
       " 27      0.003947    -0.011061  \n",
       " 28     -0.004750     0.001856  \n",
       " 29      0.006551    -0.024656  \n",
       " ..           ...          ...  \n",
       " 956    -0.008038     0.001655  \n",
       " 957     0.006075    -0.030255  \n",
       " 958    -0.017483    -0.007580  \n",
       " 959    -0.012785    -0.020401  \n",
       " 960     0.044572    -0.026911  \n",
       " 961     0.042648     0.062812  \n",
       " 962    -0.014628     0.003386  \n",
       " 963     0.000475    -0.033486  \n",
       " 964    -0.007774     0.004998  \n",
       " 965    -0.013426     0.018680  \n",
       " 966     0.124255    -0.010983  \n",
       " 967     0.011509     0.013093  \n",
       " 968     0.027094     0.014422  \n",
       " 969     0.029581     0.035954  \n",
       " 970    -0.003645     0.027136  \n",
       " 971     0.010691    -0.014933  \n",
       " 972    -0.000108     0.009736  \n",
       " 973     0.023785     0.037617  \n",
       " 974     0.016052     0.010592  \n",
       " 975     0.047490     0.020412  \n",
       " 976     0.036834     0.037147  \n",
       " 977    -0.003479     0.018315  \n",
       " 978    -0.009649     0.012350  \n",
       " 979     0.024508    -0.017201  \n",
       " 980     0.003372     0.049019  \n",
       " 981     0.041053    -0.020226  \n",
       " 982     0.000385     0.028368  \n",
       " 983     0.036812     0.010418  \n",
       " 984     0.008327    -0.015459  \n",
       " 985     0.079927     0.014912  \n",
       " \n",
       " [986 rows x 138 columns],\n",
       " 'w2v_100.csv':       ID  Substitutions_var  Stop_codon_var  Fusion_var  gene_fusion_var  \\\n",
       " 0      1                  1               0           0              0.0   \n",
       " 1      2                  0               0           0              0.0   \n",
       " 2      3                  1               0           0              0.0   \n",
       " 3      4                  1               0           0              0.0   \n",
       " 4      5                  0               0           0              0.0   \n",
       " 5      6                  1               0           0              0.0   \n",
       " 6      7                  1               0           0              0.0   \n",
       " 7      8                  1               0           0              0.0   \n",
       " 8      9                  1               0           0              0.0   \n",
       " 9     10                  1               0           0              0.0   \n",
       " 10    11                  1               0           0              0.0   \n",
       " 11    12                  1               0           0              0.0   \n",
       " 12    13                  1               0           0              0.0   \n",
       " 13    14                  1               0           0              0.0   \n",
       " 14    15                  1               0           0              0.0   \n",
       " 15    16                  1               0           0              0.0   \n",
       " 16    17                  1               0           0              0.0   \n",
       " 17    18                  1               0           0              0.0   \n",
       " 18    19                  1               0           0              0.0   \n",
       " 19    20                  1               0           0              0.0   \n",
       " 20    21                  1               0           0              0.0   \n",
       " 21    22                  1               0           0              0.0   \n",
       " 22    23                  1               0           0              0.0   \n",
       " 23    24                  0               0           0              1.0   \n",
       " 24    25                  1               0           0              0.0   \n",
       " 25    26                  1               0           0              0.0   \n",
       " 26    27                  1               0           0              0.0   \n",
       " 27    28                  1               0           0              0.0   \n",
       " 28    29                  1               0           0              0.0   \n",
       " 29    30                  1               0           0              0.0   \n",
       " ..   ...                ...             ...         ...              ...   \n",
       " 955  956                  1               0           0              0.0   \n",
       " 956  957                  1               0           0              0.0   \n",
       " 957  958                  1               0           0              0.0   \n",
       " 958  959                  1               0           0              0.0   \n",
       " 959  960                  1               0           0              0.0   \n",
       " 960  961                  1               0           0              0.0   \n",
       " 961  962                  0               0           0              0.0   \n",
       " 962  963                  0               0           0              0.0   \n",
       " 963  964                  1               0           0              0.0   \n",
       " 964  965                  1               0           0              0.0   \n",
       " 965  966                  1               0           0              0.0   \n",
       " 966  967                  1               0           0              0.0   \n",
       " 967  968                  1               0           0              0.0   \n",
       " 968  969                  1               0           0              0.0   \n",
       " 969  970                  1               0           0              0.0   \n",
       " 970  971                  1               0           0              0.0   \n",
       " 971  972                  1               0           0              0.0   \n",
       " 972  973                  1               0           0              0.0   \n",
       " 973  974                  1               0           0              0.0   \n",
       " 974  975                  1               0           0              0.0   \n",
       " 975  976                  1               0           0              0.0   \n",
       " 976  977                  1               0           0              0.0   \n",
       " 977  978                  1               0           0              0.0   \n",
       " 978  979                  1               0           0              0.0   \n",
       " 979  980                  1               0           0              0.0   \n",
       " 980  981                  1               0           0              0.0   \n",
       " 981  982                  1               0           0              0.0   \n",
       " 982  983                  1               0           0              0.0   \n",
       " 983  984                  1               0           0              0.0   \n",
       " 984  985                  1               0           0              0.0   \n",
       " \n",
       "      Deletion_var  del_or_ins_var  Amplification_var  Truncation_var  \\\n",
       " 0             0.0             0.0                  0               0   \n",
       " 1             0.0             0.0                  0               1   \n",
       " 2             0.0             0.0                  0               0   \n",
       " 3             0.0             0.0                  0               0   \n",
       " 4             0.0             1.0                  0               0   \n",
       " 5             0.0             0.0                  0               0   \n",
       " 6             0.0             0.0                  0               0   \n",
       " 7             0.0             0.0                  0               0   \n",
       " 8             0.0             0.0                  0               0   \n",
       " 9             0.0             0.0                  0               0   \n",
       " 10            0.0             0.0                  0               0   \n",
       " 11            0.0             0.0                  0               0   \n",
       " 12            0.0             0.0                  0               0   \n",
       " 13            0.0             0.0                  0               0   \n",
       " 14            0.0             0.0                  0               0   \n",
       " 15            0.0             0.0                  0               0   \n",
       " 16            0.0             0.0                  0               0   \n",
       " 17            0.0             0.0                  0               0   \n",
       " 18            0.0             0.0                  0               0   \n",
       " 19            0.0             0.0                  0               0   \n",
       " 20            0.0             0.0                  0               0   \n",
       " 21            0.0             0.0                  0               0   \n",
       " 22            0.0             0.0                  0               0   \n",
       " 23            0.0             0.0                  0               0   \n",
       " 24            0.0             0.0                  0               0   \n",
       " 25            0.0             0.0                  0               0   \n",
       " 26            0.0             0.0                  0               0   \n",
       " 27            0.0             0.0                  0               0   \n",
       " 28            0.0             0.0                  0               0   \n",
       " 29            0.0             0.0                  0               0   \n",
       " ..            ...             ...                ...             ...   \n",
       " 955           0.0             0.0                  0               0   \n",
       " 956           0.0             0.0                  0               0   \n",
       " 957           0.0             0.0                  0               0   \n",
       " 958           0.0             0.0                  0               0   \n",
       " 959           0.0             0.0                  0               0   \n",
       " 960           0.0             0.0                  0               0   \n",
       " 961           0.0             1.0                  0               0   \n",
       " 962           1.0             0.0                  0               0   \n",
       " 963           0.0             0.0                  0               0   \n",
       " 964           0.0             0.0                  0               0   \n",
       " 965           0.0             0.0                  0               0   \n",
       " 966           0.0             0.0                  0               0   \n",
       " 967           0.0             0.0                  0               0   \n",
       " 968           0.0             0.0                  0               0   \n",
       " 969           0.0             0.0                  0               0   \n",
       " 970           0.0             0.0                  0               0   \n",
       " 971           0.0             0.0                  0               0   \n",
       " 972           0.0             0.0                  0               0   \n",
       " 973           0.0             0.0                  0               0   \n",
       " 974           0.0             0.0                  0               0   \n",
       " 975           0.0             0.0                  0               0   \n",
       " 976           0.0             0.0                  0               0   \n",
       " 977           0.0             0.0                  0               0   \n",
       " 978           0.0             0.0                  0               0   \n",
       " 979           0.0             0.0                  0               0   \n",
       " 980           0.0             0.0                  0               0   \n",
       " 981           0.0             0.0                  0               0   \n",
       " 982           0.0             0.0                  0               0   \n",
       " 983           0.0             0.0                  0               0   \n",
       " 984           0.0             0.0                  0               0   \n",
       " \n",
       "      exon_var    ...           90        91        92        93        94  \\\n",
       " 0           0    ...    -0.560591 -0.217440  1.509804 -0.372604 -0.321935   \n",
       " 1           0    ...    -0.461699 -0.091269  1.266158 -0.130519 -0.188111   \n",
       " 2           0    ...    -0.583703 -0.230117  1.656022 -0.357887 -0.064712   \n",
       " 3           0    ...    -0.938934 -0.113299  1.721324 -0.318640 -0.242833   \n",
       " 4           0    ...    -0.713793 -0.215930  1.579704 -0.415306 -0.143500   \n",
       " 5           0    ...    -0.703395  0.005410  1.552233 -0.093403 -0.281877   \n",
       " 6           0    ...    -0.661601 -0.058028  1.337800 -0.483264 -0.415883   \n",
       " 7           0    ...    -0.526700 -0.000386  1.545040 -0.106476 -0.412201   \n",
       " 8           0    ...    -0.984189 -0.158234  1.666638 -0.146327 -0.280690   \n",
       " 9           0    ...    -0.588758 -0.128085  1.530606 -0.177643 -0.279759   \n",
       " 10          0    ...    -0.295846  0.014319  1.339524 -0.217211 -0.484747   \n",
       " 11          0    ...    -0.579791 -0.113374  1.412108 -0.493285 -0.247310   \n",
       " 12          0    ...    -0.624620  0.243312  1.631354  0.126190 -0.097017   \n",
       " 13          0    ...    -0.800911 -0.053113  1.654557 -0.356543 -0.212017   \n",
       " 14          0    ...    -0.837973  0.057795  1.683786 -0.196513  0.041078   \n",
       " 15          0    ...    -0.571769 -0.054435  1.429483 -0.240358 -0.026774   \n",
       " 16          0    ...    -0.567477  0.289351  1.547143  0.023404 -0.230009   \n",
       " 17          0    ...    -0.780308  0.002835  1.710478 -0.167246 -0.335772   \n",
       " 18          0    ...    -0.582879 -0.010378  1.445924 -0.290612 -0.234701   \n",
       " 19          0    ...    -0.581789 -0.141946  1.458142 -0.172371 -0.574529   \n",
       " 20          0    ...    -0.449514 -0.046563  1.202033 -0.126560 -0.071393   \n",
       " 21          0    ...    -0.609384 -0.142742  1.406593 -0.310164 -0.226220   \n",
       " 22          0    ...    -0.933188  0.026225  1.619292 -0.458163  0.187311   \n",
       " 23          0    ...    -0.592010 -0.113260  1.434067 -0.364821 -0.036587   \n",
       " 24          0    ...    -0.719540  0.077393  1.667673  0.015373 -0.183554   \n",
       " 25          0    ...    -0.598630 -0.052560  1.353695 -0.320614 -0.264984   \n",
       " 26          0    ...    -0.531949 -0.077169  1.371247 -0.223602 -0.172377   \n",
       " 27          0    ...    -0.730300 -0.095174  1.547943 -0.232377 -0.146851   \n",
       " 28          0    ...    -0.428380 -0.010102  1.498633 -0.117088 -0.370480   \n",
       " 29          0    ...    -0.422257 -0.007734  1.410228 -0.072896 -0.020948   \n",
       " ..        ...    ...          ...       ...       ...       ...       ...   \n",
       " 955         0    ...    -0.748586  0.100029  1.460963 -0.335282 -0.598048   \n",
       " 956         0    ...    -1.162975  0.023806  2.065993 -0.464780 -0.195240   \n",
       " 957         0    ...    -0.822896  0.082826  1.489282 -0.098531 -0.280450   \n",
       " 958         0    ...    -0.599056 -0.064039  1.401014 -0.412646 -0.130556   \n",
       " 959         0    ...    -0.421952 -0.144384  1.167414 -0.406551 -0.281770   \n",
       " 960         0    ...    -0.615478  0.173923  1.536186 -0.104671 -0.245038   \n",
       " 961         0    ...    -0.443131 -0.118385  1.248935 -0.234416 -0.078332   \n",
       " 962         0    ...    -0.449315 -0.047126  1.397005 -0.004027 -0.189290   \n",
       " 963         0    ...    -1.006283  0.194343  1.886811 -0.213835 -0.086513   \n",
       " 964         0    ...    -0.450018 -0.008031  1.606947 -0.076458 -0.255812   \n",
       " 965         0    ...    -0.776616 -0.059948  1.753153 -0.162556 -0.262580   \n",
       " 966         0    ...    -0.401635  0.059220  1.504645 -0.181061 -0.403070   \n",
       " 967         0    ...    -0.614273 -0.086159  1.571903 -0.157398 -0.240486   \n",
       " 968         0    ...    -0.381705 -0.164202  1.407366 -0.038606 -0.084638   \n",
       " 969         0    ...    -0.698052 -0.101785  1.645583 -0.275430 -0.343840   \n",
       " 970         0    ...    -0.617893 -0.128574  1.434259 -0.280074 -0.419781   \n",
       " 971         0    ...    -0.945337 -0.303268  1.731651 -0.300895 -0.173930   \n",
       " 972         0    ...    -0.555377  0.041557  1.468323 -0.032081 -0.231127   \n",
       " 973         0    ...    -0.537596 -0.160996  1.549290 -0.437908 -0.376443   \n",
       " 974         0    ...    -0.541618 -0.142912  1.238564 -0.333193 -0.189983   \n",
       " 975         0    ...    -0.684121 -0.325182  1.570804 -0.265294 -0.447618   \n",
       " 976         0    ...    -0.336615 -0.089308  1.109990 -0.073929 -0.133017   \n",
       " 977         0    ...    -0.583168 -0.094521  1.670355 -0.166530 -0.236284   \n",
       " 978         0    ...    -0.612507  0.026102  1.449675 -0.147272  0.149107   \n",
       " 979         0    ...    -0.703948 -0.136039  1.405875 -0.208474 -0.046363   \n",
       " 980         0    ...    -0.445261 -0.188632  1.357602 -0.250389 -0.197722   \n",
       " 981         0    ...    -0.489182 -0.033051  1.173781 -0.399977 -0.092028   \n",
       " 982         0    ...    -0.429906 -0.270626  1.437210 -0.210286 -0.422595   \n",
       " 983         0    ...    -0.530086  0.031208  1.365604 -0.136008 -0.036372   \n",
       " 984         0    ...    -0.463452 -0.083635  1.406907 -0.264828 -0.143729   \n",
       " \n",
       "            95        96        97        98        99  \n",
       " 0    0.537585  0.605142 -0.010238 -0.203764  0.222885  \n",
       " 1    0.603840  0.702891 -0.123344 -0.206443  0.153253  \n",
       " 2    0.531142  0.433710 -0.065807 -0.425615  0.344359  \n",
       " 3    0.284507  0.420027  0.035817 -0.460874  0.278028  \n",
       " 4    0.481088  0.298617  0.008028 -0.491950  0.431286  \n",
       " 5    0.270667  0.461864 -0.075522 -0.239264  0.157155  \n",
       " 6    0.689163  0.716914 -0.349329 -0.001992 -0.065596  \n",
       " 7    0.488790  0.474683 -0.105720 -0.180117  0.118355  \n",
       " 8    0.360492  0.348760  0.112174 -0.368362  0.273853  \n",
       " 9    0.512631  0.383329 -0.029601 -0.380948  0.355037  \n",
       " 10   0.552363  0.862279 -0.069053 -0.409786 -0.206091  \n",
       " 11   0.562994  0.630891 -0.199881  0.006298  0.125049  \n",
       " 12   0.139579  0.674597 -0.137435 -0.386334  0.224762  \n",
       " 13   0.406428  0.729814 -0.385534 -0.391498  0.126242  \n",
       " 14   0.397522  0.724072 -0.310204 -0.402298  0.310779  \n",
       " 15   0.490185  0.640807 -0.106229 -0.291747  0.276354  \n",
       " 16   0.512194  0.595059 -0.124993 -0.316471  0.064954  \n",
       " 17   0.167362  0.605726 -0.027759 -0.375266  0.358652  \n",
       " 18   0.432492  0.722670 -0.325806 -0.317624  0.117617  \n",
       " 19   0.508267  0.449473 -0.137140 -0.321651  0.236468  \n",
       " 20   0.428413  0.627792  0.095963 -0.306740  0.292671  \n",
       " 21   0.405151  0.522067  0.036665 -0.252187  0.309871  \n",
       " 22   0.244513  0.396049  0.133659 -0.338944  0.300870  \n",
       " 23   0.438060  0.531475  0.035700 -0.419249  0.255659  \n",
       " 24   0.407835  0.673925 -0.107374 -0.369834  0.245849  \n",
       " 25   0.462147  0.488606 -0.159573 -0.144142  0.051043  \n",
       " 26   0.489159  0.667017  0.026087 -0.203328  0.155821  \n",
       " 27   0.478528  0.402121  0.241803 -0.451279  0.296915  \n",
       " 28   0.553428  0.707440 -0.158749 -0.336643  0.030924  \n",
       " 29   0.449392  0.745336 -0.022814 -0.477725  0.367216  \n",
       " ..        ...       ...       ...       ...       ...  \n",
       " 955  0.536029  0.613092 -0.276617 -0.230643 -0.046567  \n",
       " 956  0.312037  0.255744  0.004299 -0.594360  0.011492  \n",
       " 957  0.634818  0.377826  0.165926 -0.387077 -0.187665  \n",
       " 958  0.503160  0.459804 -0.083183 -0.170133  0.112838  \n",
       " 959  0.768613  0.763336 -0.209220 -0.189399 -0.005874  \n",
       " 960  0.127559  0.751465 -0.262063 -0.501072 -0.105156  \n",
       " 961  0.577118  0.555277  0.247332 -0.359145  0.282294  \n",
       " 962  0.487125  0.861438 -0.188086 -0.332885  0.240494  \n",
       " 963  0.184035  0.466504 -0.081324 -0.462873 -0.044868  \n",
       " 964  0.392298  0.925308 -0.139923 -0.501942  0.219187  \n",
       " 965  0.525621  0.346110  0.082316 -0.263164  0.053089  \n",
       " 966  0.307675  0.744136 -0.255659 -0.348506  0.091349  \n",
       " 967  0.414792  0.334296  0.051866 -0.376294  0.339428  \n",
       " 968  0.477693  0.492525  0.120614 -0.472306  0.315237  \n",
       " 969  0.515326  0.820309 -0.306864 -0.394099  0.305652  \n",
       " 970  0.609895  0.696482 -0.110201 -0.314800  0.184411  \n",
       " 971  0.343307  0.826051 -0.237628 -0.591922  0.359416  \n",
       " 972  0.330313  0.666234 -0.012534 -0.442837  0.249354  \n",
       " 973  0.404012  0.672846 -0.141137 -0.313864  0.166781  \n",
       " 974  0.567862  0.694550  0.092765 -0.401449  0.204712  \n",
       " 975  0.418601  0.602876 -0.148345 -0.453014  0.254594  \n",
       " 976  0.355322  0.659767  0.166587 -0.439016  0.369317  \n",
       " 977  0.417530  0.717914 -0.101721 -0.552212  0.243444  \n",
       " 978  0.388412  0.553779  0.283950 -0.473404  0.375267  \n",
       " 979  0.439696  0.582242 -0.073558 -0.476699  0.326498  \n",
       " 980  0.591875  0.473874  0.054552 -0.385277  0.231080  \n",
       " 981  0.384891  0.762762 -0.020622 -0.186770  0.149504  \n",
       " 982  0.615334  0.425490 -0.135878 -0.434664  0.340177  \n",
       " 983  0.463668  0.539296  0.099885 -0.215862  0.277923  \n",
       " 984  0.378826  0.590308 -0.181089 -0.353088  0.249588  \n",
       " \n",
       " [985 rows x 138 columns]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
