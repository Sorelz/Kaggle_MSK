{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import keras\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train= {} \n",
    "work_test = {}\n",
    "pre_process=[\"tfidf_tsvd_100.csv\",\"w2v_100.csv\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"../bases/new_training_variants.csv\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_feat=pd.read_csv(\"../l2_meta_features/svd25_molecular_functions.csv\")\n",
    "magic_feat=magic_feat.drop([\"Class\",\"Gene\",\"ID\",\"Variation\"],axis=1)\n",
    "magic_train=magic_feat[:len(y)]\n",
    "magic_test=magic_feat[len(y):]\n",
    "magic_train=magic_train.reset_index(drop=True)\n",
    "magic_test=magic_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_test=work_test[\"w2v_100\"][\"ID\"]\n",
    "ID_train=work_train[\"w2v_100\"][\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train=work_train[\"tfidf_tsvd_100\"]#.merge(work_train[\"w2v_100\"])\n",
    "deep_train=deep_train.drop(\"ID\",axis=1)\n",
    "deep_test=work_test[\"tfidf_tsvd_100\"]#.merge(work_test[\"w2v_100\"])\n",
    "deep_test=deep_test.drop(\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train_1=pd.concat((deep_train,magic_train),axis=1)\n",
    "deep_test_1=pd.concat((deep_test,magic_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train_1[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Substitutions_var', 'Stop_codon_var', 'Fusion_var', 'gene_fusion_var',\n",
       "       'Deletion_var', 'del_or_ins_var', 'Amplification_var', 'Truncation_var',\n",
       "       'exon_var', 'frameshift_var',\n",
       "       ...\n",
       "       'molecular_SVD_16', 'molecular_SVD_17', 'molecular_SVD_18',\n",
       "       'molecular_SVD_19', 'molecular_SVD_20', 'molecular_SVD_21',\n",
       "       'molecular_SVD_22', 'molecular_SVD_23', 'molecular_SVD_24',\n",
       "       'molecular_SVD_25'],\n",
       "      dtype='object', length=162)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_train_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Substitutions_var', 'Stop_codon_var', 'Fusion_var', 'gene_fusion_var',\n",
       "       'Deletion_var', 'del_or_ins_var', 'Amplification_var', 'Truncation_var',\n",
       "       'exon_var', 'frameshift_var',\n",
       "       ...\n",
       "       'molecular_SVD_16', 'molecular_SVD_17', 'molecular_SVD_18',\n",
       "       'molecular_SVD_19', 'molecular_SVD_20', 'molecular_SVD_21',\n",
       "       'molecular_SVD_22', 'molecular_SVD_23', 'molecular_SVD_24',\n",
       "       'molecular_SVD_25'],\n",
       "      dtype='object', length=162)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_test_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3689, 162)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2356 samples, validate on 590 samples\n",
      "Epoch 1/100\n",
      "2356/2356 [==============================] - 2s - loss: 12.8008 - acc: 0.2003 - val_loss: 10.1937 - val_acc: 0.3661\n",
      "Epoch 2/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.9090 - acc: 0.2585 - val_loss: 10.1936 - val_acc: 0.3661\n",
      "Epoch 3/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.9060 - acc: 0.2602 - val_loss: 10.1935 - val_acc: 0.3661\n",
      "Epoch 4/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.9353 - acc: 0.2568 - val_loss: 10.1935 - val_acc: 0.3661\n",
      "Epoch 5/100\n",
      "2356/2356 [==============================] - 0s - loss: 12.7862 - acc: 0.2029 - val_loss: 13.1713 - val_acc: 0.1814\n",
      "Epoch 6/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.1121 - acc: 0.1842 - val_loss: 13.1713 - val_acc: 0.1814\n",
      "Epoch 7/100\n",
      "2356/2356 [==============================] - 0s - loss: 12.7104 - acc: 0.2076 - val_loss: 13.1712 - val_acc: 0.1814\n",
      "Epoch 8/100\n",
      "2356/2356 [==============================] - 0s - loss: 12.6024 - acc: 0.2152 - val_loss: 10.1935 - val_acc: 0.3661\n",
      "Epoch 9/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.9914 - acc: 0.2525 - val_loss: 10.1936 - val_acc: 0.3661\n",
      "Epoch 10/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8292 - acc: 0.2657 - val_loss: 10.1936 - val_acc: 0.3661\n",
      "Epoch 11/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8277 - acc: 0.2661 - val_loss: 10.1936 - val_acc: 0.3661\n",
      "Epoch 12/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8482 - acc: 0.2644 - val_loss: 10.1937 - val_acc: 0.3661\n",
      "Epoch 13/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8199 - acc: 0.2657 - val_loss: 10.1937 - val_acc: 0.3661\n",
      "Epoch 14/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8219 - acc: 0.2657 - val_loss: 10.1937 - val_acc: 0.3661\n",
      "Epoch 15/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8377 - acc: 0.2649 - val_loss: 10.1938 - val_acc: 0.3661\n",
      "Epoch 16/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8205 - acc: 0.2661 - val_loss: 10.1938 - val_acc: 0.3661\n",
      "Epoch 17/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8378 - acc: 0.2649 - val_loss: 10.1939 - val_acc: 0.3661\n",
      "Epoch 18/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8225 - acc: 0.2661 - val_loss: 10.1941 - val_acc: 0.3661\n",
      "Epoch 19/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8266 - acc: 0.2657 - val_loss: 10.1942 - val_acc: 0.3661\n",
      "Epoch 20/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8206 - acc: 0.2657 - val_loss: 10.1941 - val_acc: 0.3661\n",
      "Epoch 21/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8054 - acc: 0.2666 - val_loss: 10.1942 - val_acc: 0.3661\n",
      "Epoch 22/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8196 - acc: 0.2666 - val_loss: 10.1943 - val_acc: 0.3661\n",
      "Epoch 23/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8441 - acc: 0.2649 - val_loss: 10.1948 - val_acc: 0.3661\n",
      "Epoch 24/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8413 - acc: 0.2653 - val_loss: 10.1950 - val_acc: 0.3661\n",
      "Epoch 25/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8476 - acc: 0.2649 - val_loss: 10.1950 - val_acc: 0.3661\n",
      "Epoch 26/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8355 - acc: 0.2649 - val_loss: 10.1953 - val_acc: 0.3661\n",
      "Epoch 27/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8222 - acc: 0.2666 - val_loss: 10.1954 - val_acc: 0.3661\n",
      "Epoch 28/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8222 - acc: 0.2661 - val_loss: 10.1956 - val_acc: 0.3661\n",
      "Epoch 29/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8223 - acc: 0.2666 - val_loss: 10.1957 - val_acc: 0.3661\n",
      "Epoch 30/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8221 - acc: 0.2666 - val_loss: 10.1957 - val_acc: 0.3661\n",
      "Epoch 31/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8221 - acc: 0.2666 - val_loss: 10.1958 - val_acc: 0.3661\n",
      "Epoch 32/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8138 - acc: 0.2670 - val_loss: 10.1958 - val_acc: 0.3661\n",
      "Epoch 33/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8218 - acc: 0.2666 - val_loss: 10.1958 - val_acc: 0.3661\n",
      "Epoch 34/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8220 - acc: 0.2666 - val_loss: 10.1959 - val_acc: 0.3661\n",
      "Epoch 35/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8220 - acc: 0.2666 - val_loss: 10.1961 - val_acc: 0.3661\n",
      "Epoch 36/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8220 - acc: 0.2666 - val_loss: 10.1962 - val_acc: 0.3661\n",
      "Epoch 37/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8213 - acc: 0.2661 - val_loss: 10.1962 - val_acc: 0.3661\n",
      "Epoch 38/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8220 - acc: 0.2666 - val_loss: 10.1963 - val_acc: 0.3661\n",
      "Epoch 39/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8207 - acc: 0.2661 - val_loss: 10.1963 - val_acc: 0.3661\n",
      "Epoch 40/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8208 - acc: 0.2666 - val_loss: 10.1963 - val_acc: 0.3661\n",
      "Epoch 41/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8216 - acc: 0.2666 - val_loss: 10.1964 - val_acc: 0.3661\n",
      "Epoch 42/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8151 - acc: 0.2670 - val_loss: 10.1965 - val_acc: 0.3661\n",
      "Epoch 43/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8287 - acc: 0.2661 - val_loss: 10.1966 - val_acc: 0.3661\n",
      "Epoch 44/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8274 - acc: 0.2657 - val_loss: 10.1968 - val_acc: 0.3661\n",
      "Epoch 45/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8221 - acc: 0.2666 - val_loss: 10.1968 - val_acc: 0.3661\n",
      "Epoch 46/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8217 - acc: 0.2666 - val_loss: 10.1969 - val_acc: 0.3661\n",
      "Epoch 47/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8197 - acc: 0.2666 - val_loss: 10.1970 - val_acc: 0.3661\n",
      "Epoch 48/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8198 - acc: 0.2666 - val_loss: 10.1971 - val_acc: 0.3661\n",
      "Epoch 49/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8213 - acc: 0.2666 - val_loss: 10.1972 - val_acc: 0.3661\n",
      "Epoch 50/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8206 - acc: 0.2666 - val_loss: 10.1974 - val_acc: 0.3661\n",
      "Epoch 51/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8185 - acc: 0.2661 - val_loss: 10.1973 - val_acc: 0.3661\n",
      "Epoch 52/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8176 - acc: 0.2666 - val_loss: 10.1975 - val_acc: 0.3661\n",
      "Epoch 53/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8151 - acc: 0.2666 - val_loss: 10.1974 - val_acc: 0.3661\n",
      "Epoch 54/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8146 - acc: 0.2666 - val_loss: 10.1975 - val_acc: 0.3661\n",
      "Epoch 55/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8113 - acc: 0.2666 - val_loss: 10.1976 - val_acc: 0.3661\n",
      "Epoch 56/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8254 - acc: 0.2661 - val_loss: 10.1977 - val_acc: 0.3661\n",
      "Epoch 57/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8139 - acc: 0.2666 - val_loss: 10.1977 - val_acc: 0.3661\n",
      "Epoch 58/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8180 - acc: 0.2666 - val_loss: 10.1978 - val_acc: 0.3661\n",
      "Epoch 59/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8293 - acc: 0.2649 - val_loss: 10.1981 - val_acc: 0.3661\n",
      "Epoch 60/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8189 - acc: 0.2666 - val_loss: 10.1981 - val_acc: 0.3661\n",
      "Epoch 61/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8117 - acc: 0.2666 - val_loss: 10.1983 - val_acc: 0.3661\n",
      "Epoch 62/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8153 - acc: 0.2666 - val_loss: 10.1983 - val_acc: 0.3661\n",
      "Epoch 63/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8186 - acc: 0.2666 - val_loss: 10.1986 - val_acc: 0.3661\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2356/2356 [==============================] - 0s - loss: 11.8191 - acc: 0.2666 - val_loss: 10.1988 - val_acc: 0.3661\n",
      "Epoch 65/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8186 - acc: 0.2666 - val_loss: 10.1989 - val_acc: 0.3661\n",
      "Epoch 66/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8101 - acc: 0.2670 - val_loss: 10.1992 - val_acc: 0.3661\n",
      "Epoch 67/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8236 - acc: 0.2661 - val_loss: 10.1994 - val_acc: 0.3661\n",
      "Epoch 68/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8045 - acc: 0.2666 - val_loss: 10.1996 - val_acc: 0.3661\n",
      "Epoch 69/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8217 - acc: 0.2661 - val_loss: 10.2000 - val_acc: 0.3661\n",
      "Epoch 70/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.7968 - acc: 0.2678 - val_loss: 10.2003 - val_acc: 0.3661\n",
      "Epoch 71/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8307 - acc: 0.2653 - val_loss: 10.1947 - val_acc: 0.3661\n",
      "Epoch 72/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.7894 - acc: 0.2670 - val_loss: 10.1998 - val_acc: 0.3661\n",
      "Epoch 73/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8282 - acc: 0.2657 - val_loss: 10.2002 - val_acc: 0.3661\n",
      "Epoch 74/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8314 - acc: 0.2653 - val_loss: 10.2001 - val_acc: 0.3661\n",
      "Epoch 75/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8051 - acc: 0.2670 - val_loss: 10.2003 - val_acc: 0.3661\n",
      "Epoch 76/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8221 - acc: 0.2657 - val_loss: 10.1941 - val_acc: 0.3661\n",
      "Epoch 77/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8289 - acc: 0.2653 - val_loss: 10.1954 - val_acc: 0.3661\n",
      "Epoch 78/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.9447 - acc: 0.2547 - val_loss: 10.1900 - val_acc: 0.3661\n",
      "Epoch 79/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8177 - acc: 0.2644 - val_loss: 10.2009 - val_acc: 0.3661\n",
      "Epoch 80/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8400 - acc: 0.2653 - val_loss: 10.2010 - val_acc: 0.3661\n",
      "Epoch 81/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8259 - acc: 0.2657 - val_loss: 10.2012 - val_acc: 0.3661\n",
      "Epoch 82/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8178 - acc: 0.2666 - val_loss: 10.2011 - val_acc: 0.3661\n",
      "Epoch 83/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8057 - acc: 0.2661 - val_loss: 10.2010 - val_acc: 0.3661\n",
      "Epoch 84/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8121 - acc: 0.2670 - val_loss: 10.2010 - val_acc: 0.3661\n",
      "Epoch 85/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8305 - acc: 0.2657 - val_loss: 10.2013 - val_acc: 0.3661\n",
      "Epoch 86/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8241 - acc: 0.2661 - val_loss: 10.2013 - val_acc: 0.3661\n",
      "Epoch 87/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8121 - acc: 0.2661 - val_loss: 10.2011 - val_acc: 0.3661\n",
      "Epoch 88/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8122 - acc: 0.2666 - val_loss: 10.2011 - val_acc: 0.3661\n",
      "Epoch 89/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8166 - acc: 0.2666 - val_loss: 10.2011 - val_acc: 0.3661\n",
      "Epoch 90/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8245 - acc: 0.2661 - val_loss: 10.2013 - val_acc: 0.3661\n",
      "Epoch 91/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8123 - acc: 0.2670 - val_loss: 10.2014 - val_acc: 0.3661\n",
      "Epoch 92/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8184 - acc: 0.2666 - val_loss: 10.2015 - val_acc: 0.3661\n",
      "Epoch 93/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.7952 - acc: 0.2670 - val_loss: 10.2019 - val_acc: 0.3661\n",
      "Epoch 94/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8241 - acc: 0.2661 - val_loss: 10.2021 - val_acc: 0.3661\n",
      "Epoch 95/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8180 - acc: 0.2666 - val_loss: 10.2023 - val_acc: 0.3661\n",
      "Epoch 96/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8199 - acc: 0.2666 - val_loss: 10.2025 - val_acc: 0.3661\n",
      "Epoch 97/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8098 - acc: 0.2670 - val_loss: 10.2024 - val_acc: 0.3661\n",
      "Epoch 98/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8115 - acc: 0.2670 - val_loss: 10.2024 - val_acc: 0.3661\n",
      "Epoch 99/100\n",
      "2356/2356 [==============================] - ETA: 0s - loss: 11.8076 - acc: 0.26 - 0s - loss: 11.8194 - acc: 0.2666 - val_loss: 10.2025 - val_acc: 0.3661\n",
      "Epoch 100/100\n",
      "2356/2356 [==============================] - 0s - loss: 11.8141 - acc: 0.2666 - val_loss: 10.2023 - val_acc: 0.3661\n",
      " 32/743 [>.............................] - ETA: 0sloss: 11.51\n",
      "Train on 2359 samples, validate on 590 samples\n",
      "Epoch 1/100\n",
      "2359/2359 [==============================] - 2s - loss: 13.3194 - acc: 0.1568 - val_loss: 13.1480 - val_acc: 0.1780\n",
      "Epoch 2/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.1300 - acc: 0.1717 - val_loss: 12.2301 - val_acc: 0.1780\n",
      "Epoch 3/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.6530 - acc: 0.1840 - val_loss: 14.0994 - val_acc: 0.1169\n",
      "Epoch 4/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.5650 - acc: 0.1971 - val_loss: 14.1496 - val_acc: 0.1169\n",
      "Epoch 5/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4054 - acc: 0.2141 - val_loss: 14.1863 - val_acc: 0.1169\n",
      "Epoch 6/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4871 - acc: 0.2166 - val_loss: 14.1867 - val_acc: 0.1169\n",
      "Epoch 7/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4883 - acc: 0.2124 - val_loss: 14.1830 - val_acc: 0.1169\n",
      "Epoch 8/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3987 - acc: 0.2183 - val_loss: 14.1855 - val_acc: 0.1169\n",
      "Epoch 9/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3576 - acc: 0.2221 - val_loss: 14.1847 - val_acc: 0.1169\n",
      "Epoch 10/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4224 - acc: 0.2192 - val_loss: 14.1803 - val_acc: 0.1169\n",
      "Epoch 11/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4243 - acc: 0.2179 - val_loss: 14.1849 - val_acc: 0.1169\n",
      "Epoch 12/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3855 - acc: 0.2200 - val_loss: 14.1867 - val_acc: 0.1169\n",
      "Epoch 13/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4525 - acc: 0.2196 - val_loss: 14.1875 - val_acc: 0.1169\n",
      "Epoch 14/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4064 - acc: 0.2209 - val_loss: 14.1876 - val_acc: 0.1169\n",
      "Epoch 15/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4252 - acc: 0.2226 - val_loss: 14.1926 - val_acc: 0.1169\n",
      "Epoch 16/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4352 - acc: 0.2247 - val_loss: 14.1935 - val_acc: 0.1169\n",
      "Epoch 17/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3969 - acc: 0.2268 - val_loss: 14.1901 - val_acc: 0.1169\n",
      "Epoch 18/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4345 - acc: 0.2234 - val_loss: 14.1888 - val_acc: 0.1169\n",
      "Epoch 19/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4477 - acc: 0.2238 - val_loss: 14.1876 - val_acc: 0.1169\n",
      "Epoch 20/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3979 - acc: 0.2272 - val_loss: 14.1884 - val_acc: 0.1169\n",
      "Epoch 21/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3667 - acc: 0.2268 - val_loss: 14.1909 - val_acc: 0.1169\n",
      "Epoch 22/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.4153 - acc: 0.2247 - val_loss: 14.1864 - val_acc: 0.1169\n",
      "Epoch 23/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3073 - acc: 0.2221 - val_loss: 14.0852 - val_acc: 0.1169\n",
      "Epoch 24/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.2568 - acc: 0.2145 - val_loss: 14.1731 - val_acc: 0.1169\n",
      "Epoch 25/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3611 - acc: 0.2170 - val_loss: 14.1550 - val_acc: 0.1169\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2359/2359 [==============================] - 0s - loss: 12.3054 - acc: 0.2170 - val_loss: 14.1272 - val_acc: 0.1169\n",
      "Epoch 27/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.5257 - acc: 0.1908 - val_loss: 13.1476 - val_acc: 0.1780\n",
      "Epoch 28/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.6810 - acc: 0.1874 - val_loss: 14.1750 - val_acc: 0.1169\n",
      "Epoch 29/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.3333 - acc: 0.2166 - val_loss: 14.1713 - val_acc: 0.1169\n",
      "Epoch 30/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.2878 - acc: 0.2217 - val_loss: 14.1755 - val_acc: 0.1169\n",
      "Epoch 31/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.2292 - acc: 0.2200 - val_loss: 13.9495 - val_acc: 0.1169\n",
      "Epoch 32/100\n",
      "2359/2359 [==============================] - 0s - loss: 12.0650 - acc: 0.2018 - val_loss: 14.1194 - val_acc: 0.1169\n",
      "Epoch 33/100\n",
      "2359/2359 [==============================] - 0s - loss: 11.6804 - acc: 0.2120 - val_loss: 11.9194 - val_acc: 0.1780\n",
      "Epoch 34/100\n",
      "2359/2359 [==============================] - 0s - loss: 10.8207 - acc: 0.1844 - val_loss: 11.0835 - val_acc: 0.1153\n",
      "Epoch 35/100\n",
      "2359/2359 [==============================] - 0s - loss: 9.8009 - acc: 0.1869 - val_loss: 7.9959 - val_acc: 0.1153\n",
      "Epoch 36/100\n",
      "2359/2359 [==============================] - 0s - loss: 6.2996 - acc: 0.1865 - val_loss: 2.0632 - val_acc: 0.2695\n",
      "Epoch 37/100\n",
      "2359/2359 [==============================] - 0s - loss: 3.4152 - acc: 0.2272 - val_loss: 1.8960 - val_acc: 0.3746\n",
      "Epoch 38/100\n",
      "2359/2359 [==============================] - 0s - loss: 2.6516 - acc: 0.2437 - val_loss: 1.8474 - val_acc: 0.3746\n",
      "Epoch 39/100\n",
      "2359/2359 [==============================] - 0s - loss: 2.3102 - acc: 0.2510 - val_loss: 1.7997 - val_acc: 0.3746\n",
      "Epoch 40/100\n",
      "2359/2359 [==============================] - 0s - loss: 2.1812 - acc: 0.2518 - val_loss: 1.8064 - val_acc: 0.3746\n",
      "Epoch 41/100\n",
      "2359/2359 [==============================] - 0s - loss: 2.0795 - acc: 0.2641 - val_loss: 1.8115 - val_acc: 0.3746\n",
      "Epoch 42/100\n",
      "2359/2359 [==============================] - 0s - loss: 2.0632 - acc: 0.2556 - val_loss: 1.7915 - val_acc: 0.3746\n",
      "Epoch 43/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.9935 - acc: 0.2594 - val_loss: 1.7793 - val_acc: 0.3746\n",
      "Epoch 44/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.9544 - acc: 0.2586 - val_loss: 1.7746 - val_acc: 0.3746\n",
      "Epoch 45/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.9640 - acc: 0.2543 - val_loss: 1.8189 - val_acc: 0.3559\n",
      "Epoch 46/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.9172 - acc: 0.2560 - val_loss: 1.7756 - val_acc: 0.3746\n",
      "Epoch 47/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.9133 - acc: 0.2611 - val_loss: 1.7872 - val_acc: 0.3746\n",
      "Epoch 48/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8880 - acc: 0.2628 - val_loss: 1.7634 - val_acc: 0.3746\n",
      "Epoch 49/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8643 - acc: 0.2577 - val_loss: 1.7533 - val_acc: 0.3746\n",
      "Epoch 50/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8686 - acc: 0.2560 - val_loss: 1.7784 - val_acc: 0.3746\n",
      "Epoch 51/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8623 - acc: 0.2637 - val_loss: 1.7932 - val_acc: 0.3746\n",
      "Epoch 52/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8566 - acc: 0.2658 - val_loss: 1.7819 - val_acc: 0.3746\n",
      "Epoch 53/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8455 - acc: 0.2649 - val_loss: 1.7647 - val_acc: 0.3746\n",
      "Epoch 54/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8420 - acc: 0.2649 - val_loss: 1.7672 - val_acc: 0.3746\n",
      "Epoch 55/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8429 - acc: 0.2645 - val_loss: 1.7632 - val_acc: 0.3746\n",
      "Epoch 56/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8426 - acc: 0.2649 - val_loss: 1.7670 - val_acc: 0.3746\n",
      "Epoch 57/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8408 - acc: 0.2654 - val_loss: 1.7737 - val_acc: 0.3746\n",
      "Epoch 58/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8382 - acc: 0.2645 - val_loss: 1.7696 - val_acc: 0.3746\n",
      "Epoch 59/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8399 - acc: 0.2649 - val_loss: 1.7761 - val_acc: 0.3746\n",
      "Epoch 60/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8412 - acc: 0.2649 - val_loss: 1.7683 - val_acc: 0.3746\n",
      "Epoch 61/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8409 - acc: 0.2645 - val_loss: 1.7746 - val_acc: 0.3746\n",
      "Epoch 62/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8387 - acc: 0.2654 - val_loss: 1.7641 - val_acc: 0.3746\n",
      "Epoch 63/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8403 - acc: 0.2654 - val_loss: 1.7755 - val_acc: 0.3746\n",
      "Epoch 64/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8382 - acc: 0.2649 - val_loss: 1.7699 - val_acc: 0.3746\n",
      "Epoch 65/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8399 - acc: 0.2654 - val_loss: 1.7734 - val_acc: 0.3746\n",
      "Epoch 66/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8391 - acc: 0.2649 - val_loss: 1.7802 - val_acc: 0.3746\n",
      "Epoch 67/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8379 - acc: 0.2654 - val_loss: 1.7690 - val_acc: 0.3746\n",
      "Epoch 68/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8420 - acc: 0.2645 - val_loss: 1.7729 - val_acc: 0.3746\n",
      "Epoch 69/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8358 - acc: 0.2649 - val_loss: 1.7519 - val_acc: 0.3746\n",
      "Epoch 70/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8394 - acc: 0.2649 - val_loss: 1.7694 - val_acc: 0.3746\n",
      "Epoch 71/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8381 - acc: 0.2645 - val_loss: 1.7756 - val_acc: 0.3746\n",
      "Epoch 72/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8363 - acc: 0.2649 - val_loss: 1.7702 - val_acc: 0.3746\n",
      "Epoch 73/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8386 - acc: 0.2645 - val_loss: 1.7630 - val_acc: 0.3746\n",
      "Epoch 74/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8391 - acc: 0.2645 - val_loss: 1.7580 - val_acc: 0.3746\n",
      "Epoch 75/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8365 - acc: 0.2654 - val_loss: 1.7633 - val_acc: 0.3746\n",
      "Epoch 76/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8383 - acc: 0.2645 - val_loss: 1.7687 - val_acc: 0.3746\n",
      "Epoch 77/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8362 - acc: 0.2645 - val_loss: 1.7653 - val_acc: 0.3746\n",
      "Epoch 78/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8365 - acc: 0.2649 - val_loss: 1.7651 - val_acc: 0.3746\n",
      "Epoch 79/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8374 - acc: 0.2654 - val_loss: 1.7731 - val_acc: 0.3746\n",
      "Epoch 80/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8362 - acc: 0.2649 - val_loss: 1.7736 - val_acc: 0.3746\n",
      "Epoch 81/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8361 - acc: 0.2654 - val_loss: 1.7751 - val_acc: 0.3746\n",
      "Epoch 82/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8371 - acc: 0.2649 - val_loss: 1.7704 - val_acc: 0.3746\n",
      "Epoch 83/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8354 - acc: 0.2654 - val_loss: 1.7773 - val_acc: 0.3746\n",
      "Epoch 84/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8335 - acc: 0.2654 - val_loss: 1.7487 - val_acc: 0.3746\n",
      "Epoch 85/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8419 - acc: 0.2645 - val_loss: 1.7638 - val_acc: 0.3746\n",
      "Epoch 86/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8370 - acc: 0.2654 - val_loss: 1.7737 - val_acc: 0.3746\n",
      "Epoch 87/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8391 - acc: 0.2649 - val_loss: 1.7681 - val_acc: 0.3746\n",
      "Epoch 88/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8371 - acc: 0.2654 - val_loss: 1.7817 - val_acc: 0.3746\n",
      "Epoch 89/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8389 - acc: 0.2645 - val_loss: 1.7796 - val_acc: 0.3746\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2359/2359 [==============================] - 0s - loss: 1.8339 - acc: 0.2654 - val_loss: 1.7604 - val_acc: 0.3746\n",
      "Epoch 91/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8299 - acc: 0.2654 - val_loss: 1.7430 - val_acc: 0.3746\n",
      "Epoch 92/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8360 - acc: 0.2645 - val_loss: 1.7698 - val_acc: 0.3746\n",
      "Epoch 93/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8336 - acc: 0.2649 - val_loss: 1.7635 - val_acc: 0.3746\n",
      "Epoch 94/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8354 - acc: 0.2654 - val_loss: 1.7723 - val_acc: 0.3746\n",
      "Epoch 95/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8371 - acc: 0.2649 - val_loss: 1.7644 - val_acc: 0.3746\n",
      "Epoch 96/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8332 - acc: 0.2654 - val_loss: 1.7732 - val_acc: 0.3746\n",
      "Epoch 97/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8365 - acc: 0.2649 - val_loss: 1.7710 - val_acc: 0.3746\n",
      "Epoch 98/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8334 - acc: 0.2654 - val_loss: 1.7570 - val_acc: 0.3746\n",
      "Epoch 99/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8350 - acc: 0.2658 - val_loss: 1.7851 - val_acc: 0.3644\n",
      "Epoch 100/100\n",
      "2359/2359 [==============================] - 0s - loss: 1.8335 - acc: 0.2654 - val_loss: 1.7695 - val_acc: 0.3746\n",
      " 32/740 [>.............................] - ETA: 0sloss: 1.83\n",
      "Train on 2361 samples, validate on 591 samples\n",
      "Epoch 1/100\n",
      "2361/2361 [==============================] - 1s - loss: 13.3603 - acc: 0.1567 - val_loss: 9.6643 - val_acc: 0.3773\n",
      "Epoch 2/100\n",
      "2361/2361 [==============================] - 0s - loss: 12.6728 - acc: 0.1957 - val_loss: 9.9899 - val_acc: 0.3773\n",
      "Epoch 3/100\n",
      "2361/2361 [==============================] - 0s - loss: 12.3015 - acc: 0.2291 - val_loss: 10.0046 - val_acc: 0.3773\n",
      "Epoch 4/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7680 - acc: 0.2651 - val_loss: 10.0037 - val_acc: 0.3773\n",
      "Epoch 5/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.9029 - acc: 0.2537 - val_loss: 10.0062 - val_acc: 0.3773\n",
      "Epoch 6/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.9422 - acc: 0.2533 - val_loss: 9.9989 - val_acc: 0.3773\n",
      "Epoch 7/100\n",
      "2361/2361 [==============================] - 0s - loss: 12.0077 - acc: 0.2516 - val_loss: 10.0055 - val_acc: 0.3773\n",
      "Epoch 8/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8557 - acc: 0.2613 - val_loss: 10.0106 - val_acc: 0.3773\n",
      "Epoch 9/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8657 - acc: 0.2601 - val_loss: 10.0120 - val_acc: 0.3773\n",
      "Epoch 10/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8452 - acc: 0.2630 - val_loss: 10.0104 - val_acc: 0.3773\n",
      "Epoch 11/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8441 - acc: 0.2618 - val_loss: 10.0105 - val_acc: 0.3773\n",
      "Epoch 12/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8214 - acc: 0.2634 - val_loss: 10.0126 - val_acc: 0.3773\n",
      "Epoch 13/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8324 - acc: 0.2626 - val_loss: 10.0020 - val_acc: 0.3773\n",
      "Epoch 14/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.9179 - acc: 0.2541 - val_loss: 10.0035 - val_acc: 0.3773\n",
      "Epoch 15/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8623 - acc: 0.2609 - val_loss: 10.0099 - val_acc: 0.3773\n",
      "Epoch 16/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8547 - acc: 0.2626 - val_loss: 10.0128 - val_acc: 0.3773\n",
      "Epoch 17/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8481 - acc: 0.2622 - val_loss: 10.0127 - val_acc: 0.3773\n",
      "Epoch 18/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8452 - acc: 0.2630 - val_loss: 10.0118 - val_acc: 0.3773\n",
      "Epoch 19/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8252 - acc: 0.2643 - val_loss: 10.0071 - val_acc: 0.3773\n",
      "Epoch 20/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8202 - acc: 0.2622 - val_loss: 10.0093 - val_acc: 0.3773\n",
      "Epoch 21/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8351 - acc: 0.2634 - val_loss: 10.0101 - val_acc: 0.3773\n",
      "Epoch 22/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8509 - acc: 0.2622 - val_loss: 10.0069 - val_acc: 0.3773\n",
      "Epoch 23/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7419 - acc: 0.2677 - val_loss: 10.0022 - val_acc: 0.3773\n",
      "Epoch 24/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8331 - acc: 0.2609 - val_loss: 10.0031 - val_acc: 0.3773\n",
      "Epoch 25/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7511 - acc: 0.2673 - val_loss: 9.9953 - val_acc: 0.3773\n",
      "Epoch 26/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8377 - acc: 0.2613 - val_loss: 10.0014 - val_acc: 0.3773\n",
      "Epoch 27/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7920 - acc: 0.2651 - val_loss: 10.0117 - val_acc: 0.3773\n",
      "Epoch 28/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8400 - acc: 0.2639 - val_loss: 10.0138 - val_acc: 0.3773\n",
      "Epoch 29/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8544 - acc: 0.2630 - val_loss: 10.0138 - val_acc: 0.3773\n",
      "Epoch 30/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8292 - acc: 0.2643 - val_loss: 10.0139 - val_acc: 0.3773\n",
      "Epoch 31/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8199 - acc: 0.2647 - val_loss: 10.0140 - val_acc: 0.3773\n",
      "Epoch 32/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8445 - acc: 0.2626 - val_loss: 10.0141 - val_acc: 0.3773\n",
      "Epoch 33/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8263 - acc: 0.2651 - val_loss: 10.0141 - val_acc: 0.3773\n",
      "Epoch 34/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8433 - acc: 0.2634 - val_loss: 10.0142 - val_acc: 0.3773\n",
      "Epoch 35/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8307 - acc: 0.2643 - val_loss: 10.0137 - val_acc: 0.3773\n",
      "Epoch 36/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8368 - acc: 0.2639 - val_loss: 10.0133 - val_acc: 0.3773\n",
      "Epoch 37/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8524 - acc: 0.2630 - val_loss: 10.0121 - val_acc: 0.3773\n",
      "Epoch 38/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8434 - acc: 0.2639 - val_loss: 10.0105 - val_acc: 0.3773\n",
      "Epoch 39/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8365 - acc: 0.2630 - val_loss: 10.0080 - val_acc: 0.3773\n",
      "Epoch 40/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8016 - acc: 0.2651 - val_loss: 10.0059 - val_acc: 0.3773\n",
      "Epoch 41/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8161 - acc: 0.2643 - val_loss: 10.0023 - val_acc: 0.3773\n",
      "Epoch 42/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8265 - acc: 0.2613 - val_loss: 9.9947 - val_acc: 0.3773\n",
      "Epoch 43/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8722 - acc: 0.2571 - val_loss: 10.0012 - val_acc: 0.3773\n",
      "Epoch 44/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8337 - acc: 0.2618 - val_loss: 10.0101 - val_acc: 0.3773\n",
      "Epoch 45/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8434 - acc: 0.2626 - val_loss: 10.0055 - val_acc: 0.3773\n",
      "Epoch 46/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8242 - acc: 0.2639 - val_loss: 10.0068 - val_acc: 0.3773\n",
      "Epoch 47/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7980 - acc: 0.2647 - val_loss: 10.0043 - val_acc: 0.3773\n",
      "Epoch 48/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8416 - acc: 0.2626 - val_loss: 10.0024 - val_acc: 0.3773\n",
      "Epoch 49/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8171 - acc: 0.2618 - val_loss: 9.9934 - val_acc: 0.3773\n",
      "Epoch 50/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7467 - acc: 0.2651 - val_loss: 9.9885 - val_acc: 0.3773\n",
      "Epoch 51/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8281 - acc: 0.2613 - val_loss: 9.9900 - val_acc: 0.3773\n",
      "Epoch 52/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8015 - acc: 0.2639 - val_loss: 9.9898 - val_acc: 0.3773\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 0s - loss: 11.8518 - acc: 0.2609 - val_loss: 9.9949 - val_acc: 0.3773\n",
      "Epoch 54/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7810 - acc: 0.2656 - val_loss: 9.9940 - val_acc: 0.3773\n",
      "Epoch 55/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7963 - acc: 0.2630 - val_loss: 9.9938 - val_acc: 0.3773\n",
      "Epoch 56/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8020 - acc: 0.2639 - val_loss: 9.9890 - val_acc: 0.3773\n",
      "Epoch 57/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8288 - acc: 0.2626 - val_loss: 9.9858 - val_acc: 0.3773\n",
      "Epoch 58/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8575 - acc: 0.2605 - val_loss: 9.9943 - val_acc: 0.3773\n",
      "Epoch 59/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8001 - acc: 0.2639 - val_loss: 9.9876 - val_acc: 0.3773\n",
      "Epoch 60/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8275 - acc: 0.2609 - val_loss: 9.9894 - val_acc: 0.3773\n",
      "Epoch 61/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.9005 - acc: 0.2541 - val_loss: 9.9842 - val_acc: 0.3773\n",
      "Epoch 62/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8615 - acc: 0.2601 - val_loss: 9.9978 - val_acc: 0.3773\n",
      "Epoch 63/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8193 - acc: 0.2626 - val_loss: 9.9939 - val_acc: 0.3773\n",
      "Epoch 64/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7844 - acc: 0.2639 - val_loss: 9.9905 - val_acc: 0.3773\n",
      "Epoch 65/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8162 - acc: 0.2626 - val_loss: 9.9930 - val_acc: 0.3773\n",
      "Epoch 66/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8066 - acc: 0.2639 - val_loss: 9.9907 - val_acc: 0.3773\n",
      "Epoch 67/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8423 - acc: 0.2622 - val_loss: 9.9918 - val_acc: 0.3773\n",
      "Epoch 68/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7972 - acc: 0.2634 - val_loss: 9.9908 - val_acc: 0.3773\n",
      "Epoch 69/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7962 - acc: 0.2634 - val_loss: 9.9886 - val_acc: 0.3773\n",
      "Epoch 70/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8478 - acc: 0.2605 - val_loss: 9.9863 - val_acc: 0.3773\n",
      "Epoch 71/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8547 - acc: 0.2596 - val_loss: 9.9816 - val_acc: 0.3773\n",
      "Epoch 72/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7846 - acc: 0.2630 - val_loss: 9.9725 - val_acc: 0.3773\n",
      "Epoch 73/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8920 - acc: 0.2567 - val_loss: 9.9808 - val_acc: 0.3773\n",
      "Epoch 74/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7943 - acc: 0.2647 - val_loss: 9.9794 - val_acc: 0.3773\n",
      "Epoch 75/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7976 - acc: 0.2634 - val_loss: 9.9775 - val_acc: 0.3773\n",
      "Epoch 76/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8402 - acc: 0.2605 - val_loss: 9.9734 - val_acc: 0.3773\n",
      "Epoch 77/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7258 - acc: 0.2660 - val_loss: 9.9705 - val_acc: 0.3790\n",
      "Epoch 78/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.6582 - acc: 0.2681 - val_loss: 9.9830 - val_acc: 0.3773\n",
      "Epoch 79/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7588 - acc: 0.2664 - val_loss: 9.9818 - val_acc: 0.3773\n",
      "Epoch 80/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7518 - acc: 0.2651 - val_loss: 9.9779 - val_acc: 0.3773\n",
      "Epoch 81/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7308 - acc: 0.2681 - val_loss: 9.9779 - val_acc: 0.3773\n",
      "Epoch 82/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7264 - acc: 0.2647 - val_loss: 9.6859 - val_acc: 0.3756\n",
      "Epoch 83/100\n",
      "2361/2361 [==============================] - 0s - loss: 12.2390 - acc: 0.2321 - val_loss: 14.0145 - val_acc: 0.1286\n",
      "Epoch 84/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.9921 - acc: 0.2465 - val_loss: 13.9359 - val_acc: 0.1286\n",
      "Epoch 85/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7656 - acc: 0.2584 - val_loss: 9.9754 - val_acc: 0.3773\n",
      "Epoch 86/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7801 - acc: 0.2639 - val_loss: 9.9932 - val_acc: 0.3773\n",
      "Epoch 87/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7925 - acc: 0.2643 - val_loss: 9.9857 - val_acc: 0.3773\n",
      "Epoch 88/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8170 - acc: 0.2609 - val_loss: 10.0079 - val_acc: 0.3773\n",
      "Epoch 89/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7857 - acc: 0.2664 - val_loss: 10.0067 - val_acc: 0.3773\n",
      "Epoch 90/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.7955 - acc: 0.2647 - val_loss: 10.0066 - val_acc: 0.3773\n",
      "Epoch 91/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8371 - acc: 0.2643 - val_loss: 10.0110 - val_acc: 0.3773\n",
      "Epoch 92/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8597 - acc: 0.2622 - val_loss: 10.0096 - val_acc: 0.3773\n",
      "Epoch 93/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8296 - acc: 0.2643 - val_loss: 10.0120 - val_acc: 0.3773\n",
      "Epoch 94/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8426 - acc: 0.2626 - val_loss: 10.0100 - val_acc: 0.3773\n",
      "Epoch 95/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8399 - acc: 0.2643 - val_loss: 10.0090 - val_acc: 0.3773\n",
      "Epoch 96/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8059 - acc: 0.2647 - val_loss: 10.0052 - val_acc: 0.3773\n",
      "Epoch 97/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8108 - acc: 0.2643 - val_loss: 10.0034 - val_acc: 0.3773\n",
      "Epoch 98/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8179 - acc: 0.2647 - val_loss: 9.9993 - val_acc: 0.3773\n",
      "Epoch 99/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8367 - acc: 0.2626 - val_loss: 9.9904 - val_acc: 0.3773\n",
      "Epoch 100/100\n",
      "2361/2361 [==============================] - 0s - loss: 11.8171 - acc: 0.2626 - val_loss: 10.0006 - val_acc: 0.3773\n",
      " 32/737 [>.............................] - ETA: 0sloss: 11.16\n",
      "Train on 2363 samples, validate on 591 samples\n",
      "Epoch 1/100\n",
      "2363/2363 [==============================] - 2s - loss: 14.7836 - acc: 0.0800 - val_loss: 13.0124 - val_acc: 0.1929\n",
      "Epoch 2/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1639 - acc: 0.1189 - val_loss: 13.0126 - val_acc: 0.1929\n",
      "Epoch 3/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1494 - acc: 0.1198 - val_loss: 13.0127 - val_acc: 0.1912\n",
      "Epoch 4/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1612 - acc: 0.1189 - val_loss: 13.0127 - val_acc: 0.1912\n",
      "Epoch 5/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1394 - acc: 0.1210 - val_loss: 13.0128 - val_acc: 0.1912\n",
      "Epoch 6/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1409 - acc: 0.1215 - val_loss: 13.0128 - val_acc: 0.1912\n",
      "Epoch 7/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1560 - acc: 0.1206 - val_loss: 13.0129 - val_acc: 0.1912\n",
      "Epoch 8/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1448 - acc: 0.1215 - val_loss: 13.0130 - val_acc: 0.1912\n",
      "Epoch 9/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.9490 - acc: 0.1312 - val_loss: 13.0131 - val_acc: 0.1912\n",
      "Epoch 10/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.0031 - acc: 0.1287 - val_loss: 13.0042 - val_acc: 0.1912\n",
      "Epoch 11/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1313 - acc: 0.1206 - val_loss: 13.0132 - val_acc: 0.1912\n",
      "Epoch 12/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1657 - acc: 0.1202 - val_loss: 13.0132 - val_acc: 0.1912\n",
      "Epoch 13/100\n",
      "2363/2363 [==============================] - 0s - loss: 14.1052 - acc: 0.1223 - val_loss: 13.0120 - val_acc: 0.1912\n",
      "Epoch 14/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.8700 - acc: 0.1367 - val_loss: 13.0136 - val_acc: 0.1912\n",
      "Epoch 15/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.7706 - acc: 0.1439 - val_loss: 13.0027 - val_acc: 0.1912\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363/2363 [==============================] - 0s - loss: 13.8319 - acc: 0.1384 - val_loss: 12.9675 - val_acc: 0.1912\n",
      "Epoch 17/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.6689 - acc: 0.2103 - val_loss: 14.1062 - val_acc: 0.1235\n",
      "Epoch 18/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4920 - acc: 0.2243 - val_loss: 14.1064 - val_acc: 0.1235\n",
      "Epoch 19/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4972 - acc: 0.2243 - val_loss: 14.1066 - val_acc: 0.1235\n",
      "Epoch 20/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4808 - acc: 0.2243 - val_loss: 14.1068 - val_acc: 0.1235\n",
      "Epoch 21/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.5057 - acc: 0.2230 - val_loss: 14.1070 - val_acc: 0.1235\n",
      "Epoch 22/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4785 - acc: 0.2239 - val_loss: 14.1069 - val_acc: 0.1235\n",
      "Epoch 23/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4900 - acc: 0.2239 - val_loss: 14.1071 - val_acc: 0.1235\n",
      "Epoch 24/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4917 - acc: 0.2243 - val_loss: 14.1071 - val_acc: 0.1235\n",
      "Epoch 25/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4849 - acc: 0.2247 - val_loss: 14.1074 - val_acc: 0.1235\n",
      "Epoch 26/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4983 - acc: 0.2239 - val_loss: 14.1074 - val_acc: 0.1235\n",
      "Epoch 27/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4896 - acc: 0.2239 - val_loss: 14.1076 - val_acc: 0.1235\n",
      "Epoch 28/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4909 - acc: 0.2239 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 29/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4778 - acc: 0.2247 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 30/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4852 - acc: 0.2247 - val_loss: 14.1083 - val_acc: 0.1235\n",
      "Epoch 31/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4984 - acc: 0.2243 - val_loss: 14.1084 - val_acc: 0.1235\n",
      "Epoch 32/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4877 - acc: 0.2247 - val_loss: 14.1087 - val_acc: 0.1235\n",
      "Epoch 33/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4770 - acc: 0.2251 - val_loss: 14.1089 - val_acc: 0.1235\n",
      "Epoch 34/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4908 - acc: 0.2243 - val_loss: 14.1091 - val_acc: 0.1235\n",
      "Epoch 35/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4865 - acc: 0.2239 - val_loss: 14.1090 - val_acc: 0.1235\n",
      "Epoch 36/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4843 - acc: 0.2247 - val_loss: 14.1090 - val_acc: 0.1235\n",
      "Epoch 37/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4838 - acc: 0.2251 - val_loss: 14.1091 - val_acc: 0.1235\n",
      "Epoch 38/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4914 - acc: 0.2239 - val_loss: 14.1089 - val_acc: 0.1235\n",
      "Epoch 39/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4847 - acc: 0.2243 - val_loss: 14.1089 - val_acc: 0.1235\n",
      "Epoch 40/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4835 - acc: 0.2251 - val_loss: 14.1092 - val_acc: 0.1235\n",
      "Epoch 41/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4910 - acc: 0.2247 - val_loss: 14.1093 - val_acc: 0.1235\n",
      "Epoch 42/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4843 - acc: 0.2247 - val_loss: 14.1090 - val_acc: 0.1235\n",
      "Epoch 43/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4826 - acc: 0.2243 - val_loss: 14.1091 - val_acc: 0.1235\n",
      "Epoch 44/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4836 - acc: 0.2251 - val_loss: 14.1096 - val_acc: 0.1235\n",
      "Epoch 45/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4840 - acc: 0.2251 - val_loss: 14.1098 - val_acc: 0.1235\n",
      "Epoch 46/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4767 - acc: 0.2260 - val_loss: 14.1095 - val_acc: 0.1235\n",
      "Epoch 47/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4836 - acc: 0.2256 - val_loss: 14.1098 - val_acc: 0.1235\n",
      "Epoch 48/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4832 - acc: 0.2251 - val_loss: 14.1102 - val_acc: 0.1235\n",
      "Epoch 49/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4833 - acc: 0.2251 - val_loss: 14.1104 - val_acc: 0.1235\n",
      "Epoch 50/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4815 - acc: 0.2251 - val_loss: 14.1107 - val_acc: 0.1235\n",
      "Epoch 51/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4833 - acc: 0.2256 - val_loss: 14.1107 - val_acc: 0.1235\n",
      "Epoch 52/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4833 - acc: 0.2256 - val_loss: 14.1111 - val_acc: 0.1235\n",
      "Epoch 53/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4831 - acc: 0.2256 - val_loss: 14.1115 - val_acc: 0.1235\n",
      "Epoch 54/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4838 - acc: 0.2251 - val_loss: 14.1114 - val_acc: 0.1235\n",
      "Epoch 55/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4833 - acc: 0.2256 - val_loss: 14.1117 - val_acc: 0.1235\n",
      "Epoch 56/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4765 - acc: 0.2260 - val_loss: 14.1129 - val_acc: 0.1235\n",
      "Epoch 57/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4836 - acc: 0.2251 - val_loss: 14.1132 - val_acc: 0.1235\n",
      "Epoch 58/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4842 - acc: 0.2251 - val_loss: 14.1132 - val_acc: 0.1235\n",
      "Epoch 59/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4831 - acc: 0.2256 - val_loss: 14.1134 - val_acc: 0.1235\n",
      "Epoch 60/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4761 - acc: 0.2260 - val_loss: 14.1136 - val_acc: 0.1235\n",
      "Epoch 61/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4768 - acc: 0.2256 - val_loss: 14.1135 - val_acc: 0.1235\n",
      "Epoch 62/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4904 - acc: 0.2247 - val_loss: 14.1137 - val_acc: 0.1235\n",
      "Epoch 63/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4900 - acc: 0.2251 - val_loss: 14.1140 - val_acc: 0.1235\n",
      "Epoch 64/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4830 - acc: 0.2251 - val_loss: 14.1136 - val_acc: 0.1235\n",
      "Epoch 65/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4760 - acc: 0.2260 - val_loss: 14.1141 - val_acc: 0.1235\n",
      "Epoch 66/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4826 - acc: 0.2247 - val_loss: 14.1147 - val_acc: 0.1235\n",
      "Epoch 67/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4774 - acc: 0.2251 - val_loss: 14.1150 - val_acc: 0.1235\n",
      "Epoch 68/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4764 - acc: 0.2256 - val_loss: 14.1144 - val_acc: 0.1235\n",
      "Epoch 69/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4828 - acc: 0.2256 - val_loss: 14.1146 - val_acc: 0.1235\n",
      "Epoch 70/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4760 - acc: 0.2260 - val_loss: 14.1146 - val_acc: 0.1235\n",
      "Epoch 71/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4587 - acc: 0.2260 - val_loss: 14.1153 - val_acc: 0.1235\n",
      "Epoch 72/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.5372 - acc: 0.2218 - val_loss: 14.1156 - val_acc: 0.1235\n",
      "Epoch 73/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4705 - acc: 0.2256 - val_loss: 14.1160 - val_acc: 0.1235\n",
      "Epoch 74/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4720 - acc: 0.2260 - val_loss: 14.1158 - val_acc: 0.1235\n",
      "Epoch 75/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4760 - acc: 0.2260 - val_loss: 14.1154 - val_acc: 0.1235\n",
      "Epoch 76/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4765 - acc: 0.2256 - val_loss: 14.1144 - val_acc: 0.1235\n",
      "Epoch 77/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4825 - acc: 0.2256 - val_loss: 14.1143 - val_acc: 0.1235\n",
      "Epoch 78/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4690 - acc: 0.2264 - val_loss: 14.1144 - val_acc: 0.1235\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363/2363 [==============================] - 0s - loss: 12.4827 - acc: 0.2256 - val_loss: 14.1145 - val_acc: 0.1235\n",
      "Epoch 80/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4767 - acc: 0.2256 - val_loss: 14.1138 - val_acc: 0.1235\n",
      "Epoch 81/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4628 - acc: 0.2264 - val_loss: 14.1135 - val_acc: 0.1235\n",
      "Epoch 82/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4829 - acc: 0.2256 - val_loss: 14.1137 - val_acc: 0.1235\n",
      "Epoch 83/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4899 - acc: 0.2247 - val_loss: 14.1131 - val_acc: 0.1235\n",
      "Epoch 84/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4827 - acc: 0.2256 - val_loss: 14.1132 - val_acc: 0.1235\n",
      "Epoch 85/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.5168 - acc: 0.2234 - val_loss: 14.1133 - val_acc: 0.1235\n",
      "Epoch 86/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4937 - acc: 0.2247 - val_loss: 14.1137 - val_acc: 0.1235\n",
      "Epoch 87/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4899 - acc: 0.2247 - val_loss: 14.1140 - val_acc: 0.1235\n",
      "Epoch 88/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4971 - acc: 0.2243 - val_loss: 14.1142 - val_acc: 0.1235\n",
      "Epoch 89/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4834 - acc: 0.2251 - val_loss: 14.1146 - val_acc: 0.1235\n",
      "Epoch 90/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4832 - acc: 0.2251 - val_loss: 14.1152 - val_acc: 0.1235\n",
      "Epoch 91/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4827 - acc: 0.2256 - val_loss: 14.1148 - val_acc: 0.1235\n",
      "Epoch 92/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4828 - acc: 0.2256 - val_loss: 14.1152 - val_acc: 0.1235\n",
      "Epoch 93/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4763 - acc: 0.2256 - val_loss: 14.1151 - val_acc: 0.1235\n",
      "Epoch 94/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4837 - acc: 0.2251 - val_loss: 14.1136 - val_acc: 0.1235\n",
      "Epoch 95/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4828 - acc: 0.2256 - val_loss: 14.1139 - val_acc: 0.1235\n",
      "Epoch 96/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4778 - acc: 0.2251 - val_loss: 14.1130 - val_acc: 0.1235\n",
      "Epoch 97/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4883 - acc: 0.2251 - val_loss: 14.1133 - val_acc: 0.1235\n",
      "Epoch 98/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4827 - acc: 0.2256 - val_loss: 14.1132 - val_acc: 0.1235\n",
      "Epoch 99/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4833 - acc: 0.2256 - val_loss: 14.1133 - val_acc: 0.1235\n",
      "Epoch 100/100\n",
      "2363/2363 [==============================] - 0s - loss: 12.4828 - acc: 0.2256 - val_loss: 14.1133 - val_acc: 0.1235\n",
      " 32/735 [>.............................] - ETA: 0sloss: 13.87\n",
      "Train on 2364 samples, validate on 591 samples\n",
      "Epoch 1/100\n",
      "2364/2364 [==============================] - 2s - loss: 13.8754 - acc: 0.1311 - val_loss: 14.0050 - val_acc: 0.1235\n",
      "Epoch 2/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.8364 - acc: 0.1984 - val_loss: 14.1039 - val_acc: 0.1235\n",
      "Epoch 3/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5266 - acc: 0.2208 - val_loss: 14.1039 - val_acc: 0.1235\n",
      "Epoch 4/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5112 - acc: 0.2217 - val_loss: 14.1038 - val_acc: 0.1235\n",
      "Epoch 5/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5087 - acc: 0.2221 - val_loss: 14.1039 - val_acc: 0.1235\n",
      "Epoch 6/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4948 - acc: 0.2229 - val_loss: 14.1039 - val_acc: 0.1235\n",
      "Epoch 7/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4678 - acc: 0.2246 - val_loss: 14.1038 - val_acc: 0.1235\n",
      "Epoch 8/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5006 - acc: 0.2225 - val_loss: 14.1039 - val_acc: 0.1235\n",
      "Epoch 9/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4785 - acc: 0.2242 - val_loss: 14.1039 - val_acc: 0.1235\n",
      "Epoch 10/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4948 - acc: 0.2234 - val_loss: 14.1038 - val_acc: 0.1235\n",
      "Epoch 11/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5067 - acc: 0.2221 - val_loss: 14.1038 - val_acc: 0.1235\n",
      "Epoch 12/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5161 - acc: 0.2204 - val_loss: 14.1037 - val_acc: 0.1235\n",
      "Epoch 13/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5008 - acc: 0.2225 - val_loss: 14.1040 - val_acc: 0.1235\n",
      "Epoch 14/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5107 - acc: 0.2217 - val_loss: 14.1042 - val_acc: 0.1235\n",
      "Epoch 15/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4860 - acc: 0.2242 - val_loss: 14.1042 - val_acc: 0.1235\n",
      "Epoch 16/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5034 - acc: 0.2242 - val_loss: 14.1043 - val_acc: 0.1235\n",
      "Epoch 17/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5048 - acc: 0.2234 - val_loss: 14.1045 - val_acc: 0.1235\n",
      "Epoch 18/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5135 - acc: 0.2204 - val_loss: 14.1048 - val_acc: 0.1235\n",
      "Epoch 19/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5076 - acc: 0.2229 - val_loss: 14.1049 - val_acc: 0.1235\n",
      "Epoch 20/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4939 - acc: 0.2246 - val_loss: 14.1052 - val_acc: 0.1235\n",
      "Epoch 21/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5023 - acc: 0.2229 - val_loss: 14.1057 - val_acc: 0.1235\n",
      "Epoch 22/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4731 - acc: 0.2250 - val_loss: 14.1059 - val_acc: 0.1235\n",
      "Epoch 23/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5584 - acc: 0.2191 - val_loss: 14.1063 - val_acc: 0.1235\n",
      "Epoch 24/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5852 - acc: 0.2166 - val_loss: 14.1063 - val_acc: 0.1235\n",
      "Epoch 25/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5272 - acc: 0.2225 - val_loss: 14.1064 - val_acc: 0.1235\n",
      "Epoch 26/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5182 - acc: 0.2225 - val_loss: 14.1066 - val_acc: 0.1235\n",
      "Epoch 27/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.7108 - acc: 0.2107 - val_loss: 14.1065 - val_acc: 0.1235\n",
      "Epoch 28/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4898 - acc: 0.2242 - val_loss: 14.1063 - val_acc: 0.1235\n",
      "Epoch 29/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5355 - acc: 0.2217 - val_loss: 14.1064 - val_acc: 0.1235\n",
      "Epoch 30/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5841 - acc: 0.2187 - val_loss: 14.1063 - val_acc: 0.1235\n",
      "Epoch 31/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5532 - acc: 0.2195 - val_loss: 14.1064 - val_acc: 0.1235\n",
      "Epoch 32/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.6700 - acc: 0.2119 - val_loss: 14.1065 - val_acc: 0.1235\n",
      "Epoch 33/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.8032 - acc: 0.2026 - val_loss: 14.1061 - val_acc: 0.1235\n",
      "Epoch 34/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.8257 - acc: 0.2009 - val_loss: 14.1066 - val_acc: 0.1235\n",
      "Epoch 35/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5509 - acc: 0.2200 - val_loss: 14.1064 - val_acc: 0.1235\n",
      "Epoch 36/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5178 - acc: 0.2208 - val_loss: 14.1065 - val_acc: 0.1235\n",
      "Epoch 37/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5629 - acc: 0.2195 - val_loss: 14.1063 - val_acc: 0.1235\n",
      "Epoch 38/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.6206 - acc: 0.2153 - val_loss: 14.1075 - val_acc: 0.1235\n",
      "Epoch 39/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4923 - acc: 0.2242 - val_loss: 14.1077 - val_acc: 0.1235\n",
      "Epoch 40/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4994 - acc: 0.2238 - val_loss: 14.1078 - val_acc: 0.1235\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2364/2364 [==============================] - 0s - loss: 12.4933 - acc: 0.2242 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 42/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4969 - acc: 0.2238 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 43/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5232 - acc: 0.2217 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 44/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5534 - acc: 0.2200 - val_loss: 14.1077 - val_acc: 0.1235\n",
      "Epoch 45/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4906 - acc: 0.2246 - val_loss: 14.1076 - val_acc: 0.1235\n",
      "Epoch 46/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4929 - acc: 0.2242 - val_loss: 14.1077 - val_acc: 0.1235\n",
      "Epoch 47/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4803 - acc: 0.2238 - val_loss: 14.1076 - val_acc: 0.1235\n",
      "Epoch 48/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4716 - acc: 0.2263 - val_loss: 14.1079 - val_acc: 0.1235\n",
      "Epoch 49/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4982 - acc: 0.2246 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 50/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4844 - acc: 0.2242 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 51/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4861 - acc: 0.2246 - val_loss: 14.1080 - val_acc: 0.1235\n",
      "Epoch 52/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4793 - acc: 0.2250 - val_loss: 14.1077 - val_acc: 0.1235\n",
      "Epoch 53/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4921 - acc: 0.2242 - val_loss: 14.1076 - val_acc: 0.1235\n",
      "Epoch 54/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4912 - acc: 0.2250 - val_loss: 14.1077 - val_acc: 0.1235\n",
      "Epoch 55/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4855 - acc: 0.2250 - val_loss: 14.1081 - val_acc: 0.1235\n",
      "Epoch 56/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4857 - acc: 0.2246 - val_loss: 14.1081 - val_acc: 0.1235\n",
      "Epoch 57/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4919 - acc: 0.2246 - val_loss: 14.1081 - val_acc: 0.1235\n",
      "Epoch 58/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4854 - acc: 0.2250 - val_loss: 14.1082 - val_acc: 0.1235\n",
      "Epoch 59/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4992 - acc: 0.2246 - val_loss: 14.1084 - val_acc: 0.1235\n",
      "Epoch 60/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4914 - acc: 0.2250 - val_loss: 14.1085 - val_acc: 0.1235\n",
      "Epoch 61/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4917 - acc: 0.2250 - val_loss: 14.1087 - val_acc: 0.1235\n",
      "Epoch 62/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4855 - acc: 0.2246 - val_loss: 14.1086 - val_acc: 0.1235\n",
      "Epoch 63/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4852 - acc: 0.2250 - val_loss: 14.1088 - val_acc: 0.1235\n",
      "Epoch 64/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4788 - acc: 0.2255 - val_loss: 14.1083 - val_acc: 0.1235\n",
      "Epoch 65/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4923 - acc: 0.2246 - val_loss: 14.1084 - val_acc: 0.1235\n",
      "Epoch 66/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4827 - acc: 0.2250 - val_loss: 14.1082 - val_acc: 0.1235\n",
      "Epoch 67/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4852 - acc: 0.2255 - val_loss: 14.1084 - val_acc: 0.1235\n",
      "Epoch 68/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4887 - acc: 0.2242 - val_loss: 14.1085 - val_acc: 0.1235\n",
      "Epoch 69/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4847 - acc: 0.2255 - val_loss: 14.1086 - val_acc: 0.1235\n",
      "Epoch 70/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4851 - acc: 0.2255 - val_loss: 14.1087 - val_acc: 0.1235\n",
      "Epoch 71/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4862 - acc: 0.2250 - val_loss: 14.1089 - val_acc: 0.1235\n",
      "Epoch 72/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4857 - acc: 0.2246 - val_loss: 14.1091 - val_acc: 0.1235\n",
      "Epoch 73/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4919 - acc: 0.2250 - val_loss: 14.1094 - val_acc: 0.1235\n",
      "Epoch 74/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4863 - acc: 0.2246 - val_loss: 14.1091 - val_acc: 0.1235\n",
      "Epoch 75/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4918 - acc: 0.2246 - val_loss: 14.1091 - val_acc: 0.1235\n",
      "Epoch 76/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4851 - acc: 0.2250 - val_loss: 14.1090 - val_acc: 0.1235\n",
      "Epoch 77/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4857 - acc: 0.2246 - val_loss: 14.1088 - val_acc: 0.1235\n",
      "Epoch 78/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4848 - acc: 0.2255 - val_loss: 14.1090 - val_acc: 0.1235\n",
      "Epoch 79/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4918 - acc: 0.2250 - val_loss: 14.1094 - val_acc: 0.1235\n",
      "Epoch 80/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4914 - acc: 0.2250 - val_loss: 14.1095 - val_acc: 0.1235\n",
      "Epoch 81/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4829 - acc: 0.2246 - val_loss: 14.1093 - val_acc: 0.1235\n",
      "Epoch 82/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4847 - acc: 0.2255 - val_loss: 14.1093 - val_acc: 0.1235\n",
      "Epoch 83/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4845 - acc: 0.2255 - val_loss: 14.1095 - val_acc: 0.1235\n",
      "Epoch 84/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4779 - acc: 0.2259 - val_loss: 14.1095 - val_acc: 0.1235\n",
      "Epoch 85/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4851 - acc: 0.2250 - val_loss: 14.1096 - val_acc: 0.1235\n",
      "Epoch 86/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4845 - acc: 0.2255 - val_loss: 14.1097 - val_acc: 0.1235\n",
      "Epoch 87/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4844 - acc: 0.2255 - val_loss: 14.1098 - val_acc: 0.1235\n",
      "Epoch 88/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4780 - acc: 0.2255 - val_loss: 14.1099 - val_acc: 0.1235\n",
      "Epoch 89/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4823 - acc: 0.2255 - val_loss: 14.1101 - val_acc: 0.1235\n",
      "Epoch 90/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4847 - acc: 0.2250 - val_loss: 14.1101 - val_acc: 0.1235\n",
      "Epoch 91/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4845 - acc: 0.2255 - val_loss: 14.1101 - val_acc: 0.1235\n",
      "Epoch 92/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5012 - acc: 0.2238 - val_loss: 14.1096 - val_acc: 0.1235\n",
      "Epoch 93/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4700 - acc: 0.2259 - val_loss: 14.1099 - val_acc: 0.1235\n",
      "Epoch 94/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4888 - acc: 0.2250 - val_loss: 14.1102 - val_acc: 0.1235\n",
      "Epoch 95/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4781 - acc: 0.2250 - val_loss: 14.1100 - val_acc: 0.1235\n",
      "Epoch 96/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4975 - acc: 0.2242 - val_loss: 14.1097 - val_acc: 0.1235\n",
      "Epoch 97/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5190 - acc: 0.2225 - val_loss: 14.1105 - val_acc: 0.1235\n",
      "Epoch 98/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4532 - acc: 0.2267 - val_loss: 14.1104 - val_acc: 0.1235\n",
      "Epoch 99/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.4993 - acc: 0.2234 - val_loss: 14.1105 - val_acc: 0.1235\n",
      "Epoch 100/100\n",
      "2364/2364 [==============================] - 0s - loss: 12.5258 - acc: 0.2225 - val_loss: 14.1108 - val_acc: 0.1235\n",
      "704/734 [===========================>..] - ETA: 0sloss: 12.73\n",
      "10.22 (+/- 4.30)\n"
     ]
    }
   ],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=26)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(np.array(deep_train_1), y):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=162, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30,activation=\"relu\"))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    es=EarlyStopping(monitor=\"loss\",mode=\"min\",patience=100)\n",
    "    checkpoint=ModelCheckpoint(filepath=\"checknn\",save_best_only=True,monitor=\"val_loss\",mode=\"min\")\n",
    "    model.fit(np.array(deep_train_1)[train], y_cat[train],epochs=100,batch_size=50,validation_split=0.2,callbacks=[es,checkpoint],verbose=True)\n",
    "    model.load_weights(\"checknn\")\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(np.array(deep_train_1)[test], y_cat[test])\n",
    "    print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "    cvscores.append(scores[0])\n",
    "print(\"%.2f (+/- %.2f)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat=to_categorical(y,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
