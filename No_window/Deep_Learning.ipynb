{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import keras\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_train= {} \n",
    "work_test = {}\n",
    "pre_process=[\"tfidf_tsvd_100.csv\",\"w2v_100.csv\"]\n",
    "path=\"checkpoints_databases/\"\n",
    "for f in pre_process:\n",
    "    work_train[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_train_\"+f)\n",
    "    work_test[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path+\"nw_working_test_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"../bases/new_training_variants.csv\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_feat=pd.read_csv(\"../l2_meta_features/svd25_molecular_functions.csv\")\n",
    "magic_feat=magic_feat.drop([\"Class\",\"Gene\",\"ID\",\"Variation\"],axis=1)\n",
    "magic_train=magic_feat[:len(y)]\n",
    "magic_test=magic_feat[len(y):]\n",
    "magic_train=magic_train.reset_index(drop=True)\n",
    "magic_test=magic_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_test=work_test[\"w2v_100\"][\"ID\"]\n",
    "ID_train=work_train[\"w2v_100\"][\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train=work_train[\"tfidf_tsvd_100\"]#.merge(work_train[\"w2v_100\"])\n",
    "deep_train=deep_train.drop(\"ID\",axis=1)\n",
    "deep_test=work_test[\"tfidf_tsvd_100\"]#.merge(work_test[\"w2v_100\"])\n",
    "deep_test=deep_test.drop(\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train_1=pd.concat((deep_train,magic_train),axis=1)\n",
    "deep_test_1=pd.concat((deep_test,magic_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train_1[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Substitutions_var', 'Stop_codon_var', 'Fusion_var', 'gene_fusion_var',\n",
       "       'Deletion_var', 'del_or_ins_var', 'Amplification_var', 'Truncation_var',\n",
       "       'exon_var', 'frameshift_var',\n",
       "       ...\n",
       "       'molecular_SVD_16', 'molecular_SVD_17', 'molecular_SVD_18',\n",
       "       'molecular_SVD_19', 'molecular_SVD_20', 'molecular_SVD_21',\n",
       "       'molecular_SVD_22', 'molecular_SVD_23', 'molecular_SVD_24',\n",
       "       'molecular_SVD_25'],\n",
       "      dtype='object', length=162)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_train_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Substitutions_var', 'Stop_codon_var', 'Fusion_var', 'gene_fusion_var',\n",
       "       'Deletion_var', 'del_or_ins_var', 'Amplification_var', 'Truncation_var',\n",
       "       'exon_var', 'frameshift_var',\n",
       "       ...\n",
       "       'molecular_SVD_16', 'molecular_SVD_17', 'molecular_SVD_18',\n",
       "       'molecular_SVD_19', 'molecular_SVD_20', 'molecular_SVD_21',\n",
       "       'molecular_SVD_22', 'molecular_SVD_23', 'molecular_SVD_24',\n",
       "       'molecular_SVD_25'],\n",
       "      dtype='object', length=162)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_test_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3689, 162)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2356 samples, validate on 590 samples\n",
      "Epoch 1/100\n",
      "2356/2356 [==============================] - 1s - loss: 14.8663 - acc: 0.0764 - val_loss: 15.2747 - val_acc: 0.0508\n",
      "Epoch 2/100\n",
      "2356/2356 [==============================] - 0s - loss: 14.8540 - acc: 0.0781 - val_loss: 15.2748 - val_acc: 0.0508\n",
      "Epoch 3/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.8030 - acc: 0.1430 - val_loss: 13.1721 - val_acc: 0.1814\n",
      "Epoch 4/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2248 - acc: 0.1791 - val_loss: 13.1729 - val_acc: 0.1814\n",
      "Epoch 5/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2246 - acc: 0.1795 - val_loss: 13.1733 - val_acc: 0.1814\n",
      "Epoch 6/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2243 - acc: 0.1795 - val_loss: 13.1739 - val_acc: 0.1814\n",
      "Epoch 7/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2243 - acc: 0.1795 - val_loss: 13.1746 - val_acc: 0.1814\n",
      "Epoch 8/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2243 - acc: 0.1795 - val_loss: 13.1755 - val_acc: 0.1814\n",
      "Epoch 9/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1759 - val_acc: 0.1814\n",
      "Epoch 10/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1763 - val_acc: 0.1814\n",
      "Epoch 11/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1765 - val_acc: 0.1814\n",
      "Epoch 12/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1772 - val_acc: 0.1814\n",
      "Epoch 13/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1784 - val_acc: 0.1814\n",
      "Epoch 14/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1786 - val_acc: 0.1814\n",
      "Epoch 15/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1783 - val_acc: 0.1814\n",
      "Epoch 16/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1786 - val_acc: 0.1814\n",
      "Epoch 17/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1788 - val_acc: 0.1814\n",
      "Epoch 18/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1789 - val_acc: 0.1814\n",
      "Epoch 19/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1791 - val_acc: 0.1814\n",
      "Epoch 20/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1793 - val_acc: 0.1814\n",
      "Epoch 21/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1795 - val_acc: 0.1814\n",
      "Epoch 22/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1798 - val_acc: 0.1814\n",
      "Epoch 23/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1800 - val_acc: 0.1814\n",
      "Epoch 24/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1804 - val_acc: 0.1814\n",
      "Epoch 25/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1807 - val_acc: 0.1814\n",
      "Epoch 26/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1809 - val_acc: 0.1814\n",
      "Epoch 27/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1812 - val_acc: 0.1814\n",
      "Epoch 28/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1813 - val_acc: 0.1814\n",
      "Epoch 29/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1814 - val_acc: 0.1814\n",
      "Epoch 30/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1817 - val_acc: 0.1814\n",
      "Epoch 31/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1820 - val_acc: 0.1814\n",
      "Epoch 32/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1821 - val_acc: 0.1814\n",
      "Epoch 33/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1822 - val_acc: 0.1814\n",
      "Epoch 34/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1823 - val_acc: 0.1814\n",
      "Epoch 35/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1824 - val_acc: 0.1814\n",
      "Epoch 36/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1825 - val_acc: 0.1814\n",
      "Epoch 37/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1825 - val_acc: 0.1814\n",
      "Epoch 38/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1827 - val_acc: 0.1814\n",
      "Epoch 39/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1827 - val_acc: 0.1814\n",
      "Epoch 40/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1827 - val_acc: 0.1814\n",
      "Epoch 41/100\n",
      "2356/2356 [==============================] - 0s - loss: 13.2242 - acc: 0.1795 - val_loss: 13.1824 - val_acc: 0.1814\n",
      "544/743 [====================>.........] - ETA: 0sloss: 13.20\n",
      "Train on 2359 samples, validate on 590 samples\n",
      "Epoch 1/100\n",
      "2359/2359 [==============================] - 2s - loss: 12.4812 - acc: 0.2238 - val_loss: 15.3341 - val_acc: 0.0458\n",
      "Epoch 2/100\n",
      "2359/2359 [==============================] - 0s - loss: 14.6581 - acc: 0.0899 - val_loss: 15.3805 - val_acc: 0.0458\n",
      "Epoch 3/100\n",
      "2359/2359 [==============================] - 0s - loss: 14.6710 - acc: 0.0890 - val_loss: 15.3805 - val_acc: 0.0458\n",
      "Epoch 4/100\n",
      "2359/2359 [==============================] - 0s - loss: 14.6703 - acc: 0.0894 - val_loss: 15.3805 - val_acc: 0.0458\n",
      "Epoch 5/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.6861 - acc: 0.1509 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 6/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2075 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 7/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2075 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 8/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2074 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 9/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2074 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 10/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2074 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 11/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2074 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "Epoch 12/100\n",
      "2359/2359 [==============================] - 0s - loss: 13.2074 - acc: 0.1806 - val_loss: 13.2496 - val_acc: 0.1780\n",
      "544/740 [=====================>........] - ETA: 0sloss: 13.20\n",
      "Train on 2361 samples, validate on 591 samples\n",
      "Epoch 1/100\n",
      "2361/2361 [==============================] - 2s - loss: 13.2880 - acc: 0.1724 - val_loss: 14.0222 - val_acc: 0.1286\n",
      "Epoch 2/100\n",
      "2361/2361 [==============================] - 0s - loss: 12.5099 - acc: 0.2228 - val_loss: 14.0226 - val_acc: 0.1286\n",
      "Epoch 3/100\n",
      "2361/2361 [==============================] - 0s - loss: 12.5023 - acc: 0.2232 - val_loss: 15.3061 - val_acc: 0.0491\n",
      "Epoch 4/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6725 - acc: 0.0889 - val_loss: 15.3071 - val_acc: 0.0491\n",
      "Epoch 5/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6783 - acc: 0.0894 - val_loss: 15.3089 - val_acc: 0.0491\n",
      "Epoch 6/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6779 - acc: 0.0894 - val_loss: 15.3100 - val_acc: 0.0491\n",
      "Epoch 7/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6778 - acc: 0.0894 - val_loss: 15.3110 - val_acc: 0.0491\n",
      "Epoch 8/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6777 - acc: 0.0894 - val_loss: 15.3119 - val_acc: 0.0491\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 0s - loss: 14.6777 - acc: 0.0894 - val_loss: 15.3121 - val_acc: 0.0491\n",
      "Epoch 10/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6777 - acc: 0.0894 - val_loss: 15.3131 - val_acc: 0.0491\n",
      "Epoch 11/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6776 - acc: 0.0894 - val_loss: 15.3138 - val_acc: 0.0491\n",
      "Epoch 12/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6777 - acc: 0.0894 - val_loss: 15.3141 - val_acc: 0.0491\n",
      "Epoch 13/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6777 - acc: 0.0894 - val_loss: 15.3140 - val_acc: 0.0491\n",
      "Epoch 14/100\n",
      "2361/2361 [==============================] - 0s - loss: 14.6776 - acc: 0.0894 - val_loss: 15.3141 - val_acc: 0.0491\n",
      "736/737 [============================>.] - ETA: 0sloss: 12.82\n",
      "Train on 2363 samples, validate on 591 samples\n",
      "Epoch 1/100\n",
      "2363/2363 [==============================] - 2s - loss: 13.2572 - acc: 0.1756 - val_loss: 13.1497 - val_acc: 0.1827\n",
      "Epoch 2/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2226 - acc: 0.1786 - val_loss: 13.1508 - val_acc: 0.1827\n",
      "Epoch 3/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2216 - acc: 0.1786 - val_loss: 13.1513 - val_acc: 0.1827\n",
      "Epoch 4/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2207 - acc: 0.1794 - val_loss: 13.1535 - val_acc: 0.1827\n",
      "Epoch 5/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2194 - acc: 0.1799 - val_loss: 13.1558 - val_acc: 0.1827\n",
      "Epoch 6/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1562 - val_acc: 0.1827\n",
      "Epoch 7/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1573 - val_acc: 0.1827\n",
      "Epoch 8/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1576 - val_acc: 0.1827\n",
      "Epoch 9/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1586 - val_acc: 0.1827\n",
      "Epoch 10/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1592 - val_acc: 0.1827\n",
      "Epoch 11/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1604 - val_acc: 0.1827\n",
      "Epoch 12/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1602 - val_acc: 0.1827\n",
      "Epoch 13/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1607 - val_acc: 0.1827\n",
      "Epoch 14/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1608 - val_acc: 0.1827\n",
      "Epoch 15/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1616 - val_acc: 0.1827\n",
      "Epoch 16/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1616 - val_acc: 0.1827\n",
      "Epoch 17/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1622 - val_acc: 0.1827\n",
      "Epoch 18/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1627 - val_acc: 0.1827\n",
      "Epoch 19/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1626 - val_acc: 0.1827\n",
      "Epoch 20/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1633 - val_acc: 0.1827\n",
      "Epoch 21/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1647 - val_acc: 0.1827\n",
      "Epoch 22/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1647 - val_acc: 0.1827\n",
      "Epoch 23/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1647 - val_acc: 0.1827\n",
      "Epoch 24/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1647 - val_acc: 0.1827\n",
      "Epoch 25/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1648 - val_acc: 0.1827\n",
      "Epoch 26/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1647 - val_acc: 0.1827\n",
      "Epoch 27/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1648 - val_acc: 0.1827\n",
      "Epoch 28/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1648 - val_acc: 0.1827\n",
      "Epoch 29/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1649 - val_acc: 0.1827\n",
      "Epoch 30/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1649 - val_acc: 0.1827\n",
      "Epoch 31/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1649 - val_acc: 0.1827\n",
      "Epoch 32/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1650 - val_acc: 0.1827\n",
      "Epoch 33/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1651 - val_acc: 0.1827\n",
      "Epoch 34/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1653 - val_acc: 0.1827\n",
      "Epoch 35/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1654 - val_acc: 0.1827\n",
      "Epoch 36/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1656 - val_acc: 0.1827\n",
      "Epoch 37/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1657 - val_acc: 0.1827\n",
      "Epoch 38/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1659 - val_acc: 0.1827\n",
      "Epoch 39/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1660 - val_acc: 0.1827\n",
      "Epoch 40/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1673 - val_acc: 0.1827\n",
      "Epoch 41/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1674 - val_acc: 0.1827\n",
      "Epoch 42/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1673 - val_acc: 0.1827\n",
      "Epoch 43/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1671 - val_acc: 0.1827\n",
      "Epoch 44/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1671 - val_acc: 0.1827\n",
      "Epoch 45/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1671 - val_acc: 0.1827\n",
      "Epoch 46/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1671 - val_acc: 0.1827\n",
      "Epoch 47/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1673 - val_acc: 0.1827\n",
      "Epoch 48/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1673 - val_acc: 0.1827\n",
      "Epoch 49/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1673 - val_acc: 0.1827\n",
      "Epoch 50/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1673 - val_acc: 0.1827\n",
      "Epoch 51/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "Epoch 52/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1674 - val_acc: 0.1827\n",
      "Epoch 53/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1674 - val_acc: 0.1827\n",
      "Epoch 54/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "Epoch 55/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "Epoch 56/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "Epoch 58/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "Epoch 59/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1681 - val_acc: 0.1827\n",
      "Epoch 60/100\n",
      "2363/2363 [==============================] - 0s - loss: 13.2192 - acc: 0.1799 - val_loss: 13.1675 - val_acc: 0.1827\n",
      "576/735 [======================>.......] - ETA: 0sloss: 13.22\n",
      "Train on 2364 samples, validate on 591 samples\n",
      "Epoch 1/100\n",
      "2364/2364 [==============================] - 2s - loss: 14.0604 - acc: 0.1261 - val_loss: 12.9852 - val_acc: 0.1929\n",
      "Epoch 2/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.8183 - acc: 0.1413 - val_loss: 13.3156 - val_acc: 0.1726\n",
      "Epoch 3/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1820 - acc: 0.1810 - val_loss: 13.3148 - val_acc: 0.1726\n",
      "Epoch 4/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1808 - acc: 0.1823 - val_loss: 13.3172 - val_acc: 0.1726\n",
      "Epoch 5/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1798 - acc: 0.1823 - val_loss: 13.3178 - val_acc: 0.1726\n",
      "Epoch 6/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1796 - acc: 0.1823 - val_loss: 13.3181 - val_acc: 0.1726\n",
      "Epoch 7/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1797 - acc: 0.1823 - val_loss: 13.3203 - val_acc: 0.1726\n",
      "Epoch 8/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3207 - val_acc: 0.1726\n",
      "Epoch 9/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3211 - val_acc: 0.1726\n",
      "Epoch 10/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3214 - val_acc: 0.1726\n",
      "Epoch 11/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3221 - val_acc: 0.1726\n",
      "Epoch 12/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3224 - val_acc: 0.1726\n",
      "Epoch 13/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3226 - val_acc: 0.1726\n",
      "Epoch 14/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3229 - val_acc: 0.1726\n",
      "Epoch 15/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3233 - val_acc: 0.1726\n",
      "Epoch 16/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3241 - val_acc: 0.1726\n",
      "Epoch 17/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3253 - val_acc: 0.1726\n",
      "Epoch 18/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3251 - val_acc: 0.1726\n",
      "Epoch 19/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3250 - val_acc: 0.1726\n",
      "Epoch 20/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3252 - val_acc: 0.1726\n",
      "Epoch 21/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3256 - val_acc: 0.1726\n",
      "Epoch 22/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3261 - val_acc: 0.1726\n",
      "Epoch 23/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3277 - val_acc: 0.1726\n",
      "Epoch 24/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3277 - val_acc: 0.1726\n",
      "Epoch 25/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3278 - val_acc: 0.1726\n",
      "Epoch 26/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3277 - val_acc: 0.1726\n",
      "Epoch 27/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3278 - val_acc: 0.1726\n",
      "Epoch 28/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3278 - val_acc: 0.1726\n",
      "Epoch 29/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3286 - val_acc: 0.1726\n",
      "Epoch 30/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3280 - val_acc: 0.1726\n",
      "Epoch 31/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3274 - val_acc: 0.1726\n",
      "Epoch 32/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3273 - val_acc: 0.1726\n",
      "Epoch 33/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3272 - val_acc: 0.1726\n",
      "Epoch 34/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3272 - val_acc: 0.1726\n",
      "Epoch 35/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3273 - val_acc: 0.1726\n",
      "Epoch 36/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3280 - val_acc: 0.1726\n",
      "Epoch 37/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3281 - val_acc: 0.1726\n",
      "Epoch 38/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3282 - val_acc: 0.1726\n",
      "Epoch 39/100\n",
      "2364/2364 [==============================] - 0s - loss: 13.1795 - acc: 0.1823 - val_loss: 13.3283 - val_acc: 0.1726\n",
      "544/734 [=====================>........] - ETA: 0sloss: 13.94\n",
      "13.28 (+/- 0.37)\n"
     ]
    }
   ],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=26)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(np.array(deep_train_1), y):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_dim=162, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(300,activation=\"relu\"))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    es=EarlyStopping(monitor=\"loss\",mode=\"min\",patience=10)\n",
    "    checkpoint=ModelCheckpoint(filepath=\"checknn\",save_best_only=True,monitor=\"val_loss\",mode=\"min\")\n",
    "    model.fit(np.array(deep_train_1)[train], y_cat[train],epochs=100,batch_size=50,validation_split=0.2,callbacks=[es,checkpoint],verbose=True)\n",
    "    model.load_weights(\"checknn\")\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(np.array(deep_train_1)[test], y_cat[test])\n",
    "    print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "    cvscores.append(scores[0])\n",
    "print(\"%.2f (+/- %.2f)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat=to_categorical(y,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
