{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train=\"scores/stack_train/\"\n",
    "path_test=\"scores/stack_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_train = {} \n",
    "dict_test = {}\n",
    "train_files = [i for i in os.listdir(path_train)]\n",
    "test_files = [i for i in os.listdir(path_test)]\n",
    "for f in train_files:\n",
    "    dict_train[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path_train+f)\n",
    "for f in test_files:\n",
    "    dict_test[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path_test+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_no_ID=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7',\n",
    "       'class8', 'class9']\n",
    "del dict_train[\".DS_Store\"]\n",
    "del dict_test[\".DS_Store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Affecting  columns name\n",
    "for name in dict_test.keys():\n",
    "    dict_train[name].columns=[name+\"_\"+s for s in col_no_ID]+[\"ID\"]\n",
    "    dict_test[name].columns=[name+\"_\"+s for s in col_no_ID]+[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_train=dict_train[\"nowdw_XGB_medium\"].merge(dict_train[\"nowdw_XGB_small\"],\n",
    "on=\"ID\").merge(dict_train[\"nowdw_XGB_tall\"],on=\"ID\").merge(dict_train[\"XGB_M_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_S_d2v\"],on=\"ID\").merge(dict_train[\"XGB_T_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_S_tfidf\"],on=\"ID\").merge(dict_train[\"XGB_M_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_T_tfidf\"],on=\"ID\").merge(dict_train[\"XGB_S_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_M_w2v\"],on=\"ID\").merge(dict_train[\"XGB_T_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_S_d2v\"],on=\"ID\").merge(dict_train[\"LGBM_M_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_T_d2v\"],on=\"ID\").merge(dict_train[\"LGBM_S_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_M_tfidf\"],on=\"ID\").merge(dict_train[\"LGBM_T_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_S_w2v\"],on=\"ID\").merge(dict_train[\"LGBM_M_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_T_w2v\"],on=\"ID\").merge(dict_train[\"adaboost_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"adaboost_tfidf\"],on=\"ID\").merge(dict_train[\"adaboost_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"logit_d2v\"],on=\"ID\").merge(dict_train[\"logit_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"logit_w2v\"],on=\"ID\")#.merge(dict_train[\"nowdw_neural_net\"],on=\"ID\")\n",
    "#a tester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_test=dict_test[\"nowdw_XGB_medium\"].merge(dict_test[\"nowdw_XGB_small\"],\n",
    "on=\"ID\").merge(dict_test[\"nowdw_XGB_tall\"],on=\"ID\").merge(dict_test[\"XGB_M_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_S_d2v\"],on=\"ID\").merge(dict_test[\"XGB_T_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_S_tfidf\"],on=\"ID\").merge(dict_test[\"XGB_M_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_T_tfidf\"],on=\"ID\").merge(dict_test[\"XGB_S_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_M_w2v\"],on=\"ID\").merge(dict_test[\"XGB_T_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_S_d2v\"],on=\"ID\").merge(dict_test[\"LGBM_M_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_T_d2v\"],on=\"ID\").merge(dict_test[\"LGBM_S_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_M_tfidf\"],on=\"ID\").merge(dict_test[\"LGBM_T_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_S_w2v\"],on=\"ID\").merge(dict_test[\"LGBM_M_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_T_w2v\"],on=\"ID\").merge(dict_test[\"adaboost_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"adaboost_tfidf\"],on=\"ID\").merge(dict_test[\"adaboost_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"logit_d2v\"],on=\"ID\").merge(dict_test[\"logit_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"logit_w2v\"],on=\"ID\")#.merge(dict_test[\"nowdw_neural_net\"],on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quand le merging est fini : table unique, on peut monter un meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"bases/training_variants\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_test=stack_test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.array(stack_train.drop(\"ID\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=np.array(stack_test.drop(\"ID\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':[1,3,5],\n",
    " 'min_child_weight':[1,3,5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing other meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb=cross_val_score(XGBClassifier(objective=\"multi:softprob\",\n",
    "seed=26),X_train,y,scoring=\"neg_log_loss\",cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_log=cross_val_score(LogisticRegression(),X_train,y,scoring=\"neg_log_loss\",cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.90562516735978016"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_log.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y)\n",
    "y_test=clf.predict_proba(X_test)\n",
    "\n",
    "classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "sub = pd.DataFrame(y_test, columns=classes)\n",
    "sub['ID'] = ID_test\n",
    "sub.to_csv(\"scores/stacking_linear.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
