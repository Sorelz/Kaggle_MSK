{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('bases/training_variants')\n",
    "test = pd.read_csv('bases/test_variants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = pd.read_csv('bases/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"], encoding = \"utf-8\")\n",
    "test_texts = pd.read_csv('bases/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"], encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_texts, how='left', on='ID')\n",
    "test = pd.merge(test, test_texts, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transform Gene Letter to their abbreviation in order to find them in the text\n",
    "One_to_Three_AA = {'C': 'Cys', 'D': 'Asp', 'S': 'Ser', 'Q': 'Gln', 'K': 'Lys',\n",
    "         'I': 'Ile', 'P': 'Pro', 'T': 'Thr', 'F': 'Phe', 'N': 'Asn', \n",
    "         'G': 'Gly', 'H': 'His', 'L': 'Leu', 'R': 'Arg', 'W': 'Trp', \n",
    "         'A': 'Ala', 'V': 'Val', 'E': 'Glu', 'Y': 'Tyr', 'M': 'Met'}\n",
    "pattern = re.compile('|'.join(One_to_Three_AA.keys()))\n",
    "##### Get variation types by using regex\n",
    "def variation_regex(data, pattern): # if you want to not ignore cases, add extra argument to function\n",
    "    Boolean = [not bool(re.search(pattern, i, re.IGNORECASE)) for i in data.Variation]\n",
    "    data_no_regex = data[Boolean]  # 182 Fusions => 495 over \n",
    "    not_Boolean = [not i for i in Boolean]  \n",
    "    data_regex = data[not_Boolean]\n",
    "    \n",
    "    return (data_regex, data_no_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### process the train and test set together\n",
    "data_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "data_all_backup = data_all[:] ##### We keep backup because we want dummy variables of Gene & Text \n",
    "# TODO maybe also use Variation function of Gene from a database, and other suggestions. Also can use Count_sub as feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sub(data):\n",
    "\n",
    "    ##### The normal case is around 2080 out of the 2644\n",
    "    \n",
    "    \n",
    "    Boolean = [data.Variation[i] in data.Text[i] or #normal case\n",
    "               data.Variation[i][:-1] in data.Text[i] or #case 1.\n",
    "               pattern.sub(lambda x: One_to_Three_AA[x.group()], data.Variation[i][:-1]) # case2\n",
    "               in data.Text[i]  for i in data.index] ## because new indexing we use \n",
    "    \n",
    "    #TODO could also match insensitive as a next step for more info.\n",
    "    #Shorter Boolean below = the normal version\n",
    "    \n",
    "    #Boolean = [trainSub.Variation[i] in trainSub.Text[i] #normal case\n",
    "    #           for i in trainSub.ID] ## because new indexing we use ID\n",
    "    #           \n",
    "            \n",
    "    sub_in_text = data[Boolean]\n",
    "    not_Boolean = [not i for i in Boolean]  \n",
    "\n",
    "    sub_not_in_text = data[not_Boolean]\n",
    "#    sub_in_text['Count'] = [sub_in_text.Text[i].count(sub_in_text.Variation[i][:-1])\n",
    "#                    +sub_in_text.Text[i].count(pattern.sub(lambda x: One_to_Three_AA[x.group()], sub_in_text.Variation[i][:-1]))\n",
    "#                    for i in sub_in_text.index]\n",
    "    \n",
    "    return sub_in_text, sub_not_in_text\n",
    "##### For subs that are not find in text: use regex to account for a different number\n",
    "##### TODO: things you can further try - with AA name replacement, searching for the number only etc.\n",
    "def find_sub_noText(data):\n",
    "    Booleans = []\n",
    "    for i in data.index:\n",
    "        split_variation = re.split('(\\d+)', data.Variation[i]) # split based on a number\n",
    "        first_Amino = re.escape(split_variation[0]) #re.escpae uses variable as regex\n",
    "        last_Amino = re.escape(split_variation[-1])\n",
    "        #first_number = re.escape(split_variation[1][0])\n",
    "        #new_regex = r\"[^a-zA-Z0-9]\" + first_Amino + first_number\n",
    "        new_regex  = first_Amino + r\"\\d+\" + last_Amino\n",
    "        Boolean = bool(re.search(new_regex, data.Text[i]))\n",
    "        Booleans.append(Boolean)\n",
    "    \n",
    "    sub_number_in_text = data[Booleans]\n",
    "    not_Boolean = [not i for i in Booleans]  \n",
    "\n",
    "    sub_again_no_text = data[not_Boolean]\n",
    "    return sub_again_no_text, sub_number_in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Next we use a window to extract sentences\n",
    "def get_sentences_sub(data, splitted_sentences, window_left, window_right):\n",
    "    #position_sentences = [[] for _ in range(len(data))]  #### currently not used\n",
    "    data.index = range(len(data))\n",
    "    sentences_with_sub = [[] for _ in range(len(data))]\n",
    "    \n",
    "    for i in range(len(splitted_sentences)):\n",
    "        sentences = splitted_sentences[i]\n",
    "        one_to_three_variation = pattern.sub(lambda x: One_to_Three_AA[x.group()], data.Variation[i][:-1])\n",
    "        Variation = data.Variation[i][:-1]        \n",
    "        for j in range(len(sentences)):                              \n",
    "            if (Variation in sentences[j]) or (one_to_three_variation in sentences[j]):\n",
    "                new_regex = re.escape(Variation) + r\"[\\S]*\" ### Means no white space 0 or more\n",
    "                sentences[j] = re.sub(new_regex, ' placeholderMutation', sentences[j]) #case 1\n",
    "                new_regex = re.escape(one_to_three_variation) + r\"[\\S]*\"\n",
    "                sentences[j] = re.sub(new_regex, ' placeholderMutation', sentences[j]) #case 2\n",
    "                sentences_with_sub[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "                \n",
    "                ### We add space to ' placeholderMutation' because sometimes there are letters in front of it\n",
    "                # position_sentences[i].append(j) # not used for the moment\n",
    "\n",
    "    return sentences_with_sub   ### This might take a while because it's looping through all sentences\n",
    "def get_sentences_sub_noText(data, splitted_sentences, window_left, window_right):\n",
    "    #position_sentences = [[] for _ in range(len(data))]  #### currently not used\n",
    "    data.index = range(len(data))\n",
    "    sentences_with_sub = [[] for _ in range(len(data))]\n",
    "    \n",
    "    for i in range(len(splitted_sentences)):\n",
    "        sentences = splitted_sentences[i] \n",
    "        for j in range(len(sentences)):\n",
    "            split_variation = re.split('(\\d+)', data.Variation[i]) # split based on a number\n",
    "            first_Amino = re.escape(split_variation[0]) #re.escpae uses variable as regex\n",
    "            last_Amino = re.escape(split_variation[-1])\n",
    "            new_regex  = first_Amino + r\"\\d+\" + last_Amino\n",
    "            \n",
    "            #counter=len(re.findall(new_regex, sentences[j]))\n",
    "            \n",
    "            Boolean = bool(re.search(new_regex, sentences[j]))\n",
    "            if Boolean:\n",
    "                sentences[j] = re.sub(new_regex, ' placeholderMutation', sentences[j]) # Might help catch sy\n",
    "                sentences_with_sub[i].extend(sentences[j-window_left : j+1+window_right])\n",
    "                # position_sentences[i].append(j) # not used for the moment\n",
    "\n",
    "    return sentences_with_sub   ### This might take a while because it's looping through all sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Converts list of sentences into one string of sentences for each document => to use for tfidf etc.\n",
    "def sentences_to_string(sentences_list):\n",
    "    sentence_strings = []\n",
    "    for sentences in sentences_list:\n",
    "        sentence_string =  ' '.join(str(sentence) for sentence in sentences)\n",
    "        sentence_strings.append(sentence_string)\n",
    "    \n",
    "    return sentence_strings ### This doesn't take such a long time to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitutions (subs) processing of data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### First find those that have the format of being a substitution in data\n",
    "data_all['Substitutions_var'] = data_all.Variation.apply(lambda x: bool(re.search('^[A-Z]\\\\d+[A-Z*]$', x))*1) #multiplying by 1 converts True to 1, False to 0 => Maybe modify this later?\n",
    "data_all['Stop_codon_var'] = data_all.Variation.apply(lambda x: bool(re.search('[*]', x))*1) #multiplying by 1 converts True to 1, False to 0\n",
    "data_sub = data_all[data_all['Substitutions_var']==1] ### Now we know the index of where a substitution occurs - the data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_in_text, sub_not_in_text = find_sub(data_sub)\n",
    "sub_in_text_backup = sub_in_text[:] ## index gets changed by text_processing if we don't make a copy\n",
    "##### INVESTIGATION: Why do some subs don't appear in Text?: Try to automize this and find out\n",
    "### Substitutions can appear as SAME_PREFIX - Other number - SAME_SUFFIX\n",
    "\n",
    "sub_again_no_Text, sub_noText = find_sub_noText(sub_not_in_text) # 108 such cases out of 411 = nice improvement\n",
    "sub_noText_backup = sub_noText[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on variations who have the 2 letters right but not same numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLTK_sub = [sent_tokenize(sub_in_text.Text[i]) for i in sub_in_text.index] # takes a long time to run tokenizer => use pickle to save\n",
    "sub_sentences = get_sentences_sub(sub_in_text, NLTK_sub, window_left = 2, window_right = 2) \n",
    "# Retrieves sentences where subsitution mutation is included.\n",
    "# window_left and window_right specify which sentences to keep at the left side or right side of the sub sentences.\n",
    "# IMPORTANT: I used also placeholderMutation to replace the original sub mutations here\n",
    "sub_sentences = [sorted(set(sentences), key = sentences.index) for sentences in sub_sentences] # only uses unique sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLTK_sub_noText = [sent_tokenize(sub_noText.Text[i]) for i in sub_noText.index]\n",
    "sub_noText_sentences = get_sentences_sub_noText(sub_noText, NLTK_sub_noText, window_left = 2, window_right = 2) # Retrieves sentences where subsitution mutation is included\n",
    "sub_noText_sentences = [sorted(set(sentences), key = sentences.index) for sentences in sub_noText_sentences] # only use unique sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sentences_string = sentences_to_string(sub_sentences)\n",
    "sub_noText_string = sentences_to_string(sub_noText_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafiz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\rafiz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_all.Text[sub_in_text_backup.index] = sub_sentences_string\n",
    "data_all.Text[sub_noText_backup.index] = sub_noText_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "############## Non-subs preprocessing of data set #######################\n",
    "\n",
    "#def find_mutation_type(row, pattern):  ##### TODO: make clearer by using a function instead of lambda\n",
    "#    return bool(re.search('^fusion', row, re.IGNORECASE)) *1. Also for subs\n",
    "\n",
    "####### Fusions : 'Fusions' ############\n",
    "data_all['Fusion_var'] = data_all.Variation.apply(lambda x: bool(re.search('^fusion', x, re.IGNORECASE))*1) #multiplying by 1 converts True to 1, False to 0\n",
    "new_fusion, new_data_all = variation_regex(data_all, '^fusion') \n",
    "\n",
    "###### Fusions: 'Gene-Gene fusion' ########\n",
    "data_all['gene_fusion_var'] = new_data_all.Variation.apply(lambda x: bool(re.search('fusion', x, re.IGNORECASE))*1) \n",
    "_ , new_data_all = variation_regex(new_data_all, 'fusion') \n",
    "###### Notice that NaN introduced for places where splicing occured => replace after NaN with 0's when complete\n",
    "\n",
    "####### Deletions: 'Deletions' ############\n",
    "data_all['Deletion_var'] = new_data_all.Variation.apply(lambda x: bool(re.search('^del', x, re.IGNORECASE))*1) \n",
    "new_del, new_data_all = variation_regex(new_data_all, '^del') \n",
    "\n",
    "####### Deletions & Insertions wheteher together or seperately (doesn't make a big difference IMO)\n",
    "data_all['del_or_ins_var'] = new_data_all.Variation.apply(lambda x: bool(re.search('del|ins', x, re.IGNORECASE))*1) \n",
    "# we could also later divide it into del, ins if we want to\n",
    "\n",
    "###### Amplifications #########\n",
    "data_all['Amplification_var'] = data_all.Variation.apply(lambda x: bool(re.search('ampl', x, re.IGNORECASE))*1) \n",
    "\n",
    "###### Truncations ########### Don't forget there are 'Truncating mutations' = 95 and '_trunc' = 4\n",
    "data_all['Truncation_var'] = data_all.Variation.apply(lambda x: bool(re.search('trunc', x, re.IGNORECASE))*1) \n",
    "\n",
    "####### Exons #########\n",
    "data_all['exon_var'] = data_all.Variation.apply(lambda x: bool(re.search('exon', x, re.IGNORECASE))*1) \n",
    "\n",
    "####### Frameshift mutations ########\n",
    "data_all['frameshift_var'] = data_all.Variation.apply(lambda x: bool(re.search('fs', x, re.IGNORECASE))*1) \n",
    "\n",
    "####### Duplications ##############\n",
    "data_all['dup_var'] = data_all.Variation.apply(lambda x: bool(re.search('dup', x, re.IGNORECASE))*1) \n",
    "\n",
    "data_all.fillna(0, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO : #Sentence Tokenizer for non-subs that are not in text, AND\n",
    "#subs that are not in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not used\n",
    "################ The dummy variables for Gene and Text ##################\n",
    "## TODO: also use dummy for Text? There are 135 shared Genes and 142 shared Text between train and Leaks!  len(set(train.Text) & set(Leaks.Text))\n",
    "#data_all_dummy = data_all_backup[['Gene', 'Text']] # drop those columns we don't need as dummy.\n",
    "#X_dummy = pd.get_dummies(data_all_dummy) # converts categorical variables into dummy variable. From len set => 269 genes + 2090 texts\n",
    "#X_dummy_train = X_dummy[:train.shape[0]]\n",
    "#X_dummy_test = X_dummy[train.shape[0]:]\n",
    "#dummy_names = X_dummy.columns.values #### To remember names if you want to check again what Gene or Text used\n",
    "#X_dummy = X_dummy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Use the variation types \n",
    "#variation_types = data_all.drop(['ID', 'Gene', 'Class', 'Text', 'Variation'], axis =1)\n",
    "#X_variation_train = variation_types[:train.shape[0]]\n",
    "#X_variation_test = variation_types[train.shape[0]:]\n",
    "#variation_names = variation_types.columns.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'~', ']', '_', '2', ')', '[', '4', '8', ';', '3', '<', '^', '(', '{', '|', '>', '7', \"'\", '}', '@', '`', '5', '\"', ':', '1', '=', '$', '&', '9', '\\\\', '6', '!', '0', '*', '%', '#', '?', '+'}\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set('!\"#$%&\\'()*+:;<=>?@[\\\\]^_`{|}~0123456789') \n",
    "print(exclude)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc,lemmatiz=False):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free_0 = [re.sub(\",|\\.|/\",\" \",ch) for ch in stop_free]\n",
    "    if lemmatiz:\n",
    "        punc_free_lem=\"\".join(ch for ch in punc_free_0 if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free_lem.split())\n",
    "        return normalized\n",
    "    else:\n",
    "        punc_free = \"\".join(ch for ch in punc_free_0 if ch not in exclude)\n",
    "        return punc_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#No lemmatization for the moment, be careful not to lemmatize then w2vec\n",
    "data_all.Text = [clean(doc) for doc in data_all.Text]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some more features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Class     Gene    ID                                               Text  \\\n",
      "0       1.0   FAM58A     0  cyclin-dependent kinases cdks regulate variety...   \n",
      "1       2.0      CBL     1  normal tumor pairwise analysis  significant lo...   \n",
      "2       2.0      CBL     2  normal tumor pairwise analysis  significant lo...   \n",
      "3       3.0      CBL     3  hrm analysis cbl exons   blast crisis cases n ...   \n",
      "4       4.0      CBL     4  vm mutant borderline densitometry ratio    mut...   \n",
      "5       4.0      CBL     5  vm mutant borderline densitometry ratio    mut...   \n",
      "6       5.0      CBL     6  figure  figure  structures wild type green ke ...   \n",
      "7       1.0      CBL     7  cbl negative regulator activated receptor tyro...   \n",
      "8       4.0      CBL     8  subset jmml patients harbor cbl mutations asso...   \n",
      "9       4.0      CBL     9  subset jmml patients harbor cbl mutations asso...   \n",
      "10      4.0      CBL    10  vm mutant borderline densitometry ratio    mut...   \n",
      "11      4.0      CBL    11  materials methods plasmids used human wild-typ...   \n",
      "12      4.0      CBL    12  materials methods plasmids used human wild-typ...   \n",
      "13      4.0      CBL    13  materials methods plasmids used human wild-typ...   \n",
      "14      5.0      CBL    14  figure  figure  structures wild type green ke ...   \n",
      "15      4.0      CBL    15  materials methods plasmids used human wild-typ...   \n",
      "16      1.0      CBL    16  determine residual cylindrical refractive erro...   \n",
      "17      4.0      CBL    17  transformed niht cells showed pi kinase-depend...   \n",
      "18      5.0      CBL    18  figure  figure  structures wild type green ke ...   \n",
      "19      4.0      CBL    19  transformed niht cells showed pi kinase-depend...   \n",
      "20      6.0      CBL    20  normal tumor pairwise analysis  significant lo...   \n",
      "21      4.0      CBL    21  hekt cells transfected plasmids encoding wild-...   \n",
      "22      4.0      CBL    22  vm mutant borderline densitometry ratio    mut...   \n",
      "23      4.0      CBL    23  overall survival a progression-free survival b...   \n",
      "24      4.0      CBL    24  fully sequenced coding exons genes  cases q au...   \n",
      "25      4.0      CBL    25  overall survival a progression-free survival b...   \n",
      "26      4.0    SHOC2    26  abstract n-myristoylation common form co-trans...   \n",
      "27      4.0     TERT    27  families contain compound heterozygotes  one c...   \n",
      "28      7.0     TERT    28  average sequence coverage tert promoter locus ...   \n",
      "29      4.0     TERT    29  describe  families  tert mutations segregating...   \n",
      "...     ...      ...   ...                                                ...   \n",
      "8959    0.0     VSX1  5638  using dna microarray approach screen gene copy...   \n",
      "8960    0.0     MTM1  5639  according latest version tp mutation database ...   \n",
      "8961    0.0   D2HGDH  5640  four members human fibroblast growth factor re...   \n",
      "8962    0.0      DMD  5641  serine threonine protein kinase encoded akf pr...   \n",
      "8963    0.0     ANKH  5642  nuclear transport machinery sole process-level...   \n",
      "8964    0.0      DCX  5643  ezh enhancer zeste homolog  critical enzymatic...   \n",
      "8965    0.0     ADSL  5644  go to results generation characterization idhr...   \n",
      "8966    0.0  HSD17B3  5645  handful studies genetics acinar cell carcinoma...   \n",
      "8967    0.0     CD96  5646  normal wnt signaling begins wnt ligand binds r...   \n",
      "8968    0.0     HPS3  5647  materials methods family patient selection thi...   \n",
      "8969    0.0     FKTN  5648  patients principal subtype nsclc  lung squamou...   \n",
      "8970    0.0    DARS2  5649  met   nsclc   hermark serum larger activation ...   \n",
      "8971    0.0     TP53  5650  intragenic suppressor mutations instructive  p...   \n",
      "8972    0.0    ALG12  5651  overall patients detail determined function pl...   \n",
      "8973    0.0    ACOX1  5652  biopsy left eyebrow lesion showed well-differe...   \n",
      "8974    0.0   CLDN19  5653  analysis extended panel phosphoinositide pathw...   \n",
      "8975    0.0     MLH3  5654  paracrine communication oocytes somatic cells ...   \n",
      "8976    0.0     GJB1  5655  checkpoint kinase  chek  chk emerges important...   \n",
      "8977    0.0     LRP5  5656  brca conjunction n-myc interacting protein nmi...   \n",
      "8978    0.0    TGFBI  5657  akt- thought involved placental development  a...   \n",
      "8979    0.0   CYP2C9  5658  occurring responders expression table placehol...   \n",
      "8980    0.0  HSD17B3  5659  background  aims inherited deleterious mutatio...   \n",
      "8981    0.0     CAV3  5660  however  dna copy number gene expression signa...   \n",
      "8982    0.0    ABHD5  5661  diffuse large b cell lymphoma dlbcl complex di...   \n",
      "8983    0.0    NR3C2  5662  figure largedownload placeholdermutation clone...   \n",
      "8984    0.0  SLC46A1  5663  oncogenic activation â€” themes variations human...   \n",
      "8985    0.0    FOXC1  5664  cases  deletions highlight chromosomal loci co...   \n",
      "8986    0.0      GSS  5665  placeholdermutation smartpool investigate  exp...   \n",
      "8987    0.0     CTSK  5666  patients methods subjects classical nf bilater...   \n",
      "8988    0.0   DFNB59  5667  conclusion results vivo yeast-based approach c...   \n",
      "\n",
      "                 Variation  Substitutions_var  Stop_codon_var  Fusion_var  \\\n",
      "0     Truncating Mutations                  0               0           0   \n",
      "1                    W802*                  1               1           0   \n",
      "2                    Q249E                  1               0           0   \n",
      "3                    N454D                  1               0           0   \n",
      "4                    L399V                  1               0           0   \n",
      "5                    V391I                  1               0           0   \n",
      "6                    V430M                  1               0           0   \n",
      "7                 Deletion                  0               0           0   \n",
      "8                    Y371H                  1               0           0   \n",
      "9                    C384R                  1               0           0   \n",
      "10                   P395A                  1               0           0   \n",
      "11                   K382E                  1               0           0   \n",
      "12                   R420Q                  1               0           0   \n",
      "13                   C381A                  1               0           0   \n",
      "14                   P428L                  1               0           0   \n",
      "15                   D390Y                  1               0           0   \n",
      "16    Truncating Mutations                  0               0           0   \n",
      "17                   Q367P                  1               0           0   \n",
      "18                   M374V                  1               0           0   \n",
      "19                   Y371S                  1               0           0   \n",
      "20                    H94Y                  1               0           0   \n",
      "21                   C396R                  1               0           0   \n",
      "22                   G375P                  1               0           0   \n",
      "23                   S376F                  1               0           0   \n",
      "24                   P417A                  1               0           0   \n",
      "25                   H398Y                  1               0           0   \n",
      "26                     S2G                  1               0           0   \n",
      "27                   Y846C                  1               0           0   \n",
      "28                   C228T                  1               0           0   \n",
      "29                   H412Y                  1               0           0   \n",
      "...                    ...                ...             ...         ...   \n",
      "8959                 R166W                  1               0           0   \n",
      "8960                 E157K                  1               0           0   \n",
      "8961                 V444A                  1               0           0   \n",
      "8962                 Y231N                  1               0           0   \n",
      "8963                 G389R                  1               0           0   \n",
      "8964                  R59L                  1               0           0   \n",
      "8965                 R190Q                  1               0           0   \n",
      "8966                  A56T                  1               0           0   \n",
      "8967                 T280M                  1               0           0   \n",
      "8968                 R397W                  1               0           0   \n",
      "8969                 R179T                  1               0           0   \n",
      "8970                 L613F                  1               0           0   \n",
      "8971                 G245C                  1               0           0   \n",
      "8972                  T67M                  1               0           0   \n",
      "8973                 Q309R                  1               0           0   \n",
      "8974                  Q57E                  1               0           0   \n",
      "8975                 N499S                  1               0           0   \n",
      "8976                 F235C                  1               0           0   \n",
      "8977                 G171V                  1               0           0   \n",
      "8978                 R124S                  1               0           0   \n",
      "8979                 I359L                  1               0           0   \n",
      "8980                 M235V                  1               0           0   \n",
      "8981                  A46V                  1               0           0   \n",
      "8982                 E260K                  1               0           0   \n",
      "8983                 S818L                  1               0           0   \n",
      "8984                 R113S                  1               0           0   \n",
      "8985                 L130F                  1               0           0   \n",
      "8986                 R267W                  1               0           0   \n",
      "8987                  G79E                  1               0           0   \n",
      "8988                  T54I                  1               0           0   \n",
      "\n",
      "      gene_fusion_var  Deletion_var  del_or_ins_var  Amplification_var  \\\n",
      "0                 0.0           0.0             0.0                  0   \n",
      "1                 0.0           0.0             0.0                  0   \n",
      "2                 0.0           0.0             0.0                  0   \n",
      "3                 0.0           0.0             0.0                  0   \n",
      "4                 0.0           0.0             0.0                  0   \n",
      "5                 0.0           0.0             0.0                  0   \n",
      "6                 0.0           0.0             0.0                  0   \n",
      "7                 0.0           1.0             0.0                  0   \n",
      "8                 0.0           0.0             0.0                  0   \n",
      "9                 0.0           0.0             0.0                  0   \n",
      "10                0.0           0.0             0.0                  0   \n",
      "11                0.0           0.0             0.0                  0   \n",
      "12                0.0           0.0             0.0                  0   \n",
      "13                0.0           0.0             0.0                  0   \n",
      "14                0.0           0.0             0.0                  0   \n",
      "15                0.0           0.0             0.0                  0   \n",
      "16                0.0           0.0             0.0                  0   \n",
      "17                0.0           0.0             0.0                  0   \n",
      "18                0.0           0.0             0.0                  0   \n",
      "19                0.0           0.0             0.0                  0   \n",
      "20                0.0           0.0             0.0                  0   \n",
      "21                0.0           0.0             0.0                  0   \n",
      "22                0.0           0.0             0.0                  0   \n",
      "23                0.0           0.0             0.0                  0   \n",
      "24                0.0           0.0             0.0                  0   \n",
      "25                0.0           0.0             0.0                  0   \n",
      "26                0.0           0.0             0.0                  0   \n",
      "27                0.0           0.0             0.0                  0   \n",
      "28                0.0           0.0             0.0                  0   \n",
      "29                0.0           0.0             0.0                  0   \n",
      "...               ...           ...             ...                ...   \n",
      "8959              0.0           0.0             0.0                  0   \n",
      "8960              0.0           0.0             0.0                  0   \n",
      "8961              0.0           0.0             0.0                  0   \n",
      "8962              0.0           0.0             0.0                  0   \n",
      "8963              0.0           0.0             0.0                  0   \n",
      "8964              0.0           0.0             0.0                  0   \n",
      "8965              0.0           0.0             0.0                  0   \n",
      "8966              0.0           0.0             0.0                  0   \n",
      "8967              0.0           0.0             0.0                  0   \n",
      "8968              0.0           0.0             0.0                  0   \n",
      "8969              0.0           0.0             0.0                  0   \n",
      "8970              0.0           0.0             0.0                  0   \n",
      "8971              0.0           0.0             0.0                  0   \n",
      "8972              0.0           0.0             0.0                  0   \n",
      "8973              0.0           0.0             0.0                  0   \n",
      "8974              0.0           0.0             0.0                  0   \n",
      "8975              0.0           0.0             0.0                  0   \n",
      "8976              0.0           0.0             0.0                  0   \n",
      "8977              0.0           0.0             0.0                  0   \n",
      "8978              0.0           0.0             0.0                  0   \n",
      "8979              0.0           0.0             0.0                  0   \n",
      "8980              0.0           0.0             0.0                  0   \n",
      "8981              0.0           0.0             0.0                  0   \n",
      "8982              0.0           0.0             0.0                  0   \n",
      "8983              0.0           0.0             0.0                  0   \n",
      "8984              0.0           0.0             0.0                  0   \n",
      "8985              0.0           0.0             0.0                  0   \n",
      "8986              0.0           0.0             0.0                  0   \n",
      "8987              0.0           0.0             0.0                  0   \n",
      "8988              0.0           0.0             0.0                  0   \n",
      "\n",
      "      Truncation_var  exon_var  frameshift_var  dup_var  Gene_Share  \\\n",
      "0                  1         0               0        0           1   \n",
      "1                  0         0               0        0           1   \n",
      "2                  0         0               0        0           1   \n",
      "3                  0         0               0        0           1   \n",
      "4                  0         0               0        0           1   \n",
      "5                  0         0               0        0           1   \n",
      "6                  0         0               0        0           1   \n",
      "7                  0         0               0        0           1   \n",
      "8                  0         0               0        0           1   \n",
      "9                  0         0               0        0           1   \n",
      "10                 0         0               0        0           1   \n",
      "11                 0         0               0        0           1   \n",
      "12                 0         0               0        0           1   \n",
      "13                 0         0               0        0           1   \n",
      "14                 0         0               0        0           1   \n",
      "15                 0         0               0        0           1   \n",
      "16                 1         0               0        0           1   \n",
      "17                 0         0               0        0           1   \n",
      "18                 0         0               0        0           1   \n",
      "19                 0         0               0        0           1   \n",
      "20                 0         0               0        0           1   \n",
      "21                 0         0               0        0           1   \n",
      "22                 0         0               0        0           1   \n",
      "23                 0         0               0        0           1   \n",
      "24                 0         0               0        0           1   \n",
      "25                 0         0               0        0           1   \n",
      "26                 0         0               0        0           1   \n",
      "27                 0         0               0        0           1   \n",
      "28                 0         0               0        0           1   \n",
      "29                 0         0               0        0           1   \n",
      "...              ...       ...             ...      ...         ...   \n",
      "8959               0         0               0        0           0   \n",
      "8960               0         0               0        0           0   \n",
      "8961               0         0               0        0           0   \n",
      "8962               0         0               0        0           0   \n",
      "8963               0         0               0        0           0   \n",
      "8964               0         0               0        0           0   \n",
      "8965               0         0               0        0           0   \n",
      "8966               0         0               0        0           0   \n",
      "8967               0         0               0        0           0   \n",
      "8968               0         0               0        0           0   \n",
      "8969               0         0               0        0           0   \n",
      "8970               0         0               0        0           0   \n",
      "8971               0         0               0        0           1   \n",
      "8972               0         0               0        0           0   \n",
      "8973               0         0               0        0           0   \n",
      "8974               0         0               0        0           0   \n",
      "8975               0         0               0        0           0   \n",
      "8976               0         0               0        0           0   \n",
      "8977               0         0               0        0           0   \n",
      "8978               0         0               0        0           0   \n",
      "8979               0         0               0        0           0   \n",
      "8980               0         0               0        0           0   \n",
      "8981               0         0               0        0           0   \n",
      "8982               0         0               0        0           0   \n",
      "8983               0         0               0        0           0   \n",
      "8984               0         0               0        0           0   \n",
      "8985               0         0               0        0           0   \n",
      "8986               0         0               0        0           0   \n",
      "8987               0         0               0        0           0   \n",
      "8988               0         0               0        0           0   \n",
      "\n",
      "      Variation_Share  Text_words  Figure_counter  \n",
      "0                   1        4871               0  \n",
      "1                   1        1155               0  \n",
      "2                   1        1153               0  \n",
      "3                   1         645               8  \n",
      "4                   1         113               0  \n",
      "5                   1         113               0  \n",
      "6                   1         180               0  \n",
      "7                   0       11966               0  \n",
      "8                   1        3572               0  \n",
      "9                   1        2889               0  \n",
      "10                  1         113               0  \n",
      "11                  1        2191               6  \n",
      "12                  1        8224              14  \n",
      "13                  1        1438               6  \n",
      "14                  0          68               0  \n",
      "15                  0        1919               6  \n",
      "16                  1        6499               0  \n",
      "17                  0         380               0  \n",
      "18                  1         239               0  \n",
      "19                  0         287               0  \n",
      "20                  0        1456               0  \n",
      "21                  0         195               0  \n",
      "22                  1         112               0  \n",
      "23                  0         256               8  \n",
      "24                  1         474               8  \n",
      "25                  0         417               8  \n",
      "26                  1        2102               0  \n",
      "27                  1         274               0  \n",
      "28                  1         989               0  \n",
      "29                  1         260               0  \n",
      "...               ...         ...             ...  \n",
      "8959                1        2447               7  \n",
      "8960                1        7071              11  \n",
      "8961                1        1268               6  \n",
      "8962                1        2554               3  \n",
      "8963                1        4439               0  \n",
      "8964                1        2409               3  \n",
      "8965                1        3364               3  \n",
      "8966                1        2332               0  \n",
      "8967                1        6027               4  \n",
      "8968                1         935               0  \n",
      "8969                1        3838               4  \n",
      "8970                1        1958               7  \n",
      "8971                1         638               0  \n",
      "8972                1        1919               0  \n",
      "8973                1        1654               2  \n",
      "8974                1        1794               0  \n",
      "8975                1        3965               0  \n",
      "8976                1        3027               0  \n",
      "8977                1        2423               2  \n",
      "8978                1        4092               4  \n",
      "8979                1        1710               2  \n",
      "8980                1        2206               0  \n",
      "8981                1        3090               1  \n",
      "8982                1        3613               2  \n",
      "8983                1        4132               0  \n",
      "8984                1        3094               4  \n",
      "8985                1         895               0  \n",
      "8986                1         915               0  \n",
      "8987                1        5279               0  \n",
      "8988                1        1330               0  \n",
      "\n",
      "[8989 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "#Some counters on the gene and variation, here not using the 3letters abreviations\n",
    "#that means if the text contains only the gene or variation but with the \n",
    "#3letters format, the variable will capture it\n",
    "print(data_all)\n",
    "data_all[\"Gene_Share\"] = data_all_backup.apply(lambda r: sum([1 for w in r[\"Gene\"].split(\" \") if w in r[\"Text\"].split(\" \")]), axis=1)\n",
    "data_all[\"Variation_Share\"] = data_all_backup.apply(lambda r: sum([1 for w in r[\"Variation\"].split(\" \") if w in r[\"Text\"].split(\" \")]), axis=1)\n",
    "\n",
    "data_all[\"Text_words\"] = data_all[\"Text\"].map(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure_counter=[\"fig\",\"figure\"]\n",
    "for fig in figure_counter: \n",
    "        data_all[\"Figure_counter\"]=(data_all_backup[\"Text\"].map(lambda x : str(x).count(fig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all[\"Text\"]=[re.sub(\"fig|figure\",\" \",doc) for doc in data_all[\"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data_all.iloc[:len(train)]\n",
    "test = data_all.iloc[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"bases/working_train.csv\",index=False,encoding=\"utf8\")\n",
    "test.to_csv(\"bases/working_test.csv\",index=False,encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
