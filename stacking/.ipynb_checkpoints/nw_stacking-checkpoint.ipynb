{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os \n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train=\"No_window/nw_scores/nw_stack_train/\"\n",
    "path_test=\"No_window/nw_scores/nw_stack_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_train = {} \n",
    "dict_test = {}\n",
    "train_files = [i for i in os.listdir(path_train)]\n",
    "test_files = [i for i in os.listdir(path_test)]\n",
    "for f in train_files:\n",
    "    dict_train[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path_train+f)\n",
    "for f in test_files:\n",
    "    dict_test[re.sub(\"\\.csv\",\"\",f)] = pd.read_csv(path_test+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_no_ID=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7',\n",
    "       'class8', 'class9']\n",
    "del dict_train[\".DS_Store\"]\n",
    "del dict_test[\".DS_Store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Affecting  columns name\n",
    "for name in dict_test.keys():\n",
    "    dict_train[name].columns=[name+\"_\"+s for s in col_no_ID]+[\"ID\"]\n",
    "    dict_test[name].columns=[name+\"_\"+s for s in col_no_ID]+[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_train=dict_train[\"nowdw_XGB_medium\"].merge(dict_train[\"nowdw_XGB_small\"],\n",
    "on=\"ID\").merge(dict_train[\"nowdw_XGB_tall\"],on=\"ID\").merge(dict_train[\"XGB_M_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_S_d2v\"],on=\"ID\").merge(dict_train[\"XGB_T_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_S_tfidf\"],on=\"ID\").merge(dict_train[\"XGB_M_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_T_tfidf\"],on=\"ID\").merge(dict_train[\"XGB_S_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"XGB_M_w2v\"],on=\"ID\").merge(dict_train[\"XGB_T_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_S_d2v\"],on=\"ID\").merge(dict_train[\"LGBM_M_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_T_d2v\"],on=\"ID\").merge(dict_train[\"LGBM_S_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_M_tfidf\"],on=\"ID\").merge(dict_train[\"LGBM_T_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_S_w2v\"],on=\"ID\").merge(dict_train[\"LGBM_M_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"LGBM_T_w2v\"],on=\"ID\").merge(dict_train[\"adaboost_d2v\"],\n",
    "on=\"ID\").merge(dict_train[\"adaboost_tfidf\"],on=\"ID\").merge(dict_train[\"adaboost_w2v\"],\n",
    "on=\"ID\").merge(dict_train[\"logit_d2v\"],on=\"ID\").merge(dict_train[\"logit_tfidf\"],\n",
    "on=\"ID\").merge(dict_train[\"logit_w2v\"],on=\"ID\")#.merge(dict_train[\"nowdw_neural_net\"],on=\"ID\")\n",
    "#a tester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_test=dict_test[\"nowdw_XGB_medium\"].merge(dict_test[\"nowdw_XGB_small\"],\n",
    "on=\"ID\").merge(dict_test[\"nowdw_XGB_tall\"],on=\"ID\").merge(dict_test[\"XGB_M_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_S_d2v\"],on=\"ID\").merge(dict_test[\"XGB_T_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_S_tfidf\"],on=\"ID\").merge(dict_test[\"XGB_M_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_T_tfidf\"],on=\"ID\").merge(dict_test[\"XGB_S_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"XGB_M_w2v\"],on=\"ID\").merge(dict_test[\"XGB_T_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_S_d2v\"],on=\"ID\").merge(dict_test[\"LGBM_M_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_T_d2v\"],on=\"ID\").merge(dict_test[\"LGBM_S_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_M_tfidf\"],on=\"ID\").merge(dict_test[\"LGBM_T_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_S_w2v\"],on=\"ID\").merge(dict_test[\"LGBM_M_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"LGBM_T_w2v\"],on=\"ID\").merge(dict_test[\"adaboost_d2v\"],\n",
    "on=\"ID\").merge(dict_test[\"adaboost_tfidf\"],on=\"ID\").merge(dict_test[\"adaboost_w2v\"],\n",
    "on=\"ID\").merge(dict_test[\"logit_d2v\"],on=\"ID\").merge(dict_test[\"logit_tfidf\"],\n",
    "on=\"ID\").merge(dict_test[\"logit_w2v\"],on=\"ID\")#.merge(dict_test[\"nowdw_neural_net\"],on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quand le merging est fini : table unique, on peut monter un meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"..//bases/training_variants\").Class.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_test=stack_test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_feat_train=pd.read_csv(\"..//No_window/nw_meta_features/meta_train_l1l2.csv\")\n",
    "meta_feat_test=pd.read_csv(\"..//No_window/nw_meta_features/meta_train_l1l2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_train_1=pd.merge(stack_train,meta_feat_train,on=\"ID\")\n",
    "stack_test_1=pd.merge(stack_test,meta_feat_test,on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.array(stack_train_1.drop(\"ID\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=np.array(stack_test_1.drop(\"ID\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ridge vs Lasso searching\n",
    "param_test= {\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    \"penalty\": [\"l1\",\"l2\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch=GridSearchCV(estimator=LogisticRegression(), param_grid = param_test,scoring=\"neg_log_loss\",n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(X_train,y)\n",
    "gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model with parameters found on gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacker_gen(X,X_test,y,classifier):\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, random_state=26, shuffle=True)\n",
    "    fold = 0\n",
    "    y_test=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "        X_train, X_valid    = X[train_index],   X[test_index]\n",
    "        y_train, y_valid    = y[train_index],   y[test_index]\n",
    "\n",
    "        print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "\n",
    "        clf=classifier\n",
    "        clf.fit(X_train,y_train)\n",
    "        p_test = clf.predict_proba(X_test)\n",
    "        y_test += p_test/5\n",
    "    classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "    subm = pd.DataFrame(y_test, columns=classes)\n",
    "    subm['ID'] = ID_test\n",
    "    \n",
    "    subm.to_csv(\"..//final_scores/nw_stack_test.csv\",index=False)\n",
    "    \n",
    "    print(\"cross_val sur train \") #peut etre que to array est exclusivement pour les xgb\n",
    "    \n",
    "\n",
    "    y_pred=cross_val_predict(estimator=clf,X=X,y=y,cv=kf,method=\"predict_proba\")\n",
    "    subm1 = pd.DataFrame(y_pred, columns=classes)\n",
    "    subm1['ID'] = ID_train\n",
    "    subm1.to_csv(\"..//final_scores/nw_stack_train.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paramètre C et penalty à rentrer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "stacker_gen(X_train,X_test,y,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
