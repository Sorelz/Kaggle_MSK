{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "pd.options.display.max_colwidth = 50\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('..//bases/training_variants')\n",
    "test = pd.read_csv('..//bases/test_variants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts = pd.read_csv('..//bases/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"], encoding = \"utf-8\")\n",
    "test_texts = pd.read_csv('..//bases/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"], encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_texts, how='left', on='ID')\n",
    "test = pd.merge(test, test_texts, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transform Gene Letter to their abbreviation in order to find them in the text\n",
    "One_to_Three_AA = {'C': 'Cys', 'D': 'Asp', 'S': 'Ser', 'Q': 'Gln', 'K': 'Lys',\n",
    "         'I': 'Ile', 'P': 'Pro', 'T': 'Thr', 'F': 'Phe', 'N': 'Asn', \n",
    "         'G': 'Gly', 'H': 'His', 'L': 'Leu', 'R': 'Arg', 'W': 'Trp', \n",
    "         'A': 'Ala', 'V': 'Val', 'E': 'Glu', 'Y': 'Tyr', 'M': 'Met'}\n",
    "pattern = re.compile('|'.join(One_to_Three_AA.keys()))\n",
    "##### Get variation types by using regex\n",
    "def variation_regex(data, pattern): # if you want to not ignore cases, add extra argument to function\n",
    "    Boolean = [not bool(re.search(pattern, i, re.IGNORECASE)) for i in data.Variation]\n",
    "    data_no_regex = data[Boolean]  # 182 Fusions => 495 over \n",
    "    not_Boolean = [not i for i in Boolean]  \n",
    "    data_regex = data[not_Boolean]\n",
    "    \n",
    "    return (data_regex, data_no_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### process the train and test set together\n",
    "data_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "data_all_backup = data_all[:] ##### We keep backup because we want dummy variables of Gene & Text \n",
    "# TODO maybe also use Variation function of Gene from a database, and other suggestions. Also can use Count_sub as feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sub(data):\n",
    "\n",
    "    ##### The normal case is around 2080 out of the 2644\n",
    "    \n",
    "    \n",
    "    Boolean = [data.Variation[i] in data.Text[i] or #normal case\n",
    "               data.Variation[i][:-1] in data.Text[i] or #case 1.\n",
    "               pattern.sub(lambda x: One_to_Three_AA[x.group()], data.Variation[i][:-1]) # case2\n",
    "               in data.Text[i]  for i in data.index] ## because new indexing we use \n",
    "    \n",
    "    #TODO could also match insensitive as a next step for more info.\n",
    "    #Shorter Boolean below = the normal version\n",
    "    \n",
    "    #Boolean = [trainSub.Variation[i] in trainSub.Text[i] #normal case\n",
    "    #           for i in trainSub.ID] ## because new indexing we use ID\n",
    "    #           \n",
    "            \n",
    "    sub_in_text = data[Boolean]\n",
    "    not_Boolean = [not i for i in Boolean]  \n",
    "\n",
    "    sub_not_in_text = data[not_Boolean]\n",
    "#    sub_in_text['Count'] = [sub_in_text.Text[i].count(sub_in_text.Variation[i][:-1])\n",
    "#                    +sub_in_text.Text[i].count(pattern.sub(lambda x: One_to_Three_AA[x.group()], sub_in_text.Variation[i][:-1]))\n",
    "#                    for i in sub_in_text.index]\n",
    "    \n",
    "    return sub_in_text, sub_not_in_text\n",
    "##### For subs that are not find in text: use regex to account for a different number\n",
    "##### TODO: things you can further try - with AA name replacement, searching for the number only etc.\n",
    "def find_sub_noText(data):\n",
    "    Booleans = []\n",
    "    for i in data.index:\n",
    "        split_variation = re.split('(\\d+)', data.Variation[i]) # split based on a number\n",
    "        first_Amino = re.escape(split_variation[0]) #re.escpae uses variable as regex\n",
    "        last_Amino = re.escape(split_variation[-1])\n",
    "        #first_number = re.escape(split_variation[1][0])\n",
    "        #new_regex = r\"[^a-zA-Z0-9]\" + first_Amino + first_number\n",
    "        new_regex  = first_Amino + r\"\\d+\" + last_Amino\n",
    "        Boolean = bool(re.search(new_regex, data.Text[i]))\n",
    "        Booleans.append(Boolean)\n",
    "    \n",
    "    sub_number_in_text = data[Booleans]\n",
    "    not_Boolean = [not i for i in Booleans]  \n",
    "\n",
    "    sub_again_no_text = data[not_Boolean]\n",
    "    return sub_again_no_text, sub_number_in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Next we use a window to extract sentences\n",
    "def get_sentences_sub(data, splitted_sentences, window_left, window_right):\n",
    "    #position_sentences = [[] for _ in range(len(data))]  #### currently not used\n",
    "    data.index = range(len(data))\n",
    "    sentences_with_sub = [[] for _ in range(len(data))]\n",
    "    background=[[] for _ in range(len(data))]\n",
    "    for i in range(len(splitted_sentences)):\n",
    "        sentences = splitted_sentences[i]\n",
    "        one_to_three_variation = pattern.sub(lambda x: One_to_Three_AA[x.group()], data.Variation[i][:-1])\n",
    "        Variation = data.Variation[i][:-1]        \n",
    "        for j in range(len(sentences)):                              \n",
    "            if (Variation in sentences[j]) or (one_to_three_variation in sentences[j]):\n",
    "                new_regex = re.escape(Variation) + r\"[\\S]*\" ### Means no white space 0 or more\n",
    "                sentences[j] = re.sub(new_regex, ' placeholderMutation', sentences[j]) #case 1\n",
    "                new_regex = re.escape(one_to_three_variation) + r\"[\\S]*\"\n",
    "                sentences[j] = re.sub(new_regex, ' placeholderMutation', sentences[j]) #case 2\n",
    "                sentences_with_sub[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "                \n",
    "                ### We add space to ' placeholderMutation' because sometimes there are letters in front of it\n",
    "                # position_sentences[i].append(j) # not used for the moment\n",
    "            else:\n",
    "                background[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "                \n",
    "    return sentences_with_sub,background   ### This might take a while because it's looping through all sentences\n",
    "def get_sentences_sub_noText(data, splitted_sentences, window_left, window_right):\n",
    "    #position_sentences = [[] for _ in range(len(data))]  #### currently not used\n",
    "    data.index = range(len(data))\n",
    "    sentences_with_sub = [[] for _ in range(len(data))]\n",
    "    background=[[] for _ in range(len(data))]\n",
    "    for i in range(len(splitted_sentences)):\n",
    "        sentences = splitted_sentences[i] \n",
    "        for j in range(len(sentences)):\n",
    "            split_variation = re.split('(\\d+)', data.Variation[i]) # split based on a number\n",
    "            first_Amino = re.escape(split_variation[0]) #re.escpae uses variable as regex\n",
    "            last_Amino = re.escape(split_variation[-1])\n",
    "            new_regex  = first_Amino + r\"\\d+\" + last_Amino\n",
    "            \n",
    "            #counter=len(re.findall(new_regex, sentences[j]))\n",
    "            \n",
    "            Boolean = bool(re.search(new_regex, sentences[j]))\n",
    "            if Boolean:\n",
    "                sentences[j] = re.sub(new_regex, ' placeholderMutation', sentences[j]) # Might help catch sy\n",
    "                sentences_with_sub[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right,len(sentences)-1)])\n",
    "                # position_sentences[i].append(j) # not used for the moment\n",
    "            else:\n",
    "                background[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "    return sentences_with_sub,background   ### This might take a while because it's looping through all sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Converts list of sentences into one string of sentences for each document => to use for tfidf etc.\n",
    "def sentences_to_string(sentences_list):\n",
    "    sentence_strings = []\n",
    "    for sentences in sentences_list:\n",
    "        sentence_string =  ' '.join(str(sentence) for sentence in sentences)\n",
    "        sentence_strings.append(sentence_string)\n",
    "    \n",
    "    return sentence_strings ### This doesn't take such a long time to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitutions (subs) processing of data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### First find those that have the format of being a substitution in data\n",
    "data_all['Substitutions_var'] = data_all.Variation.apply(lambda x: bool(re.search('^[A-Z]\\\\d+[A-Z*]$', x))*1) #multiplying by 1 converts True to 1, False to 0 => Maybe modify this later?\n",
    "data_all['Stop_codon_var'] = data_all.Variation.apply(lambda x: bool(re.search('[*]', x))*1) #multiplying by 1 converts True to 1, False to 0\n",
    "data_sub = data_all[data_all['Substitutions_var']==1] ### Now we know the index of where a substitution occurs - the data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_in_text, sub_not_in_text = find_sub(data_sub)\n",
    "sub_in_text_backup = sub_in_text[:] ## index gets changed by text_processing if we don't make a copy\n",
    "##### INVESTIGATION: Why do some subs don't appear in Text?: Try to automize this and find out\n",
    "### Substitutions can appear as SAME_PREFIX - Other number - SAME_SUFFIX\n",
    "\n",
    "sub_again_no_Text, sub_noText = find_sub_noText(sub_not_in_text) # 108 such cases out of 411 = nice improvement\n",
    "sub_noText_backup = sub_noText[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on variations who have the 2 letters right but not same numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working on subs that are not in text + deletion,fusion etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_sub=data_all[data_all['Substitutions_var']==0]\n",
    "sub_again_no_Text=sub_again_no_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_find(data):\n",
    "    l=[\"mutat\",\"variat\",\"fusion\",\"deleti\",\"amplific\",\"framesh\",\n",
    "    \"truncat\",\"fs\",\"exon\",\"dupl\"]\n",
    "    Boolean={}\n",
    "    for word in l:\n",
    "        Boolean[word] = [re.search(word,data.Text[i]) for i in data.index] ## because new indexing we use \n",
    "    Bool=[any(tup) for tup in zip(Boolean[\"mutat\"],Boolean[\"variat\"],Boolean[\"fusion\"],\n",
    "        Boolean[\"deleti\"],Boolean[\"amplific\"],Boolean[\"truncat\"],\n",
    "        Boolean[\"fs\"],Boolean[\"framesh\"],Boolean[\"exon\"],Boolean[\"dupl\"])]\n",
    "    no_sub_in_text=data[Bool]\n",
    "    no_Bool=[not i for i in Bool]\n",
    "    no_sub_not_in_text=data[no_Bool]\n",
    "    return no_sub_in_text,no_sub_not_in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_sub_yes,no_sub_no=custom_find(no_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_find_bis(data):\n",
    "    l=[\"mutat\",\"variat\"]\n",
    "    Boolean={}\n",
    "    for word in l:\n",
    "        Boolean[word] = [re.search(word,data.Text[i]) for i in data.index] ## because new indexing we use \n",
    "    Bool=[any(tup) for tup in zip(Boolean[\"mutat\"],Boolean[\"variat\"])]\n",
    "    no_sub_in_text=data[Bool]\n",
    "    no_Bool=[not i for i in Bool]\n",
    "    no_sub_not_in_text=data[no_Bool]\n",
    "    return no_sub_in_text,no_sub_not_in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_again_yes,sub_again_no=custom_find_bis(sub_again_no_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences_nosub(data, splitted_sentences, window_left, window_right):\n",
    "    #position_sentences = [[] for _ in range(len(data))]  #### currently not used\n",
    "    data.index = range(len(data))\n",
    "    sentences_with_sub = [[] for _ in range(len(data))]\n",
    "    background=[[] for _ in range(len(data))]\n",
    "    \n",
    "    for i in range(len(splitted_sentences)):\n",
    "        sentences = splitted_sentences[i]\n",
    "        l=[\"mutat\",\"variat\",\"fusion\",\"deleti\",\"amplific\",\"framesh\",\n",
    "    \"truncat\",\"fs\",\"exon\",\"dupl\"]     \n",
    "        for j in range(len(sentences)):    \n",
    "            for keyword in l:\n",
    "                if keyword in sentences[j]:\n",
    "                    sentences_with_sub[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "                else:\n",
    "                    background[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "    return sentences_with_sub,background   ### This might take a while because it's looping through all sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLTK_nosub = [sent_tokenize(no_sub_yes.Text[i]) for i in no_sub_yes.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nosub_sentences,nosub_background = get_sentences_nosub(no_sub_yes, NLTK_nosub, window_left = 0, window_right = 0) # Retrieves sentences where keyword is included\n",
    "nosub_sentences = [sorted(set(sentences), key = sentences.index) for sentences in nosub_sentences] # only use unique \n",
    "nosub_background = [sorted(set(sentences), key = sentences.index) for sentences in nosub_background] # only use unique \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences_sub_again_notext(data, splitted_sentences, window_left, window_right):\n",
    "    #position_sentences = [[] for _ in range(len(data))]  #### currently not used\n",
    "    data.index = range(len(data))\n",
    "    sentences_with_sub = [[] for _ in range(len(data))]\n",
    "    background=[[] for _ in range(len(data))]\n",
    "    \n",
    "    for i in range(len(splitted_sentences)):\n",
    "        sentences = splitted_sentences[i]\n",
    "        l=[\"mutat\",\"variat\"]    \n",
    "        for j in range(len(sentences)):    \n",
    "            for keyword in l:\n",
    "                if keyword in sentences[j]:\n",
    "                    sentences_with_sub[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "                else:    \n",
    "                    background[i].extend(sentences[max(j-window_left,0) : min(j+1+window_right, len(sentences)-1)])\n",
    "    return sentences_with_sub,background   ### This might take a while because it's looping through all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLTK_sub_again_notext = [sent_tokenize(sub_again_yes.Text[i]) for i in sub_again_yes.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_again_sentences,sub_again_background = get_sentences_sub_again_notext(sub_again_yes, NLTK_sub_again_notext, window_left = 0, window_right = 0) # Retrieves sentences where keyword is included\n",
    "sub_again_sentences = [sorted(set(sentences), key = sentences.index) for sentences in sub_again_sentences] # only use unique \n",
    "sub_again_background = [sorted(set(sentences), key = sentences.index) for sentences in sub_again_background] # only use unique \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLTK_sub_noText = [sent_tokenize(sub_noText.Text[i]) for i in sub_noText.index]\n",
    "sub_noText_sentences,sub_noText_background = get_sentences_sub_noText(sub_noText, NLTK_sub_noText, window_left = 0, window_right = 0) # Retrieves sentences where subsitution mutation is included\n",
    "sub_noText_sentences = [sorted(set(sentences), key = sentences.index) for sentences in sub_noText_sentences] # only use unique sentences\n",
    "sub_noText_background = [sorted(set(sentences), key = sentences.index) for sentences in sub_noText_background] # only use unique \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLTK_sub = [sent_tokenize(sub_in_text.Text[i]) for i in sub_in_text.index] # takes a long time to run tokenizer => use pickle to save\n",
    "sub_sentences,sub_background = get_sentences_sub(sub_in_text, NLTK_sub, window_left = 0, window_right = 0) \n",
    "# Retrieves sentences where subsitution mutation is included.\n",
    "# window_left and window_right specify which sentences to keep at the left side or right side of the sub sentences.\n",
    "# IMPORTANT: I used also placeholderMutation to replace the original sub mutations here\n",
    "sub_sentences = [sorted(set(sentences), key = sentences.index) for sentences in sub_sentences]\n",
    "sub_background = [sorted(set(sentences), key = sentences.index) for sentences in sub_background]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_sentences_string = sentences_to_string(sub_sentences)\n",
    "sub_noText_string = sentences_to_string(sub_noText_sentences)\n",
    "nosub_sentences_string=sentences_to_string(nosub_sentences)\n",
    "sub_again_string=sentences_to_string(sub_again_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the background text (Text is now the frontline text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_all.loc[sub_in_text.index,\"Background\"]=sentences_to_string(sub_background)\n",
    "#data_all.loc[sub_noText.index,\"Background\"]=sentences_to_string(sub_noText_background)\n",
    "#data_all.loc[no_sub_yes.index,\"Background\"]=sentences_to_string(nosub_background)\n",
    "#data_all.loc[sub_again_yes.index,\"Background\"]=sentences_to_string(sub_again_background)\n",
    "#data_all.loc[sub_again_no.index,\"Background\"]=\"nbckgr\"\n",
    "#data_all.loc[no_sub_no.index,\"Background\"]=\"nbckgr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_all.Background[data_all.Background==\"\"]=\"nbckgr\"\n",
    "#data_all.Background[data_all.Background.isnull()]=\"nbckgr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Franck\\Documents\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_all.Text[sub_in_text.index] = sub_sentences_string\n",
    "data_all.Text[sub_noText.index] = sub_noText_string\n",
    "data_all.Text[no_sub_yes.index] = nosub_sentences_string\n",
    "data_all.Text[sub_again_yes.index] = sub_again_string\n",
    "data_all.Text[sub_again_no.index]=\"null\"\n",
    "data_all.Text[no_sub_no.index]=\"null\"\n",
    "data_all.Text[data_all.Text==\"\"]=\"null\"\n",
    "data_all.Text[data_all.Text.isnull()]=\"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "############## Non-subs preprocessing of data set #######################\n",
    "\n",
    "#def find_mutation_type(row, pattern):  ##### TODO: make clearer by using a function instead of lambda\n",
    "#    return bool(re.search('^fusion', row, re.IGNORECASE)) *1. Also for subs\n",
    "\n",
    "####### Fusions : 'Fusions' ############\n",
    "data_all['Fusion_var'] = data_all.Variation.apply(lambda x: bool(re.search('^fusion', x, re.IGNORECASE))*1) #multiplying by 1 converts True to 1, False to 0\n",
    "new_fusion, new_data_all = variation_regex(data_all, '^fusion') \n",
    "\n",
    "###### Fusions: 'Gene-Gene fusion' ########\n",
    "data_all['gene_fusion_var'] = data_all.Variation.apply(lambda x: bool(re.search('fusion', x, re.IGNORECASE))*1) \n",
    "_ , new_data_all = variation_regex(new_data_all, 'fusion') \n",
    "###### Notice that NaN introduced for places where splicing occured => replace after NaN with 0's when complete\n",
    "\n",
    "####### Deletions: 'Deletions' ############\n",
    "data_all['Deletion_var'] = data_all.Variation.apply(lambda x: bool(re.search('^del', x, re.IGNORECASE))*1) \n",
    "new_del, new_data_all = variation_regex(new_data_all, '^del') \n",
    "\n",
    "####### Deletions & Insertions wheteher together or seperately (doesn't make a big difference IMO)\n",
    "data_all['del_or_ins_var'] = data_all.Variation.apply(lambda x: bool(re.search('del|ins', x, re.IGNORECASE))*1) \n",
    "# we could also later divide it into del, ins if we want to\n",
    "\n",
    "###### Amplifications #########\n",
    "data_all['Amplification_var'] = data_all.Variation.apply(lambda x: bool(re.search('ampl', x, re.IGNORECASE))*1) \n",
    "\n",
    "###### Truncations ########### Don't forget there are 'Truncating mutations' = 95 and '_trunc' = 4\n",
    "data_all['Truncation_var'] = data_all.Variation.apply(lambda x: bool(re.search('trunc', x, re.IGNORECASE))*1) \n",
    "\n",
    "####### Exons #########\n",
    "data_all['exon_var'] = data_all.Variation.apply(lambda x: bool(re.search('exon', x, re.IGNORECASE))*1) \n",
    "\n",
    "####### Frameshift mutations ########\n",
    "data_all['frameshift_var'] = data_all.Variation.apply(lambda x: bool(re.search('fs', x, re.IGNORECASE))*1) \n",
    "\n",
    "####### Duplications ##############\n",
    "data_all['dup_var'] = data_all.Variation.apply(lambda x: bool(re.search('dup', x, re.IGNORECASE))*1) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO : #Sentence Tokenizer for non-subs that are not in text, AND\n",
    "#subs that are not in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not used\n",
    "################ The dummy variables for Gene and Text ##################\n",
    "## TODO: also use dummy for Text? There are 135 shared Genes and 142 shared Text between train and Leaks!  len(set(train.Text) & set(Leaks.Text))\n",
    "#data_all_dummy = data_all_backup[['Gene', 'Text']] # drop those columns we don't need as dummy.\n",
    "#X_dummy = pd.get_dummies(data_all_dummy) # converts categorical variables into dummy variable. From len set => 269 genes + 2090 texts\n",
    "#X_dummy_train = X_dummy[:train.shape[0]]\n",
    "#X_dummy_test = X_dummy[train.shape[0]:]\n",
    "#dummy_names = X_dummy.columns.values #### To remember names if you want to check again what Gene or Text used\n",
    "#X_dummy = X_dummy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Use the variation types \n",
    "#variation_types = data_all.drop(['ID', 'Gene', 'Class', 'Text', 'Variation'], axis =1)\n",
    "#X_variation_train = variation_types[:train.shape[0]]\n",
    "#X_variation_test = variation_types[train.shape[0]:]\n",
    "#variation_names = variation_types.columns.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set('!\"#$%&\\'()*+:;<=>?@[\\\\]^_`{|}~0123456789') \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc,lemmatiz=False):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free_0 = [re.sub(\",|\\.|/\",\" \",ch) for ch in stop_free]\n",
    "    if lemmatiz:\n",
    "        punc_free_lem=\"\".join(ch for ch in punc_free_0 if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free_lem.split())\n",
    "        return normalized\n",
    "    else:\n",
    "        punc_free = \"\".join(ch for ch in punc_free_0 if ch not in exclude)\n",
    "        return punc_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-a39e28a5a635>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#No lemmatization for the moment, be careful not to lemmatize then w2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBackground\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBackground\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-93-a39e28a5a635>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#No lemmatization for the moment, be careful not to lemmatize then w2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBackground\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBackground\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-92-d1b3897480d8>\u001b[0m in \u001b[0;36mclean\u001b[1;34m(doc, lemmatiz)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlemma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlemmatiz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mstop_free\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpunc_free_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",|\\.|/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_free\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlemmatiz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#No lemmatization for the moment, be careful not to lemmatize then w2vec\n",
    "data_all.Text = [clean(doc) for doc in data_all.Text]  \n",
    "#data_all.Background = [clean(doc) for doc in data_all.Background]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We gonna extract the main info of the background using tfidf+tsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_train=train.ID\n",
    "ID_test=test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data_all.iloc[:len(train)]\n",
    "test = data_all.iloc[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tfidf = TfidfVectorizer(\n",
    " #       min_df=3, max_features=5000, strip_accents=None, lowercase = False,\n",
    "  #      analyzer='word', token_pattern=r'\\w+', ngram_range=(1,3), use_idf=True,\n",
    "   #     smooth_idf=True, sublinear_tf=True\n",
    "    #    ).fit(train[\"Background\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_background = tfidf.transform(train[\"Background\"])\n",
    "#X_test_background = tfidf.transform(test[\"Background\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tsvd=TruncatedSVD(n_components=100,n_iter=10,random_state=26)\n",
    "#tsvd_train=tsvd.fit_transform(X_train_background)\n",
    "#tsvd_test=tsvd.transform(X_test_background)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(100):\n",
    "#   train['tsvd_'+str(i)] = tsvd_train[:, i]\n",
    "#   test['tsvd_'+str(i)] = tsvd_test[:, i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all=pd.concat((train, test), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some more features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Some counters on the gene and variation, here not using the 3letters abreviations\n",
    "#that means if the text contains only the gene or variation but with the \n",
    "#3letters format, the variable will capture it\n",
    "data_all[\"Gene_Share\"] = data_all.apply(lambda r: sum([1 for w in r[\"Gene\"].split(\" \") if w in r[\"Text\"].split(\" \")]), axis=1)\n",
    "data_all[\"Variation_Share\"] = data_all.apply(lambda r: sum([1 for w in r[\"Variation\"].split(\" \") if w in r[\"Text\"].split(\" \")]), axis=1)\n",
    "\n",
    "data_all[\"Text_words\"] = data_all[\"Text\"].map(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure_counter=[\"fig\",\"figure\"]\n",
    "for fig in figure_counter: \n",
    "        data_all[\"Figure_counter\"]=(data_all[\"Text\"].map(lambda x : str(x).count(fig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all[\"Text\"]=[re.sub(\"fig|figure\",\" \",doc) for doc in data_all[\"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1 = data_all.iloc[:len(train)]\n",
    "test_1 = data_all.iloc[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2=pd.get_dummies(train_1,columns=[\"Gene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_2=pd.get_dummies(test_1,columns=[\"Gene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add and remove gene dummies on test set to match train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_missing_dummy_columns( d, columns ):\n",
    "    missing_cols = set( columns ) - set( d.columns )\n",
    "    for c in missing_cols:\n",
    "        d[c] = 0\n",
    "def fix_test_columns( d, columns ):  \n",
    "\n",
    "    add_missing_dummy_columns( d, columns )\n",
    "\n",
    "    # make sure we have all the columns we need\n",
    "    assert( set( columns ) - set( d.columns ) == set())\n",
    "\n",
    "    extra_cols = set( d.columns ) - set( columns )\n",
    "    if extra_cols:\n",
    "        print (\"extra columns:\", extra_cols)\n",
    "\n",
    "    d = d[ columns ]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra columns: {'Gene_NPHS2', 'Gene_TRPM7', 'Gene_NIPBL', 'Gene_PLA2G4A', 'Gene_ATP7B', 'Gene_MMACHC', 'Gene_ORAI1', 'Gene_SLC12A1', 'Gene_UNC13D', 'Gene_SPAST', 'Gene_CD40LG', 'Gene_REEP1', 'Gene_DYM', 'Gene_ATP2C1', 'Gene_FOXI1', 'Gene_BMPR1B', 'Gene_STAT1', 'Gene_PPARG', 'Gene_EVC', 'Gene_CCBE1', 'Gene_FTCD', 'Gene_PROKR2', 'Gene_PNKP', 'Gene_MPDU1', 'Gene_CLN3', 'Gene_ACADM', 'Gene_NDUFS6', 'Gene_CYLD', 'Gene_GLA', 'Gene_BMPR2', 'Gene_TYR', 'Gene_SCN4A', 'Gene_EDARADD', 'Gene_HYAL1', 'Gene_SPINK5', 'Gene_SLC7A9', 'Gene_LPL', 'Gene_USH2A', 'Gene_MMADHC', 'Gene_KCNJ10', 'Gene_KCNQ3', 'Gene_PEX10', 'Gene_SLC2A9', 'Gene_ZFPM2', 'Gene_ALG12', 'Gene_HSPB8', 'Gene_SPTBN2', 'Gene_UBR1', 'Gene_GM2A', 'Gene_PKHD1', 'Gene_HGD', 'Gene_PPP1R3A', 'Gene_RPGRIP1L', 'Gene_TPCN2', 'Gene_IVD', 'Gene_SBDS', 'Gene_WRN', 'Gene_APOA5', 'Gene_SLC5A5', 'Gene_NKX2-6', 'Gene_CDH23', 'Gene_COQ8A', 'Gene_PLA2G6', 'Gene_SETBP1', 'Gene_SLC4A11', 'Gene_USH1C', 'Gene_KRT2', 'Gene_PRKN', 'Gene_OCRL', 'Gene_CASK', 'Gene_ETFA', 'Gene_PEX13', 'Gene_ALDH6A1', 'Gene_FUCA1', 'Gene_L2HGDH', 'Gene_RSPO4', 'Gene_KLHL7', 'Gene_PMM2', 'Gene_GCH1', 'Gene_LBR', 'Gene_CHIT1', 'Gene_HSD3B7', 'Gene_PAK3', 'Gene_SLC26A2', 'Gene_F7', 'Gene_SERPINI1', 'Gene_MXI1', 'Gene_LCT', 'Gene_TIRAP', 'Gene_IGFALS', 'Gene_P2RY12', 'Gene_CACNA1A', 'Gene_SLC33A1', 'Gene_DHH', 'Gene_GALK1', 'Gene_PALLD', 'Gene_SLC40A1', 'Gene_OPA3', 'Gene_AMT', 'Gene_KERA', 'Gene_UGT1A1', 'Gene_GCKR', 'Gene_RPS19', 'Gene_ERF', 'Gene_PIKFYVE', 'Gene_TGIF1', 'Gene_ACAD8', 'Gene_ST14', 'Gene_COL4A5', 'Gene_F11', 'Gene_ANTXR2', 'Gene_ASAH1', 'Gene_XPA', 'Gene_PRSS1', 'Gene_SART3', 'Gene_F9', 'Gene_AKAP10', 'Gene_SLC6A5', 'Gene_ARL6', 'Gene_TGFB1', 'Gene_POLG2', 'Gene_CFI', 'Gene_NHP2', 'Gene_ALDH5A1', 'Gene_MASTL', 'Gene_ALX3', 'Gene_PPARGC1B', 'Gene_FUT1', 'Gene_G6PC3', 'Gene_BCKDHA', 'Gene_ACVR2B', 'Gene_OXCT1', 'Gene_NUP62', 'Gene_FBP1', 'Gene_NDUFS8', 'Gene_PTCH2', 'Gene_PHEX', 'Gene_ASS1', 'Gene_DPYD', 'Gene_SYNE1', 'Gene_HSD17B10', 'Gene_BPGM', 'Gene_ABCG8', 'Gene_BSND', 'Gene_NEUROG3', 'Gene_KCNMB1', 'Gene_ITM2B', 'Gene_SMN2', 'Gene_SLC46A1', 'Gene_OPN1SW', 'Gene_MPLKIP', 'Gene_TCF4', 'Gene_AP3B1', 'Gene_ALG10', 'Gene_OPRM1', 'Gene_EPHB2', 'Gene_SUMF1', 'Gene_POMT2', 'Gene_PGK1', 'Gene_TWIST1', 'Gene_CPOX', 'Gene_EFHC1', 'Gene_ZIC3', 'Gene_RPGR', 'Gene_MC2R', 'Gene_NDUFA1', 'Gene_MCOLN1', 'Gene_FOXP2', 'Gene_GNE', 'Gene_DNAH5', 'Gene_CASP10', 'Gene_USB1', 'Gene_PDGFRL', 'Gene_TRPC6', 'Gene_ABCC11', 'Gene_LFNG', 'Gene_NPC2', 'Gene_NR2E3', 'Gene_CSNK1D', 'Gene_KLF11', 'Gene_ZFYVE27', 'Gene_RPL5', 'Gene_BUB1', 'Gene_PEX26', 'Gene_KIRREL3', 'Gene_CEP290', 'Gene_RAB3GAP2', 'Gene_HEXB', 'Gene_NAGLU', 'Gene_SGCG', 'Gene_MVK', 'Gene_STS', 'Gene_BHLHE41', 'Gene_TOR1A', 'Gene_ALG6', 'Gene_APOL1', 'Gene_LRP6', 'Gene_CLCN2', 'Gene_INF2', 'Gene_MAD1L1', 'Gene_BBS12', 'Gene_NHEJ1', 'Gene_FOXRED1', 'Gene_SPTLC2', 'Gene_LGI1', 'Gene_WT1', 'Gene_NLRP3', 'Gene_SCN4B', 'Gene_LHX4', 'Gene_LITAF', 'Gene_ALDOB', 'Gene_AIPL1', 'Gene_WISP3', 'Gene_HMCN1', 'Gene_A4GALT', 'Gene_TRPV4', 'Gene_CRX', 'Gene_ECM1', 'Gene_PHF8', 'Gene_AKR1D1', 'Gene_KCNE2', 'Gene_KRT74', 'Gene_ABCA4', 'Gene_STAR', 'Gene_RNASEH2B', 'Gene_APOC2', 'Gene_PITX3', 'Gene_HOGA1', 'Gene_PEX7', 'Gene_BBS1', 'Gene_TMIE', 'Gene_SLC25A20', 'Gene_MYO1A', 'Gene_CFL2', 'Gene_GRM6', 'Gene_GPD1L', 'Gene_IRF6', 'Gene_IDH3B', 'Gene_SDHD', 'Gene_FXYD2', 'Gene_ARL13B', 'Gene_RPS26', 'Gene_TRPS1', 'Gene_RAX', 'Gene_TIMM8A', 'Gene_PKD1', 'Gene_KLF1', 'Gene_NR3C2', 'Gene_GDF6', 'Gene_FZD4', 'Gene_IFT122', 'Gene_RNASEH2C', 'Gene_KCNV2', 'Gene_ARX', 'Gene_CC2D2A', 'Gene_ESRRB', 'Gene_JAK3', 'Gene_NCF2', 'Gene_BEST1', 'Gene_ESCO2', 'Gene_TFAP2B', 'Gene_ACSL4', 'Gene_DCTN1', 'Gene_SRD5A2', 'Gene_NPHP3', 'Gene_OTC', 'Gene_CYP27A1', 'Gene_FGF9', 'Gene_G6PC', 'Gene_POU4F3', 'Gene_SH2D1A', 'Gene_SLC52A3', 'Gene_SYNE2', 'Gene_PCCB', 'Gene_GPHN', 'Gene_CLCN5', 'Gene_KRT85', 'Gene_CBX2', 'Gene_HCN4', 'Gene_TLR4', 'Gene_DDB2', 'Gene_SEMA3E', 'Gene_MASP2', 'Gene_CEP152', 'Gene_LRRK2', 'Gene_FAM126A', 'Gene_SUMO4', 'Gene_RP1L1', 'Gene_ITGB2', 'Gene_OCLN', 'Gene_RAB27A', 'Gene_CX3CR1', 'Gene_ERCC6', 'Gene_IGHMBP2', 'Gene_PIGV', 'Gene_LEPR', 'Gene_RFXANK', 'Gene_UMPS', 'Gene_ARSB', 'Gene_FHL1', 'Gene_FLCN', 'Gene_SLC6A20', 'Gene_TAZ', 'Gene_GBE1', 'Gene_VIM', 'Gene_ABCC9', 'Gene_C7', 'Gene_TSEN2', 'Gene_SLC22A12', 'Gene_RNF135', 'Gene_TMPRSS3', 'Gene_SLC25A22', 'Gene_OPCML', 'Gene_TJP2', 'Gene_C2orf71', 'Gene_D2HGDH', 'Gene_SNRNP200', 'Gene_KCNQ2', 'Gene_MLH3', 'Gene_HPS3', 'Gene_TARDBP', 'Gene_BLM', 'Gene_COLQ', 'Gene_NUBPL', 'Gene_OPA1', 'Gene_MPO', 'Gene_CYP2C9', 'Gene_SCN3B', 'Gene_GUCA1A', 'Gene_CHST3', 'Gene_INVS', 'Gene_TCN2', 'Gene_HGSNAT', 'Gene_CYBB', 'Gene_GFER', 'Gene_CILP', 'Gene_IRS2', 'Gene_SHROOM4', 'Gene_RNASET2', 'Gene_LDLR', 'Gene_ARHGEF9', 'Gene_EIF2B2', 'Gene_ALG9', 'Gene_KRIT1', 'Gene_SMS', 'Gene_CTRC', 'Gene_PAFAH1B1', 'Gene_OTX2', 'Gene_OFD1', 'Gene_RAC2', 'Gene_SLC11A2', 'Gene_ADIPOQ', 'Gene_SQSTM1', 'Gene_SETX', 'Gene_SLC25A12', 'Gene_CLCN7', 'Gene_ZNF513', 'Gene_DOLK', 'Gene_ALG1', 'Gene_NIPA1', 'Gene_B3GLCT', 'Gene_CPT1A', 'Gene_HMGCL', 'Gene_MKS1', 'Gene_FBLN5', 'Gene_AGL', 'Gene_WDR36', 'Gene_CNGA3', 'Gene_CACNB2', 'Gene_LZTS1', 'Gene_TWNK', 'Gene_SNCB', 'Gene_INPP5E', 'Gene_AURKC', 'Gene_PRCD', 'Gene_SMARCAL1', 'Gene_CSTB', 'Gene_DNM1L', 'Gene_TRPM6', 'Gene_WNT10A', 'Gene_VPS13B', 'Gene_PDE6C', 'Gene_NECTIN4', 'Gene_F5', 'Gene_CLDN14', 'Gene_SLC35C1', 'Gene_IDUA', 'Gene_CYP7B1', 'Gene_LRP2', 'Gene_RXFP2', 'Gene_HTR2C', 'Gene_SLC17A8', 'Gene_CFTR', 'Gene_NDUFS7', 'Gene_VANGL1', 'Gene_PER2', 'Gene_MEF2A', 'Gene_ARHGEF10', 'Gene_EHMT1', 'Gene_TUBA1A', 'Gene_AARS', 'Gene_RPS6KA3', 'Gene_RP2', 'Gene_VWF', 'Gene_SDHAF2', 'Gene_EPM2A', 'Gene_SCN5A', 'Gene_PFKM', 'Gene_HUWE1', 'Gene_ANKK1', 'Gene_IKBKG', 'Gene_LTBP4', 'Gene_SLC11A1', 'Gene_LRAT', 'Gene_SMC1A', 'Gene_SLC34A3', 'Gene_ALG8', 'Gene_TNFRSF11A', 'Gene_CABP4', 'Gene_MINPP1', 'Gene_RIMS1', 'Gene_PTPN12', 'Gene_TLR1', 'Gene_CHST6', 'Gene_ADAMTS13', 'Gene_PLOD3', 'Gene_CD207', 'Gene_GPC3', 'Gene_OSMR', 'Gene_PAPSS2', 'Gene_HR', 'Gene_STXBP2', 'Gene_ADSL', 'Gene_ABCA1', 'Gene_LEFTY2', 'Gene_CUL4B', 'Gene_NBN', 'Gene_SGCE', 'Gene_RBM28', 'Gene_SAR1B', 'Gene_PYGL', 'Gene_CST3', 'Gene_UPB1', 'Gene_CNGB1', 'Gene_EIF2B4', 'Gene_ACADVL', 'Gene_SIX3', 'Gene_CCT5', 'Gene_TPO', 'Gene_HFE2', 'Gene_CNTNAP2', 'Gene_FA2H', 'Gene_HNMT', 'Gene_SLC26A4', 'Gene_TSPAN12', 'Gene_MED25', 'Gene_NOD2', 'Gene_ANO5', 'Gene_KCNJ1', 'Gene_ABCD1', 'Gene_MYLK2', 'Gene_YARS2', 'Gene_WNK4', 'Gene_COMP', 'Gene_CACNA1F', 'Gene_POU6F2', 'Gene_ALDH4A1', 'Gene_SLC25A3', 'Gene_RFT1', 'Gene_CACNB4', 'Gene_SH3TC2', 'Gene_SLC29A3', 'Gene_CANT1', 'Gene_TNXB', 'Gene_AXIN2', 'Gene_PAH', 'Gene_PRODH', 'Gene_TINF2', 'Gene_GUCA1B', 'Gene_ADGRV1', 'Gene_ROBO2', 'Gene_NSMF', 'Gene_PTPRJ', 'Gene_GAMT', 'Gene_HSD11B2', 'Gene_GALE', 'Gene_ELAC2', 'Gene_AGA', 'Gene_EFEMP2', 'Gene_PROM1', 'Gene_FLNA', 'Gene_PRKAG3', 'Gene_KLF6', 'Gene_GHR', 'Gene_ZNF365', 'Gene_SLC1A3', 'Gene_UROC1', 'Gene_PKLR', 'Gene_HOXA2', 'Gene_IFT80', 'Gene_POMGNT1', 'Gene_DNM2', 'Gene_ALOXE3', 'Gene_NEXN', 'Gene_ABHD5', 'Gene_WDPCP', 'Gene_DPAGT1', 'Gene_GNPTG', 'Gene_CHST14', 'Gene_LIPA', 'Gene_TBX19', 'Gene_SLC45A2', 'Gene_ADAMTS10', 'Gene_XYLT1', 'Gene_CLDN16', 'Gene_DLD', 'Gene_AVP', 'Gene_GJC2', 'Gene_AANAT', 'Gene_SHH', 'Gene_ABCA3', 'Gene_NYX', 'Gene_TPH2', 'Gene_EBP', 'Gene_GUCY2D', 'Gene_CYP1B1', 'Gene_IL23R', 'Gene_TAT', 'Gene_TMPRSS6', 'Gene_VPS13A', 'Gene_KHK', 'Gene_SHOX', 'Gene_SEMA4A', 'Gene_ATP8B1', 'Gene_TRIM37', 'Gene_ANTXR1', 'Gene_DNAI1', 'Gene_MTMR14', 'Gene_MCFD2', 'Gene_UMOD', 'Gene_POU3F4', 'Gene_OPN1LW', 'Gene_PCSK9', 'Gene_WNT7A', 'Gene_MFRP', 'Gene_TMC1', 'Gene_SLC25A38', 'Gene_MID1', 'Gene_BUB1B', 'Gene_PHF6', 'Gene_UCHL1', 'Gene_TFR2', 'Gene_KIF21A', 'Gene_TTPA', 'Gene_SIX6', 'Gene_GDAP1', 'Gene_ATL1', 'Gene_TPP1', 'Gene_RAPSN', 'Gene_SECISBP2', 'Gene_GCNT2', 'Gene_RNASEH2A', 'Gene_PSEN2', 'Gene_PON2', 'Gene_ACADS', 'Gene_CLCNKA', 'Gene_PHYH', 'Gene_SLC16A1', 'Gene_SLC25A15', 'Gene_MESP2', 'Gene_EIF2B1', 'Gene_ZMPSTE24', 'Gene_ABCC2', 'Gene_HMGCS2', 'Gene_UBE3A', 'Gene_EIF2B3', 'Gene_F8', 'Gene_OAT', 'Gene_KRT86', 'Gene_PTS', 'Gene_HADHA', 'Gene_HAL', 'Gene_COQ2', 'Gene_PSTPIP1', 'Gene_NR0B2', 'Gene_SLC10A2', 'Gene_ICK', 'Gene_KCNJ11', 'Gene_BLMH', 'Gene_FGD4', 'Gene_HTRA1', 'Gene_SIX1', 'Gene_NT5C3A', 'Gene_CUL7', 'Gene_TLR3', 'Gene_GCDH', 'Gene_FBXO7', 'Gene_BRWD3', 'Gene_SLC12A3', 'Gene_CHMP4B', 'Gene_EYA1', 'Gene_AVPR2', 'Gene_SCNN1G', 'Gene_KCNQ1', 'Gene_HLCS', 'Gene_AMELX', 'Gene_PCCA', 'Gene_PRKCH', 'Gene_NOP10', 'Gene_GLB1', 'Gene_COX10', 'Gene_BBS5', 'Gene_NDUFAF6', 'Gene_MYOT', 'Gene_HABP2', 'Gene_XK', 'Gene_LPIN2', 'Gene_FREM1', 'Gene_ARSE', 'Gene_PRPF31', 'Gene_CTSK', 'Gene_LIPH', 'Gene_PHKA2', 'Gene_GPR143', 'Gene_NPHS1', 'Gene_MECP2', 'Gene_TRIM32', 'Gene_OGG1', 'Gene_DOCK8', 'Gene_TBC1D24', 'Gene_HMBS', 'Gene_KCNQ4', 'Gene_B3GALNT1', 'Gene_HSPB3', 'Gene_MANBA', 'Gene_PYGM', 'Gene_RAX2', 'Gene_COCH', 'Gene_EIF2B5', 'Gene_MLPH', 'Gene_NR0B1', 'Gene_EMD', 'Gene_PRICKLE1', 'Gene_TREX1', 'Gene_GAN', 'Gene_SUFU', 'Gene_RAB7A', 'Gene_SCO1', 'Gene_HPRT1', 'Gene_LRTOMT', 'Gene_SLC37A4', 'Gene_PPP2R1B', 'Gene_FECH', 'Gene_LMX1B', 'Gene_MYH14', 'Gene_SPTLC1', 'Gene_GALNT12', 'Gene_LHFPL5', 'Gene_IL12RB1', 'Gene_UBIAD1', 'Gene_DNAAF1', 'Gene_CLCF1', 'Gene_ABCG5', 'Gene_CYB5R3', 'Gene_THAP1', 'Gene_HNF4A', 'Gene_PROC', 'Gene_VCP', 'Gene_RAI1', 'Gene_PSAT1', 'Gene_RTN4R', 'Gene_RNF6', 'Gene_HSD17B3', 'Gene_KCNJ5', 'Gene_GP1BA', 'Gene_TRAPPC2', 'Gene_PLEKHG5', 'Gene_MMAA', 'Gene_SLC35D1', 'Gene_HADH', 'Gene_QDPR', 'Gene_AAAS', 'Gene_NDUFV2', 'Gene_FGD1', 'Gene_CSRP3', 'Gene_NAT2', 'Gene_PHKA1', 'Gene_PRPS1', 'Gene_CLRN1', 'Gene_DLC1', 'Gene_CA2', 'Gene_LPAR6', 'Gene_FANCI', 'Gene_SLC4A4', 'Gene_C2', 'Gene_CNGB3', 'Gene_KCNJ2', 'Gene_SALL4', 'Gene_TUBB1', 'Gene_FOXF1', 'Gene_LAMP2', 'Gene_GAA', 'Gene_POF1B', 'Gene_MYO6', 'Gene_ETFDH', 'Gene_HSF4', 'Gene_HIBCH', 'Gene_OCA2', 'Gene_TGFBI', 'Gene_SOX18', 'Gene_PHGDH', 'Gene_ACVRL1', 'Gene_FGF8', 'Gene_B4GALT7', 'Gene_PNPLA2', 'Gene_SDHA', 'Gene_ACADL', 'Gene_GDNF', 'Gene_APCDD1', 'Gene_HESX1', 'Gene_DPM1', 'Gene_UROD', 'Gene_ACTN4', 'Gene_KCNJ13', 'Gene_TRPM1', 'Gene_MOGS', 'Gene_CYP21A2', 'Gene_KCNE3', 'Gene_BBS7', 'Gene_MAN2B1', 'Gene_CYP27B1', 'Gene_AQP7', 'Gene_GFI1', 'Gene_IYD', 'Gene_NKX2-5', 'Gene_SNTA1', 'Gene_GIGYF2', 'Gene_GATA1', 'Gene_DMD', 'Gene_FGF14', 'Gene_CRB1', 'Gene_DHCR7', 'Gene_PDSS1', 'Gene_PDX1', 'Gene_AMN', 'Gene_CRLF1', 'Gene_GFM1', 'Gene_KRT9', 'Gene_EXT2', 'Gene_SGCD', 'Gene_WDR35', 'Gene_FIG4', 'Gene_ATP7A', 'Gene_GSS', 'Gene_MAGT1', 'Gene_XYLT2', 'Gene_BTD', 'Gene_FANCD2', 'Gene_CYP17A1', 'Gene_RDH5', 'Gene_YARS', 'Gene_TLL1', 'Gene_USH1G', 'Gene_AMHR2', 'Gene_TBXAS1', 'Gene_HSD17B4', 'Gene_OPTN', 'Gene_FAM20C', 'Gene_F10', 'Gene_LDLRAP1', 'Gene_EGLN1', 'Gene_SLC36A2', 'Gene_STRA6', 'Gene_GJB3', 'Gene_SLC25A19', 'Gene_PIP5K1C', 'Gene_ACADSB', 'Gene_POLH', 'Gene_ARHGAP26', 'Gene_SLC19A3', 'Gene_XPNPEP3', 'Gene_XPC', 'Gene_HPD', 'Gene_BAG3', 'Gene_TUFM', 'Gene_AGTR2', 'Gene_EXT1', 'Gene_TAS2R38', 'Gene_FOXC1', 'Gene_CPN1', 'Gene_MUSK', 'Gene_PAX6', 'Gene_SAMHD1', 'Gene_KIF5A', 'Gene_GNMT', 'Gene_ADA', 'Gene_EDAR', 'Gene_GJB1', 'Gene_NODAL', 'Gene_SUOX', 'Gene_CLDN19', 'Gene_GNPTAB', 'Gene_KISS1R', 'Gene_RANBP2', 'Gene_LDB3', 'Gene_CLN5', 'Gene_CCR5', 'Gene_UROS', 'Gene_ATP6V0A4', 'Gene_UPF3B', 'Gene_SLC6A8', 'Gene_TULP1', 'Gene_HYLS1', 'Gene_PANK2', 'Gene_LARGE1', 'Gene_NOTCH3', 'Gene_DOK7', 'Gene_CBS', 'Gene_LIG4', 'Gene_AGXT', 'Gene_PYY', 'Gene_SUGCT', 'Gene_KRT12', 'Gene_LRP5', 'Gene_BBS2', 'Gene_GJA8', 'Gene_CCM2', 'Gene_SPRED1', 'Gene_NPHP4', 'Gene_MCCC1', 'Gene_BFSP2', 'Gene_RBBP8', 'Gene_NOBOX', 'Gene_DMGDH', 'Gene_DSG4', 'Gene_CTSA', 'Gene_HSD3B2', 'Gene_CTSC', 'Gene_PARK7', 'Gene_RRM2B', 'Gene_VDR', 'Gene_EFNB1', 'Gene_MYOC', 'Gene_FCGR2B', 'Gene_HCRT', 'Gene_FGF10', 'Gene_MKKS', 'Gene_NAGS', 'Gene_VANGL2', 'Gene_WWOX', 'Gene_PAX3', 'Gene_GHSR', 'Gene_HPGD', 'Gene_KLKB1', 'Gene_ERCC8', 'Gene_MLYCD', 'Gene_DYNC2H1', 'Gene_KIF1B', 'Gene_SCO2', 'Gene_CLN8', 'Gene_NPSR1', 'Gene_TUBB2B', 'Gene_SCNN1A', 'Gene_TNNT3', 'Gene_PLA2G7', 'Gene_WDR62', 'Gene_MMAB', 'Gene_ETHE1', 'Gene_SOX17', 'Gene_NLRP1', 'Gene_PITX2', 'Gene_SLC19A2', 'Gene_CLCNKB', 'Gene_SEC23A', 'Gene_NEU1', 'Gene_TP63', 'Gene_AIRE', 'Gene_MYO5B', 'Gene_SCNN1B', 'Gene_NDP', 'Gene_FOXE1', 'Gene_MYO7A', 'Gene_GALNT3', 'Gene_NDUFAF4', 'Gene_SELENON', 'Gene_AICDA', 'Gene_G6PD', 'Gene_CNNM4', 'Gene_ITGA2B', 'Gene_TLR5', 'Gene_TRPM4', 'Gene_L1CAM', 'Gene_SEPT9', 'Gene_MOCS2', 'Gene_BIN1', 'Gene_EVC2', 'Gene_MED13L', 'Gene_SERPINA7', 'Gene_MRE11', 'Gene_NPC1L1', 'Gene_CD96', 'Gene_DFNB59', 'Gene_DKC1', 'Gene_NHLRC1', 'Gene_NPHP1', 'Gene_IHH', 'Gene_CDKL5', 'Gene_CENPJ', 'Gene_MAT1A', 'Gene_TSHR', 'Gene_DAZL', 'Gene_DBH', 'Gene_NSDHL', 'Gene_RFX6', 'Gene_RUNX2', 'Gene_PLEC', 'Gene_TMEM67', 'Gene_CLN6', 'Gene_SACS', 'Gene_NPC1', 'Gene_PNPO', 'Gene_RBM20', 'Gene_RPGRIP1', 'Gene_POMT1', 'Gene_LRP4', 'Gene_PNKD', 'Gene_ZFP57', 'Gene_FBN2', 'Gene_ZNF81', 'Gene_CTH', 'Gene_VCL', 'Gene_GAD1', 'Gene_PPT1', 'Gene_PCDH15', 'Gene_PMP22', 'Gene_SDHAF1', 'Gene_CYP4V2', 'Gene_TGM5', 'Gene_WAS', 'Gene_PCDH19', 'Gene_FMR1', 'Gene_CACNA1H', 'Gene_CUBN', 'Gene_ADGRG1', 'Gene_C6', 'Gene_GALNS', 'Gene_SLC17A5', 'Gene_NEUROD1', 'Gene_ARHGAP9', 'Gene_DBT', 'Gene_TCOF1', 'Gene_GTF2H5', 'Gene_LRP8', 'Gene_TBX4', 'Gene_BAAT', 'Gene_NIPAL4', 'Gene_GRXCR1', 'Gene_HEXA', 'Gene_GATA4', 'Gene_WNT4', 'Gene_PRPF3', 'Gene_FAH', 'Gene_HFE', 'Gene_IL2RG', 'Gene_MMP13', 'Gene_STOX1', 'Gene_FTO', 'Gene_ZEB2', 'Gene_ALAS2', 'Gene_TUBB3', 'Gene_TNFRSF11B', 'Gene_ZNF592', 'Gene_PINK1', 'Gene_BSCL2', 'Gene_SPEN', 'Gene_ISCU', 'Gene_ACOX1', 'Gene_FGF23', 'Gene_VKORC1', 'Gene_AMACR', 'Gene_GRIA3', 'Gene_CFP', 'Gene_COX4I2', 'Gene_LHX3', 'Gene_TLR2', 'Gene_SAMD9', 'Gene_PPOX', 'Gene_WFS1', 'Gene_SGCB', 'Gene_ABCB11', 'Gene_ABCC6', 'Gene_ZDHHC9', 'Gene_HAMP', 'Gene_RDH12', 'Gene_SH3BP2', 'Gene_ASL', 'Gene_MCCC2', 'Gene_ALX4', 'Gene_OTOF', 'Gene_CAV3', 'Gene_ARMS2', 'Gene_TMEM43', 'Gene_OLR1', 'Gene_CPS1', 'Gene_STXBP1', 'Gene_DTNA', 'Gene_ROBO3', 'Gene_RP1', 'Gene_PHOX2B', 'Gene_FRMD7', 'Gene_SIL1', 'Gene_FOXC2', 'Gene_GIF', 'Gene_PRKAG2', 'Gene_DLAT', 'Gene_MATN3', 'Gene_TRMU', 'Gene_BMPR1A', 'Gene_CRELD1', 'Gene_DPYS', 'Gene_ARG1', 'Gene_MBTPS2', 'Gene_OPN1MW', 'Gene_RGS9', 'Gene_ADAMTSL2', 'Gene_TEK', 'Gene_FRZB', 'Gene_AIP', 'Gene_PRKRA', 'Gene_MLC1', 'Gene_MTM1', 'Gene_MEFV', 'Gene_BCO1', 'Gene_PTPN22', 'Gene_KCNJ18', 'Gene_MAPK8IP1', 'Gene_GJB4', 'Gene_PITX1', 'Gene_C1GALT1C1', 'Gene_TBX5', 'Gene_EMG1', 'Gene_AGRP', 'Gene_SRPX2', 'Gene_KRT81', 'Gene_SLC39A13', 'Gene_BBS4', 'Gene_COG4', 'Gene_NLRP7', 'Gene_CISD2', 'Gene_SOX10', 'Gene_HSPB1', 'Gene_PROK2', 'Gene_C1QTNF5', 'Gene_MTHFR', 'Gene_SIX5', 'Gene_GCM2', 'Gene_ARFGEF2', 'Gene_BBS9', 'Gene_PGAM2', 'Gene_SI', 'Gene_ECE1', 'Gene_EDA', 'Gene_BCKDHB', 'Gene_ATIC', 'Gene_ANOS1', 'Gene_SERPINF2', 'Gene_MRPS22', 'Gene_PRPF8', 'Gene_NCF1', 'Gene_EFEMP1', 'Gene_PDSS2', 'Gene_PEX5', 'Gene_WASHC5', 'Gene_MGAT2', 'Gene_GALT', 'Gene_PEX1', 'Gene_TCIRG1', 'Gene_ALDH9A1', 'Gene_SRY', 'Gene_IKBKAP', 'Gene_IMPG2', 'Gene_GUSB', 'Gene_AKAP9', 'Gene_LIPI', 'Gene_BANK1', 'Gene_NOG', 'Gene_PEX12', 'Gene_AHI1', 'Gene_MFSD8', 'Gene_TBX22', 'Gene_BBS10', 'Gene_CYP11B1', 'Gene_ALOX12B', 'Gene_DHCR24', 'Gene_SPG7', 'Gene_BCS1L', 'Gene_DCLRE1C', 'Gene_IQSEC2', 'Gene_NDUFS2', 'Gene_FLVCR2', 'Gene_NDUFS3', 'Gene_ERMAP', 'Gene_APTX', 'Gene_SGCA', 'Gene_BCAM', 'Gene_MUT', 'Gene_PLCE1', 'Gene_ALDH3A2', 'Gene_ATPAF2', 'Gene_KRT83', 'Gene_RP9', 'Gene_ABCA12', 'Gene_TSEN54', 'Gene_MTRR', 'Gene_ABCC8', 'Gene_CASR', 'Gene_GDF1', 'Gene_SC5D', 'Gene_SLC6A19', 'Gene_AFG3L2', 'Gene_VSX1', 'Gene_RAD54B', 'Gene_UPK3A', 'Gene_GCLC', 'Gene_ZNF41', 'Gene_ATG16L1', 'Gene_RGR', 'Gene_DCX', 'Gene_LYST', 'Gene_IFNAR2', 'Gene_CHMP2B', 'Gene_TRIP11', 'Gene_CYP4F22', 'Gene_ATP13A2', 'Gene_CPT2', 'Gene_TBX20', 'Gene_SLC22A5', 'Gene_DARS2', 'Gene_FXN', 'Gene_PNPLA6', 'Gene_ARSA', 'Gene_SEC23B', 'Gene_GLDC', 'Gene_GARS', 'Gene_ABCB7', 'Gene_TECTA', 'Gene_UNG', 'Gene_DLL3', 'Gene_ESPN', 'Gene_TREM2', 'Gene_SH3PXD2B', 'Gene_SIAE', 'Gene_SMPD1', 'Gene_SCN9A', 'Gene_CYBA', 'Gene_FOXP3', 'Gene_ALG3', 'Gene_FREM2', 'Gene_PC', 'Gene_AGPS', 'Gene_SCN1B', 'Gene_GDI1', 'Gene_RS1', 'Gene_ALG2', 'Gene_GYG1', 'Gene_CHD7', 'Gene_MUTYH', 'Gene_SGSH', 'Gene_CCR2', 'Gene_SLURP1', 'Gene_TDP1', 'Gene_ASPA', 'Gene_MYBPC3', 'Gene_FKTN', 'Gene_NDUFAF5', 'Gene_TSPAN7', 'Gene_SLC2A10', 'Gene_CARTPT', 'Gene_KARS', 'Gene_PEPD', 'Gene_SLC27A4', 'Gene_NDUFAF3', 'Gene_CTNS', 'Gene_DYSF', 'Gene_IDS', 'Gene_MFN2', 'Gene_PLOD2', 'Gene_LCAT', 'Gene_FLNB', 'Gene_GDF5', 'Gene_TNFRSF13B', 'Gene_UBA1', 'Gene_SLC39A4', 'Gene_KCNK9', 'Gene_BMP15', 'Gene_HTRA2', 'Gene_JAG1', 'Gene_SUCLA2', 'Gene_CDAN1', 'Gene_SLC9A3R1', 'Gene_STAT5B', 'Gene_MOCS1', 'Gene_SMN1', 'Gene_GHRL', 'Gene_PDHA1', 'Gene_TNFSF11', 'Gene_TBX1', 'Gene_XDH', 'Gene_DIS3', 'Gene_KCNMA1', 'Gene_SERPING1', 'Gene_ING1', 'Gene_RECQL4', 'Gene_TSEN34', 'Gene_PLP1', 'Gene_FKRP', 'Gene_TAB2', 'Gene_PITPNM3', 'Gene_UCP3', 'Gene_NEK8', 'Gene_DGUOK', 'Gene_F12', 'Gene_SLC16A2', 'Gene_ANKH', 'Gene_MYO15A', 'Gene_SLC22A4', 'Gene_GBA', 'Gene_SLC25A13', 'Gene_ACAT1', 'Gene_GK', 'Gene_GLE1', 'Gene_PDE8B', 'Gene_CYP2R1', 'Gene_GJB6', 'Gene_VPS33B', 'Gene_DPM3', 'Gene_VAPB', 'Gene_SLC7A7', 'Gene_TAS2R16', 'Gene_PROP1', 'Gene_TMEM216', 'Gene_FAAH', 'Gene_SLC22A18'}\n"
     ]
    }
   ],
   "source": [
    "test_3=fix_test_columns(test_2,train_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2.to_csv(\"checkpoints_databases/w_working_train.csv\",index=False,encoding=\"utf8\")\n",
    "test_3.to_csv(\"checkpoints_databases/w_working_test.csv\",index=False,encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
